Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.70s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running evaluation on the dataset:   0%|          | 0/60 [00:00<?, ?it/s]From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Running evaluation on the dataset:   2%|▏         | 1/60 [00:01<01:22,  1.40s/it]Running evaluation on the dataset:   3%|▎         | 2/60 [00:02<01:01,  1.06s/it]Running evaluation on the dataset:   5%|▌         | 3/60 [00:03<00:54,  1.04it/s]Running evaluation on the dataset:   7%|▋         | 4/60 [00:03<00:50,  1.12it/s]Running evaluation on the dataset:   8%|▊         | 5/60 [00:04<00:47,  1.16it/s]Running evaluation on the dataset:  10%|█         | 6/60 [00:05<00:45,  1.19it/s]Running evaluation on the dataset:  12%|█▏        | 7/60 [00:06<00:44,  1.19it/s]Running evaluation on the dataset:  15%|█▌        | 9/60 [00:07<00:32,  1.55it/s]Running evaluation on the dataset:  17%|█▋        | 10/60 [00:07<00:34,  1.46it/s]Running evaluation on the dataset:  20%|██        | 12/60 [00:08<00:27,  1.73it/s]Running evaluation on the dataset:  22%|██▏       | 13/60 [00:09<00:29,  1.57it/s]Running evaluation on the dataset:  23%|██▎       | 14/60 [00:10<00:31,  1.48it/s]Running evaluation on the dataset:  25%|██▌       | 15/60 [00:11<00:32,  1.39it/s]Running evaluation on the dataset:  27%|██▋       | 16/60 [00:12<00:32,  1.35it/s]Running evaluation on the dataset:  30%|███       | 18/60 [00:12<00:25,  1.64it/s]Running evaluation on the dataset:  32%|███▏      | 19/60 [00:13<00:26,  1.52it/s]Running evaluation on the dataset:  33%|███▎      | 20/60 [00:14<00:27,  1.44it/s]Running evaluation on the dataset:  35%|███▌      | 21/60 [00:15<00:28,  1.38it/s]Running evaluation on the dataset:  37%|███▋      | 22/60 [00:16<00:28,  1.33it/s]Running evaluation on the dataset:  38%|███▊      | 23/60 [00:17<00:28,  1.31it/s]Running evaluation on the dataset:  40%|████      | 24/60 [00:17<00:27,  1.29it/s]Running evaluation on the dataset:  42%|████▏     | 25/60 [00:18<00:27,  1.27it/s]Running evaluation on the dataset:  43%|████▎     | 26/60 [00:19<00:27,  1.26it/s]Running evaluation on the dataset:  45%|████▌     | 27/60 [00:20<00:26,  1.25it/s]Running evaluation on the dataset:  47%|████▋     | 28/60 [00:21<00:25,  1.25it/s]Running evaluation on the dataset:  48%|████▊     | 29/60 [00:21<00:24,  1.24it/s]Running evaluation on the dataset:  50%|█████     | 30/60 [00:22<00:24,  1.24it/s]Running evaluation on the dataset:  52%|█████▏    | 31/60 [00:23<00:23,  1.24it/s]Running evaluation on the dataset:  53%|█████▎    | 32/60 [00:24<00:22,  1.24it/s]Running evaluation on the dataset:  55%|█████▌    | 33/60 [00:25<00:21,  1.24it/s]Running evaluation on the dataset:  57%|█████▋    | 34/60 [00:25<00:20,  1.25it/s]Running evaluation on the dataset:  58%|█████▊    | 35/60 [00:26<00:20,  1.25it/s]Running evaluation on the dataset:  60%|██████    | 36/60 [00:27<00:19,  1.24it/s]Running evaluation on the dataset:  62%|██████▏   | 37/60 [00:28<00:18,  1.23it/s]Running evaluation on the dataset:  63%|██████▎   | 38/60 [00:29<00:17,  1.24it/s]Running evaluation on the dataset:  65%|██████▌   | 39/60 [00:29<00:16,  1.24it/s]Running evaluation on the dataset:  67%|██████▋   | 40/60 [00:30<00:16,  1.24it/s]Running evaluation on the dataset:  68%|██████▊   | 41/60 [00:31<00:15,  1.24it/s]Running evaluation on the dataset:  70%|███████   | 42/60 [00:32<00:14,  1.24it/s]Running evaluation on the dataset:  72%|███████▏  | 43/60 [00:33<00:13,  1.23it/s]Running evaluation on the dataset:  75%|███████▌  | 45/60 [00:34<00:09,  1.57it/s]Running evaluation on the dataset:  77%|███████▋  | 46/60 [00:34<00:09,  1.48it/s]Running evaluation on the dataset:  78%|███████▊  | 47/60 [00:35<00:09,  1.41it/s]Running evaluation on the dataset:  80%|████████  | 48/60 [00:36<00:08,  1.35it/s]Running evaluation on the dataset:  82%|████████▏ | 49/60 [00:37<00:08,  1.32it/s]Running evaluation on the dataset:  83%|████████▎ | 50/60 [00:38<00:07,  1.30it/s]Running evaluation on the dataset:  85%|████████▌ | 51/60 [00:38<00:07,  1.27it/s]Running evaluation on the dataset:  87%|████████▋ | 52/60 [00:39<00:06,  1.25it/s]Running evaluation on the dataset:  90%|█████████ | 54/60 [00:40<00:03,  1.58it/s]Running evaluation on the dataset:  92%|█████████▏| 55/60 [00:41<00:03,  1.47it/s]Running evaluation on the dataset:  93%|█████████▎| 56/60 [00:42<00:02,  1.40it/s]Running evaluation on the dataset:  95%|█████████▌| 57/60 [00:43<00:02,  1.35it/s]Running evaluation on the dataset:  97%|█████████▋| 58/60 [00:43<00:01,  1.31it/s]Running evaluation on the dataset:  98%|█████████▊| 59/60 [00:44<00:00,  1.28it/s]Running evaluation on the dataset: 100%|██████████| 60/60 [00:45<00:00,  1.27it/s]Running evaluation on the dataset: 100%|██████████| 60/60 [00:45<00:00,  1.32it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/yun.hy/.conda/envs/MedLitSpin/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
Running evaluation on the dataset:   0%|          | 0/60 [00:00<?, ?it/s]From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.
Running evaluation on the dataset:   2%|▏         | 1/60 [00:03<03:39,  3.72s/it]Running evaluation on the dataset:   3%|▎         | 2/60 [00:07<03:41,  3.82s/it]Running evaluation on the dataset:   5%|▌         | 3/60 [00:11<03:39,  3.85s/it]Running evaluation on the dataset:   7%|▋         | 4/60 [00:14<03:06,  3.33s/it]Running evaluation on the dataset:   8%|▊         | 5/60 [00:17<03:00,  3.28s/it]Running evaluation on the dataset:  10%|█         | 6/60 [00:20<03:04,  3.41s/it]Running evaluation on the dataset:  12%|█▏        | 7/60 [00:24<03:10,  3.60s/it]Running evaluation on the dataset:  13%|█▎        | 8/60 [00:27<02:57,  3.40s/it]Running evaluation on the dataset:  15%|█▌        | 9/60 [00:31<02:49,  3.33s/it]Running evaluation on the dataset:  17%|█▋        | 10/60 [00:33<02:33,  3.07s/it]Running evaluation on the dataset:  18%|█▊        | 11/60 [00:37<02:39,  3.26s/it]Running evaluation on the dataset:  20%|██        | 12/60 [00:40<02:34,  3.22s/it]Running evaluation on the dataset:  22%|██▏       | 13/60 [00:44<02:44,  3.49s/it]Running evaluation on the dataset:  23%|██▎       | 14/60 [00:47<02:34,  3.35s/it]Running evaluation on the dataset:  25%|██▌       | 15/60 [00:51<02:37,  3.51s/it]Running evaluation on the dataset:  27%|██▋       | 16/60 [00:54<02:29,  3.40s/it]Running evaluation on the dataset:  28%|██▊       | 17/60 [00:57<02:20,  3.27s/it]Running evaluation on the dataset:  30%|███       | 18/60 [01:00<02:16,  3.24s/it]Running evaluation on the dataset:  32%|███▏      | 19/60 [01:03<02:11,  3.21s/it]Running evaluation on the dataset:  33%|███▎      | 20/60 [01:06<02:07,  3.18s/it]Running evaluation on the dataset:  35%|███▌      | 21/60 [01:10<02:12,  3.39s/it]Running evaluation on the dataset:  37%|███▋      | 22/60 [01:13<02:06,  3.32s/it]Running evaluation on the dataset:  38%|███▊      | 23/60 [01:17<02:00,  3.26s/it]Running evaluation on the dataset:  40%|████      | 24/60 [01:20<01:55,  3.20s/it]Running evaluation on the dataset:  42%|████▏     | 25/60 [01:23<01:57,  3.37s/it]Running evaluation on the dataset:  43%|████▎     | 26/60 [01:27<01:59,  3.53s/it]Running evaluation on the dataset:  45%|████▌     | 27/60 [01:31<01:59,  3.61s/it]Running evaluation on the dataset:  47%|████▋     | 28/60 [01:34<01:50,  3.45s/it]Running evaluation on the dataset:  48%|████▊     | 29/60 [01:38<01:51,  3.58s/it]Running evaluation on the dataset:  50%|█████     | 30/60 [01:41<01:43,  3.45s/it]Running evaluation on the dataset:  52%|█████▏    | 31/60 [01:44<01:37,  3.36s/it]Running evaluation on the dataset:  53%|█████▎    | 32/60 [01:47<01:30,  3.25s/it]Running evaluation on the dataset:  55%|█████▌    | 33/60 [01:51<01:27,  3.23s/it]Running evaluation on the dataset:  57%|█████▋    | 34/60 [01:54<01:22,  3.17s/it]Running evaluation on the dataset:  58%|█████▊    | 35/60 [01:57<01:21,  3.25s/it]Running evaluation on the dataset:  60%|██████    | 36/60 [02:01<01:24,  3.50s/it]Running evaluation on the dataset:  62%|██████▏   | 37/60 [02:05<01:23,  3.62s/it]Running evaluation on the dataset:  63%|██████▎   | 38/60 [02:09<01:20,  3.68s/it]Running evaluation on the dataset:  65%|██████▌   | 39/60 [02:12<01:13,  3.52s/it]Running evaluation on the dataset:  67%|██████▋   | 40/60 [02:14<01:03,  3.18s/it]Running evaluation on the dataset:  68%|██████▊   | 41/60 [02:18<01:01,  3.26s/it]Running evaluation on the dataset:  70%|███████   | 42/60 [02:21<00:57,  3.20s/it]Running evaluation on the dataset:  72%|███████▏  | 43/60 [02:24<00:56,  3.31s/it]Running evaluation on the dataset:  73%|███████▎  | 44/60 [02:27<00:51,  3.22s/it]Running evaluation on the dataset:  75%|███████▌  | 45/60 [02:31<00:47,  3.20s/it]Running evaluation on the dataset:  77%|███████▋  | 46/60 [02:34<00:44,  3.18s/it]Running evaluation on the dataset:  78%|███████▊  | 47/60 [02:37<00:41,  3.20s/it]Running evaluation on the dataset:  80%|████████  | 48/60 [02:40<00:37,  3.16s/it]Running evaluation on the dataset:  82%|████████▏ | 49/60 [02:43<00:34,  3.13s/it]Running evaluation on the dataset:  83%|████████▎ | 50/60 [02:47<00:33,  3.35s/it]Running evaluation on the dataset:  85%|████████▌ | 51/60 [02:51<00:31,  3.48s/it]Running evaluation on the dataset:  87%|████████▋ | 52/60 [02:55<00:29,  3.69s/it]Running evaluation on the dataset:  88%|████████▊ | 53/60 [02:58<00:25,  3.67s/it]Running evaluation on the dataset:  90%|█████████ | 54/60 [03:03<00:22,  3.79s/it]Running evaluation on the dataset:  92%|█████████▏| 55/60 [03:07<00:19,  3.90s/it]Running evaluation on the dataset:  93%|█████████▎| 56/60 [03:11<00:15,  3.89s/it]Running evaluation on the dataset:  95%|█████████▌| 57/60 [03:14<00:10,  3.64s/it]Running evaluation on the dataset:  97%|█████████▋| 58/60 [03:18<00:07,  3.71s/it]Running evaluation on the dataset:  98%|█████████▊| 59/60 [03:22<00:03,  3.79s/it]Running evaluation on the dataset: 100%|██████████| 60/60 [03:25<00:00,  3.57s/it]Running evaluation on the dataset: 100%|██████████| 60/60 [03:25<00:00,  3.42s/it]
