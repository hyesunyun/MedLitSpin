{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for Calculating Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: the `json` files that contain overall metrics and also the linear regression model results were created manually.\n",
    "This can be done with some Python code very easily. However, the code for this is not included in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import altair as alt\n",
    "from utils import save_dataset_to_csv\n",
    "import statsmodels.formula.api as smf\n",
    "from tqdm import tqdm\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = {\n",
    "    \"alpacare-7B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 7},\n",
    "    \"biomedgpt7B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 7},\n",
    "    \"biomistral7B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 7},\n",
    "    \"claude_3.5-haiku\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None},\n",
    "    \"claude_3.5-sonnet\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None},\n",
    "    \"gemini_1.5_flash\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None},\n",
    "    \"gemini_1.5_flash-8B\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": 8},\n",
    "    \"gpt4o\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None},\n",
    "    \"gpt4o-mini\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None},\n",
    "    \"gpt35\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": 175},\n",
    "    \"llama2_chat-7B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 7},\n",
    "    \"llama2_chat-13B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 13},\n",
    "    \"llama2_chat-70B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 70},\n",
    "    \"llama3_instruct-8B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 8},\n",
    "    \"llama3_instruct-70B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 70},\n",
    "    \"med42-8B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 8},\n",
    "    \"med42-70B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 70},\n",
    "    \"mistral_instruct7B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 7},\n",
    "    \"olmo2_instruct-7B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 7},\n",
    "    \"olmo2_instruct-13B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 13},\n",
    "    \"openbiollm-8B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 8},\n",
    "    \"openbiollm-70B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 70}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin Detection Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size_in_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>claude_3.5-sonnet</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>claude_3.5-haiku</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>biomistral7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>llama2_chat-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>llama2_chat-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>llama3_instruct-8B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>llama3_instruct-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>med42-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>med42-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>olmo2_instruct-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>alpacare-7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>llama2_chat-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall        f1           model_name  \\\n",
       "0   0.783333   0.707317  0.966667  0.816901                gpt4o   \n",
       "1   0.850000   0.783784  0.966667  0.865672           gpt4o-mini   \n",
       "2   0.516667   1.000000  0.033333  0.064516                gpt35   \n",
       "3   0.733333   0.652174  1.000000  0.789474     gemini_1.5_flash   \n",
       "4   0.833333   0.794118  0.900000  0.843750  gemini_1.5_flash-8B   \n",
       "5   0.966667   1.000000  0.933333  0.965517    claude_3.5-sonnet   \n",
       "6   0.566667   0.535714  1.000000  0.697674     claude_3.5-haiku   \n",
       "7   0.516667   1.000000  0.033333  0.064516         biomistral7B   \n",
       "8   0.566667   0.537037  0.966667  0.690476      llama2_chat-13B   \n",
       "9   0.633333   0.580000  0.966667  0.725000      llama2_chat-70B   \n",
       "10  0.833333   1.000000  0.666667  0.800000   llama3_instruct-8B   \n",
       "11  0.833333   1.000000  0.666667  0.800000  llama3_instruct-70B   \n",
       "12  0.583333   1.000000  0.166667  0.285714             med42-8B   \n",
       "13  0.800000   0.909091  0.666667  0.769231            med42-70B   \n",
       "14  0.700000   1.000000  0.400000  0.571429    olmo2_instruct-7B   \n",
       "15  0.516667   1.000000  0.033333  0.064516   olmo2_instruct-13B   \n",
       "16  0.500000   0.000000  0.000000  0.000000   mistral_instruct7B   \n",
       "17  0.508475   0.500000  1.000000  0.666667        openbiollm-8B   \n",
       "18  0.833333   0.857143  0.800000  0.827586       openbiollm-70B   \n",
       "19  0.683333   0.923077  0.400000  0.558140          alpacare-7B   \n",
       "20  0.500000   0.500000  1.000000  0.666667       llama2_chat-7B   \n",
       "21  0.500000   0.500000  0.966667  0.659091          biomedgpt7B   \n",
       "\n",
       "           model_type  model_size_in_b  \n",
       "0   generalist closed              NaN  \n",
       "1   generalist closed              NaN  \n",
       "2   generalist closed            175.0  \n",
       "3   generalist closed              NaN  \n",
       "4   generalist closed              8.0  \n",
       "5   generalist closed              NaN  \n",
       "6   generalist closed              NaN  \n",
       "7     biomedical open              7.0  \n",
       "8     generalist open             13.0  \n",
       "9     generalist open             70.0  \n",
       "10    generalist open              8.0  \n",
       "11    generalist open             70.0  \n",
       "12    biomedical open              8.0  \n",
       "13    biomedical open             70.0  \n",
       "14    generalist open              7.0  \n",
       "15    generalist open             13.0  \n",
       "16    generalist open              7.0  \n",
       "17    biomedical open              8.0  \n",
       "18    biomedical open             70.0  \n",
       "19    biomedical open              7.0  \n",
       "20    generalist open              7.0  \n",
       "21    biomedical open              7.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detection_overall_metrics.json was manually created\n",
    "detection_stats_df = pd.read_json(\"./eval_outputs/detection_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "detection_stats_df[\"model_name\"] = detection_stats_df.index\n",
    "detection_stats_df[\"model_type\"] = detection_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "detection_stats_df[\"model_size_in_b\"] = detection_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "detection_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(detection_stats_df)}\")\n",
    "\n",
    "detection_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "detection_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of accuracy by model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by model type and calculate mean accuracy and standard deviation\n",
    "accuracy_by_model_type = detection_stats_df.groupby('model_type')['accuracy'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "accuracy_by_model_type.columns = ['model_type', 'mean_accuracy', 'std_deviation']\n",
    "\n",
    "print(accuracy_by_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_type  mean_precision  std_deviation\n",
      "0    biomedical open        0.812759       0.219535\n",
      "1  generalist closed        0.781872       0.172379\n",
      "2    generalist open        0.702130       0.364676\n"
     ]
    }
   ],
   "source": [
    "# Group by model type and calculate mean precision and standard deviation\n",
    "precision_by_model_type = detection_stats_df.groupby('model_type')['precision'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "precision_by_model_type.columns = ['model_type', 'mean_precision', 'std_deviation']\n",
    "\n",
    "print(precision_by_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_type  mean_recall  std_deviation\n",
      "0    biomedical open     0.576190       0.383799\n",
      "1  generalist closed     0.828571       0.352467\n",
      "2    generalist open     0.587500       0.406666\n"
     ]
    }
   ],
   "source": [
    "# Group by model type and calculate mean recall and standard deviation\n",
    "recall_by_model_type = detection_stats_df.groupby('model_type')['recall'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "recall_by_model_type.columns = ['model_type', 'mean_recall', 'std_deviation']\n",
    "\n",
    "print(recall_by_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_type   mean_f1  std_deviation\n",
      "0    biomedical open  0.547278       0.275737\n",
      "1  generalist closed  0.720501       0.300329\n",
      "2    generalist open  0.539761       0.322221\n"
     ]
    }
   ],
   "source": [
    "# Group by model type and calculate mean f1 and standard deviation\n",
    "f1_by_model_type = detection_stats_df.groupby('model_type')['f1'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "f1_by_model_type.columns = ['model_type', 'mean_f1', 'std_deviation']\n",
    "\n",
    "print(f1_by_model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-d5277e01c24041ff900416916b2188d4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-d5277e01c24041ff900416916b2188d4.vega-embed details,\n",
       "  #altair-viz-d5277e01c24041ff900416916b2188d4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-d5277e01c24041ff900416916b2188d4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-d5277e01c24041ff900416916b2188d4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-d5277e01c24041ff900416916b2188d4\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"legend\": {\"direction\": \"horizontal\", \"legendX\": 130, \"legendY\": -45, \"orient\": \"none\", \"titleAnchor\": \"middle\"}, \"scale\": {\"domain\": [\"biomedical open\", \"generalist closed\", \"generalist open\"], \"range\": [\"#0868ac\", \"#7bccc4\", \"#bae4bc\"]}, \"title\": \"Model Type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": \"-x\", \"title\": \"Model Name\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"rule\", \"color\": \"red\"}, \"encoding\": {\"size\": {\"value\": 2}, \"x\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"size\": {\"value\": 2}, \"strokeDash\": {\"value\": [10, 10]}, \"x\": {\"aggregate\": \"min\", \"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"dx\": 20, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": \"-x\", \"title\": \"Model Name\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-c99b505b5a2663bac9ed468766347b7b\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-c99b505b5a2663bac9ed468766347b7b\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLLM 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLLM 70B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary for custom labels\n",
    "custom_labels = {\n",
    "    \"alpacare-7B\": \"AlpaCare 7B\",\n",
    "    \"biomedgpt7B\": \"BioMedGPT 7B\",\n",
    "    \"biomistral7B\": \"BioMistral 7B\",\n",
    "    \"claude_3.5-haiku\": \"Claude3.5 Haiku\",\n",
    "    \"claude_3.5-sonnet\": \"Claude3.5 Sonnet\", \n",
    "    \"gemini_1.5_flash\": \"Gemini1.5 Flash\",\n",
    "    \"gemini_1.5_flash-8B\": \"Gemini1.5 Flash 8B\",\n",
    "    \"gpt4o\": \"GPT4o\",\n",
    "    \"gpt4o-mini\": \"GPT4o Mini\",\n",
    "    \"gpt35\": \"GPT3.5\",\n",
    "    \"llama2_chat-7B\": \"Llama2 Chat 7B\",\n",
    "    \"llama2_chat-13B\": \"Llama2 Chat 13B\",\n",
    "    \"llama2_chat-70B\": \"Llama2 Chat 70B\",\n",
    "    \"llama3_instruct-8B\": \"Llama3 Instruct 8B\",\n",
    "    \"llama3_instruct-70B\": \"Llama3 Instruct 70B\",\n",
    "    \"med42-8B\": \"Med42 8B\",\n",
    "    \"med42-70B\": \"Med42 70B\",\n",
    "    \"mistral_instruct7B\": \"Mistral Instruct 7B\",\n",
    "    \"olmo2_instruct-7B\": \"Olmo2 Instruct 7B\",\n",
    "    \"olmo2_instruct-13B\": \"Olmo2 Instruct 13B\",\n",
    "    \"openbiollm-8B\": \"OpenBioLLM 8B\",\n",
    "    \"openbiollm-70B\": \"OpenBioLLM 70B\"\n",
    "}\n",
    "\n",
    "detection_stats_df['model_name_custom'] = detection_stats_df['model_name'].map(custom_labels)\n",
    "\n",
    "color_mapping = {\n",
    "    'biomedical open': '#0868ac', \n",
    "    'generalist closed': '#7bccc4',\n",
    "    'generalist open': '#bae4bc',\n",
    "}\n",
    "\n",
    "# Create the bar chart\n",
    "chart = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    y=alt.Y('model_name_custom:N', sort='-x', title='Model Name'),\n",
    "    x=alt.X('accuracy:Q', title='Accuracy'),\n",
    "    color=alt.Color('model_type:N', title='Model Type',\n",
    "                    scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())),\n",
    "                    legend=alt.Legend(\n",
    "                    orient='none',\n",
    "                    legendX=130, legendY=-45,\n",
    "                    direction='horizontal',\n",
    "                    titleAnchor='middle'))  # Legend at the bottom\n",
    ").properties(\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Add value labels with increased font size\n",
    "text = chart.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontWeight='bold',\n",
    "    dx=20  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('accuracy:Q', format='.2f'),\n",
    "    color=alt.value('black'),\n",
    ")\n",
    "\n",
    "# Add a mean rule\n",
    "avg_rule = alt.Chart(detection_stats_df).mark_rule(color='red').encode(\n",
    "    x='mean(accuracy):Q',\n",
    "    size=alt.value(2)\n",
    ")\n",
    "\n",
    "# Add a 50% chance rule\n",
    "chance_rule = alt.Chart(detection_stats_df).mark_rule(color='gray').encode(\n",
    "    x='min(accuracy):Q',\n",
    "    size=alt.value(2),\n",
    "    strokeDash=alt.value([10, 10])\n",
    ")\n",
    "\n",
    "# Increase font size for axis labels, titles, and other components\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Title and facet headers (if any)\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Combine chart and text, and apply the config\n",
    "c_t = chart + avg_rule + chance_rule + text\n",
    "c_t = c_t.configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# Save to HTML\n",
    "c_t.save(\"./plots/detection_accuracy_by_model.html\")\n",
    "\n",
    "# Display the chart\n",
    "c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the bar chart\n",
    "# chart = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "#     y=alt.Y('model_name_custom:N', sort='-x', title='Model Name'),\n",
    "#     x=alt.X('accuracy:Q', title='Accuracy'),\n",
    "#    color=alt.Color('model_type:N', title='Model Type', legend=alt.Legend(\n",
    "#         orient='none',\n",
    "#         legendX=130, legendY=-45,\n",
    "#         direction='horizontal',\n",
    "#         titleAnchor='middle'), scale=alt.Scale(range=[\"#808080\", \"#A9A9A9\", \"#D3D3D3\", \"#BEBEBE\"]))  # Legend at the bottom\n",
    "# ).properties(\n",
    "#     width=800,\n",
    "# )\n",
    "\n",
    "# # Add value labels with increased font size\n",
    "# text = chart.mark_text(\n",
    "#     align='center',\n",
    "#     baseline='middle',\n",
    "#     fontWeight='bold',\n",
    "#     dx=18  # Adjust the position of the text\n",
    "# ).encode(\n",
    "#     text=alt.Text('accuracy:Q', format='.2f'),\n",
    "#     color=alt.value('black')  # Set text color to black\n",
    "# )\n",
    "\n",
    "# # Add a mean rule\n",
    "# rule = alt.Chart(detection_stats_df).mark_rule(color='gray').encode(\n",
    "#     x='mean(accuracy):Q',\n",
    "#     size=alt.value(2)\n",
    "# )\n",
    "\n",
    "# # Increase font size for axis labels, titles, and other components\n",
    "# chart_config = {\n",
    "#     \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "#     \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Title and facet headers (if any)\n",
    "#     \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "#     \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "# }\n",
    "\n",
    "# # Combine chart and text, and apply the config\n",
    "# c_t = chart + rule + text\n",
    "# c_t = c_t.configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# # Save to HTML\n",
    "# c_t.save(\"./plots/detection_accuracy_by_model_gray.html\")\n",
    "\n",
    "# # Display the chart\n",
    "# c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-bbfd82a53d574ff08482d05c592da7e8.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-bbfd82a53d574ff08482d05c592da7e8.vega-embed details,\n",
       "  #altair-viz-bbfd82a53d574ff08482d05c592da7e8.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-bbfd82a53d574ff08482d05c592da7e8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-bbfd82a53d574ff08482d05c592da7e8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-bbfd82a53d574ff08482d05c592da7e8\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"legend\": null, \"title\": \"Model Type\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Type\"}, {\"mark\": {\"type\": \"errorbar\", \"extent\": \"stdev\"}, \"encoding\": {\"x\": {\"field\": \"model_type\", \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"legend\": null, \"title\": \"Model Type\", \"type\": \"nominal\"}, \"text\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Type\"}], \"data\": {\"name\": \"data-c99b505b5a2663bac9ed468766347b7b\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-c99b505b5a2663bac9ed468766347b7b\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLLM 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLLM 70B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot average accuracy by model_type and add error bars\n",
    "bars = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    x=alt.X('model_type:N', title='Model Type', axis=alt.Axis(labelAngle=0)),\n",
    "    y=alt.Y('mean(accuracy):Q', title='Mean Accuracy'),\n",
    "    color=alt.Color('model_type:N', title='Model Type', legend=None)\n",
    ").properties(\n",
    "    title='Average Accuracy by Model Type',\n",
    "    width=800  # Set the width to 800 pixels\n",
    ")\n",
    "\n",
    "error_bars = alt.Chart(detection_stats_df).mark_errorbar(extent='stdev').encode(\n",
    "    x=alt.X('model_type:N'),\n",
    "    y=alt.Y('accuracy:Q')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-5  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('mean(accuracy):Q', format='.2f')\n",
    ")\n",
    "\n",
    "alt.layer(bars, error_bars, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of accuracy by model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model size in buckets (0-10B, 11-20B, 22-100B, 100B+/NaN)\n",
    "def model_size_bucket(model_size): \n",
    "    if model_size is None or pd.isna(model_size):\n",
    "        return \"Unknown\"\n",
    "    elif model_size >= 100:\n",
    "        return \"100B+\"\n",
    "    elif model_size <= 10:\n",
    "        return \"0-10B\"\n",
    "    elif model_size <= 20:\n",
    "        return \"11-20B\"\n",
    "    else:\n",
    "        return \"21-100B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average accuracy by model size\n",
    "detection_stats_df[\"model_size_bucket\"] = detection_stats_df[\"model_size_in_b\"].map(model_size_bucket)\n",
    "\n",
    "accuracy_by_model_size = detection_stats_df.groupby('model_size_bucket')['accuracy'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "accuracy_by_model_size.columns = ['model_size_bucket', 'mean_accuracy', 'std_deviation']\n",
    "\n",
    "print(accuracy_by_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_size_bucket  mean_precision  std_deviation\n",
      "0             0-10B        0.721719       0.337294\n",
      "1             100B+        1.000000            NaN\n",
      "2            11-20B        0.768519       0.327364\n",
      "3           21-100B        0.836558       0.180942\n",
      "4           Unknown        0.735798       0.173164\n"
     ]
    }
   ],
   "source": [
    "# average precision by model size\n",
    "precision_by_model_size = detection_stats_df.groupby('model_size_bucket')['precision'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "precision_by_model_size.columns = ['model_size_bucket', 'mean_precision', 'std_deviation']\n",
    "\n",
    "print(precision_by_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_size_bucket  mean_recall  std_deviation\n",
      "0             0-10B     0.553333       0.404969\n",
      "1             100B+     0.033333            NaN\n",
      "2            11-20B     0.500000       0.659966\n",
      "3           21-100B     0.775000       0.142400\n",
      "4           Unknown     0.973333       0.027889\n"
     ]
    }
   ],
   "source": [
    "# average recall by model size\n",
    "recall_by_model_size = detection_stats_df.groupby('model_size_bucket')['recall'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "recall_by_model_size.columns = ['model_size_bucket', 'mean_recall', 'std_deviation']\n",
    "\n",
    "print(recall_by_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_size_bucket   mean_f1  std_deviation\n",
      "0             0-10B  0.511597       0.294719\n",
      "1             100B+  0.064516            NaN\n",
      "2            11-20B  0.377496       0.442621\n",
      "3           21-100B  0.780454       0.043987\n",
      "4           Unknown  0.827048       0.098638\n"
     ]
    }
   ],
   "source": [
    "# average f1 score by model size \n",
    "f1_by_model_size_bucket = detection_stats_df.groupby('model_size_bucket')['f1'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "f1_by_model_size_bucket.columns = ['model_size_bucket', 'mean_f1', 'std_deviation']\n",
    "\n",
    "print(f1_by_model_size_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-652c14d4fb7445f298fc66dfb093e3b3.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-652c14d4fb7445f298fc66dfb093e3b3.vega-embed details,\n",
       "  #altair-viz-652c14d4fb7445f298fc66dfb093e3b3.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-652c14d4fb7445f298fc66dfb093e3b3\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-652c14d4fb7445f298fc66dfb093e3b3\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-652c14d4fb7445f298fc66dfb093e3b3\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_name\", \"sort\": \"-y\", \"title\": \"Model Name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy by Model Size Bucket\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"text\": {\"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"model_name\", \"sort\": \"-y\", \"title\": \"Model Name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy by Model Size Bucket\"}], \"data\": {\"name\": \"data-30a16b1b8a4249de23cf238f4f43805b\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-30a16b1b8a4249de23cf238f4f43805b\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\", \"model_size_bucket\": \"100B+\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLLM 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLLM 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\", \"model_size_bucket\": \"0-10B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    x=alt.X('model_name:N', sort='-y', title='Model Name'),\n",
    "    y=alt.Y('accuracy:Q', title='Accuracy'),\n",
    "    color=alt.Color('model_size_bucket:N', title='Model Size Bucket')\n",
    ").properties(\n",
    "    title='Accuracy by Model Size Bucket',\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-5  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('accuracy:Q', format='.2f')\n",
    ")\n",
    "\n",
    "bars + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-cfc81d72a6c44c319c627422b442268e.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-cfc81d72a6c44c319c627422b442268e.vega-embed details,\n",
       "  #altair-viz-cfc81d72a6c44c319c627422b442268e.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-cfc81d72a6c44c319c627422b442268e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-cfc81d72a6c44c319c627422b442268e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-cfc81d72a6c44c319c627422b442268e\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"legend\": null, \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_size_bucket\", \"sort\": [\"0-10B\", \"11-20B\", \"21-100B\", \"100B+\", \"Unknown\"], \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Size\"}, {\"mark\": {\"type\": \"errorbar\", \"extent\": \"stdev\"}, \"encoding\": {\"x\": {\"field\": \"model_size_bucket\", \"sort\": [\"0-10B\", \"11-20B\", \"21-100B\", \"100B+\", \"Unknown\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"legend\": null, \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"text\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_size_bucket\", \"sort\": [\"0-10B\", \"11-20B\", \"21-100B\", \"100B+\", \"Unknown\"], \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Size\"}], \"data\": {\"name\": \"data-30a16b1b8a4249de23cf238f4f43805b\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-30a16b1b8a4249de23cf238f4f43805b\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\", \"model_size_bucket\": \"100B+\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLLM 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLLM 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\", \"model_size_bucket\": \"0-10B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot average accuracy by model_size_bucket and add error bars\n",
    "bars = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    x=alt.X('model_size_bucket:N', title='Model Size Bucket', axis=alt.Axis(labelAngle=0), sort=['0-10B', '11-20B', '21-100B', '100B+', 'Unknown']),\n",
    "    y=alt.Y('mean(accuracy):Q', title='Mean Accuracy'),\n",
    "    color=alt.Color('model_size_bucket:N', title='Model Size Bucket', legend=None)\n",
    ").properties(\n",
    "    title='Average Accuracy by Model Size',\n",
    "    width=800  # Set the width to 800 pixels\n",
    ")\n",
    "\n",
    "error_bars = alt.Chart(detection_stats_df).mark_errorbar(extent='stdev').encode(\n",
    "    x=alt.X('model_size_bucket:N', sort=['0-10B', '11-20B', '21-100B', '100B+', 'Unknown']),\n",
    "    y=alt.Y('accuracy:Q')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-5  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('mean(accuracy):Q', format='.2f')\n",
    ")\n",
    "\n",
    "alt.layer(bars, error_bars, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-797f7a5a5b1247ec8509ef76ef2cbc83.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-797f7a5a5b1247ec8509ef76ef2cbc83.vega-embed details,\n",
       "  #altair-viz-797f7a5a5b1247ec8509ef76ef2cbc83.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-797f7a5a5b1247ec8509ef76ef2cbc83\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-797f7a5a5b1247ec8509ef76ef2cbc83\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-797f7a5a5b1247ec8509ef76ef2cbc83\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\"}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_size_in_b\", \"title\": \"Model Size (in Billion Parameters)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Model Size vs Accuracy\"}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"middle\", \"dx\": 7, \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"text\": {\"field\": \"model_name\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_size_in_b\", \"title\": \"Model Size (in Billion Parameters)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Model Size vs Accuracy\"}], \"data\": {\"name\": \"data-30a16b1b8a4249de23cf238f4f43805b\"}, \"height\": 400, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-30a16b1b8a4249de23cf238f4f43805b\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\", \"model_size_bucket\": \"100B+\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLLM 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLLM 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\", \"model_size_bucket\": \"0-10B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scatter plot of model size vs accuracy with model names as labels\n",
    "scatter_plot = alt.Chart(detection_stats_df).mark_circle().encode(\n",
    "    x=alt.X('model_size_in_b:Q', title='Model Size (in Billion Parameters)'),\n",
    "    y=alt.Y('accuracy:Q', title='Accuracy'),\n",
    "    color=alt.Color('model_type:N', title='Model Type')\n",
    ").properties(\n",
    "    title='Model Size vs Accuracy',\n",
    "    width=800,  # Set the width to 800 pixels\n",
    "    height=400  # Set the height to 400 pixels\n",
    ")\n",
    "\n",
    "text = scatter_plot.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=7,  # Adjust the position of the text\n",
    "    dy=-5,  # Adjust the vertical position of the text\n",
    ").encode(\n",
    "    text='model_name:N'\n",
    ")\n",
    "\n",
    "scatter_plot + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCT Trial Result Interpretation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benefit_answer_mean_diff</th>\n",
       "      <th>rigor_answer_mean_diff</th>\n",
       "      <th>importance_answer_mean_diff</th>\n",
       "      <th>full_text_answer_mean_diff</th>\n",
       "      <th>another_trial_answer_mean_diff</th>\n",
       "      <th>overall_mean_diff_avg</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size_in_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.566667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.113333</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>1.433333</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>2.753333</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>2.253333</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>claude_3.5-sonnet</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.966667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.373333</td>\n",
       "      <td>claude_3.5-haiku</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.051724</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alpacare-7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.167143</td>\n",
       "      <td>biomistral7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>llama2_chat-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.933333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>2.186667</td>\n",
       "      <td>llama2_chat-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.689655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>1.004598</td>\n",
       "      <td>llama2_chat-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>llama3_instruct-8B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>llama3_instruct-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1.913333</td>\n",
       "      <td>med42-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>med42-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.233333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.013333</td>\n",
       "      <td>olmo2_instruct-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.486667</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.736842</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.592593</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.546744</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>2.204444</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.633333</td>\n",
       "      <td>2.293333</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.240741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    benefit_answer_mean_diff  rigor_answer_mean_diff  \\\n",
       "0                   3.133333                0.100000   \n",
       "1                   3.566667                1.466667   \n",
       "2                   3.900000                1.433333   \n",
       "3                   2.500000               -0.100000   \n",
       "4                   3.066667               -0.100000   \n",
       "5                   2.500000               -0.166667   \n",
       "6                   2.966667               -0.033333   \n",
       "7                   6.051724                0.266667   \n",
       "8                   1.666667                0.350000   \n",
       "9                   3.500000                0.500000   \n",
       "10                  2.933333                0.833333   \n",
       "11                  2.689655                0.000000   \n",
       "12                  2.200000                0.166667   \n",
       "13                  4.400000               -0.033333   \n",
       "14                  2.966667                0.333333   \n",
       "15                  4.833333                0.000000   \n",
       "16                  3.233333                0.466667   \n",
       "17                  6.000000                0.400000   \n",
       "18                  2.736842                0.214286   \n",
       "19                  4.400000                0.000000   \n",
       "20                  3.900000                0.000000   \n",
       "21                  1.240741                0.000000   \n",
       "\n",
       "    importance_answer_mean_diff  full_text_answer_mean_diff  \\\n",
       "0                      1.233333                    2.866667   \n",
       "1                      2.733333                    3.933333   \n",
       "2                      2.066667                    2.600000   \n",
       "3                      2.166667                    3.000000   \n",
       "4                      0.966667                    2.733333   \n",
       "5                     -0.633333                    3.233333   \n",
       "6                      0.466667                    1.300000   \n",
       "7                      0.800000                    0.000000   \n",
       "8                      1.116667                    1.035714   \n",
       "9                      1.066667                    0.333333   \n",
       "10                     2.033333                    2.366667   \n",
       "11                     0.666667                    0.633333   \n",
       "12                     0.900000                    1.500000   \n",
       "13                     0.966667                    3.400000   \n",
       "14                     1.600000                    1.633333   \n",
       "15                     1.366667                    4.366667   \n",
       "16                     1.366667                    2.300000   \n",
       "17                     2.233333                    5.466667   \n",
       "18                     1.592593                    2.440000   \n",
       "19                     0.633333                    1.055556   \n",
       "20                     2.466667                    2.466667   \n",
       "21                     0.000000                   -0.153846   \n",
       "\n",
       "    another_trial_answer_mean_diff  overall_mean_diff_avg  \\\n",
       "0                         3.333333               2.133333   \n",
       "1                         3.866667               3.113333   \n",
       "2                         3.766667               2.753333   \n",
       "3                         3.700000               2.253333   \n",
       "4                         3.433333               2.020000   \n",
       "5                         2.866667               1.560000   \n",
       "6                         2.166667               1.373333   \n",
       "7                              NaN                    NaN   \n",
       "8                         1.666667               1.167143   \n",
       "9                         1.700000               1.420000   \n",
       "10                        2.766667               2.186667   \n",
       "11                        1.033333               1.004598   \n",
       "12                        2.733333               1.500000   \n",
       "13                        4.066667               2.560000   \n",
       "14                        3.033333               1.913333   \n",
       "15                        4.766667               3.066667   \n",
       "16                        2.700000               2.013333   \n",
       "17                        3.333333               3.486667   \n",
       "18                        0.750000               1.546744   \n",
       "19                        4.933333               2.204444   \n",
       "20                        2.633333               2.293333   \n",
       "21                             NaN                    NaN   \n",
       "\n",
       "             model_name         model_type  model_size_in_b  \n",
       "0                 gpt4o  generalist closed              NaN  \n",
       "1            gpt4o-mini  generalist closed              NaN  \n",
       "2                 gpt35  generalist closed            175.0  \n",
       "3      gemini_1.5_flash  generalist closed              NaN  \n",
       "4   gemini_1.5_flash-8B  generalist closed              8.0  \n",
       "5     claude_3.5-sonnet  generalist closed              NaN  \n",
       "6      claude_3.5-haiku  generalist closed              NaN  \n",
       "7           alpacare-7B    biomedical open              7.0  \n",
       "8          biomistral7B    biomedical open              7.0  \n",
       "9        llama2_chat-7B    generalist open              7.0  \n",
       "10      llama2_chat-13B    generalist open             13.0  \n",
       "11      llama2_chat-70B    generalist open             70.0  \n",
       "12   llama3_instruct-8B    generalist open              8.0  \n",
       "13  llama3_instruct-70B    generalist open             70.0  \n",
       "14             med42-8B    biomedical open              8.0  \n",
       "15            med42-70B    biomedical open             70.0  \n",
       "16    olmo2_instruct-7B    generalist open              7.0  \n",
       "17   olmo2_instruct-13B    generalist open             13.0  \n",
       "18        openbiollm-8B    biomedical open              8.0  \n",
       "19       openbiollm-70B    biomedical open             70.0  \n",
       "20   mistral_instruct7B    generalist open              7.0  \n",
       "21          biomedgpt7B    biomedical open              7.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# interpretation_overall_metrics.json was manually created\n",
    "interpretation_stats_df = pd.read_json(\"./eval_outputs/interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "interpretation_stats_df[\"model_name\"] = interpretation_stats_df.index\n",
    "interpretation_stats_df[\"model_type\"] = interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "interpretation_stats_df[\"model_size_in_b\"] = interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(interpretation_stats_df)}\")\n",
    "\n",
    "interpretation_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.35</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.59</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.19</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.47</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.31</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric         method\n",
       "0       0.71      0.07      1.35        benefit_answer  human experts\n",
       "1      -0.59     -1.13     -0.05          rigor_answer  human experts\n",
       "2      -0.38     -0.95      0.19     importance_answer  human experts\n",
       "3       0.77      0.08      1.47      full_text_answer  human experts\n",
       "4       0.64     -0.03      1.31  another_trial_answer  human experts"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_expert_stats = {\n",
    "        \"benefit_answer\": {\"mean_diff\": 0.71, \"ci_lower\": 0.07, \"ci_upper\": 1.35},\n",
    "        \"rigor_answer\": {\"mean_diff\": -0.59, \"ci_lower\": -1.13, \"ci_upper\": -0.05},\n",
    "        \"importance_answer\": {\"mean_diff\": -0.38, \"ci_lower\": -0.95, \"ci_upper\": 0.19},\n",
    "        \"full_text_answer\": {\"mean_diff\": 0.77, \"ci_lower\": 0.08, \"ci_upper\": 1.47},\n",
    "        \"another_trial_answer\": {\"mean_diff\": 0.64, \"ci_lower\": -0.03, \"ci_upper\": 1.31}\n",
    "    }\n",
    "\n",
    "human_expert_stats_df = pd.DataFrame(human_expert_stats).T\n",
    "human_expert_stats_df[\"metric\"] = human_expert_stats_df.index\n",
    "# remove index\n",
    "human_expert_stats_df.reset_index(drop=True, inplace=True)\n",
    "human_expert_stats_df[\"method\"] = \"human experts\"\n",
    "\n",
    "human_expert_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_interval(df, df_column_name):\n",
    "    mean_diff = df[df_column_name].mean()  # Calculate the mean\n",
    "    std_dev = df[df_column_name].std()  # Calculate the standard deviation\n",
    "    n = len(df[df_column_name])  # Sample size\n",
    "\n",
    "    # Calculate the margin of error for 95% CI (z = 1.96)\n",
    "    z = 1.96\n",
    "    margin_of_error = z * (std_dev / sqrt(n))\n",
    "\n",
    "    # Calculate the 95% Confidence Interval\n",
    "    ci_lower = mean_diff - margin_of_error\n",
    "    ci_upper = mean_diff + margin_of_error\n",
    "\n",
    "    return ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_stats(interpretation_stats_df, method_name = \"all LLMs\"):\n",
    "    # calculate the average of all model metrics and calculate 95% CI\n",
    "    average_model_benefit = interpretation_stats_df[\"benefit_answer_mean_diff\"].mean()\n",
    "    ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(interpretation_stats_df, \"benefit_answer_mean_diff\")\n",
    "\n",
    "    average_model_rigor = interpretation_stats_df[\"rigor_answer_mean_diff\"].mean()\n",
    "    ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(interpretation_stats_df, \"rigor_answer_mean_diff\")\n",
    "\n",
    "    average_model_importance = interpretation_stats_df[\"importance_answer_mean_diff\"].mean()\n",
    "    ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(interpretation_stats_df, \"importance_answer_mean_diff\")\n",
    "\n",
    "    average_model_full_text = interpretation_stats_df[\"full_text_answer_mean_diff\"].mean()\n",
    "    ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(interpretation_stats_df, \"full_text_answer_mean_diff\")\n",
    "\n",
    "    average_model_another_trial = interpretation_stats_df[\"another_trial_answer_mean_diff\"].mean()\n",
    "    ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(interpretation_stats_df, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "    model_stats = {\n",
    "        \"benefit_answer\": {\"mean_diff\": average_model_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "        \"rigor_answer\": {\"mean_diff\": average_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "        \"importance_answer\": {\"mean_diff\": average_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "        \"full_text_answer\": {\"mean_diff\": average_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "        \"another_trial_answer\": {\"mean_diff\": average_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "    }\n",
    "\n",
    "    model_stats_df = pd.DataFrame(model_stats).T\n",
    "    model_stats_df[\"metric\"] = model_stats_df.index\n",
    "    # remove index\n",
    "    model_stats_df.reset_index(drop=True, inplace=True)\n",
    "    model_stats_df[\"method\"] = method_name\n",
    "\n",
    "    return model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.381165</td>\n",
       "      <td>2.874680</td>\n",
       "      <td>3.887650</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277165</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.264057</td>\n",
       "      <td>0.922720</td>\n",
       "      <td>1.605395</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.205034</td>\n",
       "      <td>1.605838</td>\n",
       "      <td>2.804230</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.962500</td>\n",
       "      <td>2.496102</td>\n",
       "      <td>3.428898</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric    method\n",
       "0   3.381165  2.874680  3.887650        benefit_answer  all LLMs\n",
       "1   0.277165  0.088599  0.465730          rigor_answer  all LLMs\n",
       "2   1.264057  0.922720  1.605395     importance_answer  all LLMs\n",
       "3   2.205034  1.605838  2.804230      full_text_answer  all LLMs\n",
       "4   2.962500  2.496102  3.428898  another_trial_answer  all LLMs"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "model_stats_df = calculate_model_stats(interpretation_stats_df)\n",
    "\n",
    "model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average and 95% CI by model_type from interpretation_stats_df for each model_type\n",
    "interpretation_stats_df[\"model_type\"] = interpretation_stats_df[\"model_name\"].map(lambda x: model_metadata[x][\"model_type\"])\n",
    "\n",
    "# get only generalist closed  models\n",
    "generalist_closed_model_stats = interpretation_stats_df[interpretation_stats_df[\"model_type\"] == \"generalist closed\"]\n",
    "\n",
    "# get only generalist open models\n",
    "generalist_open_model_stats = interpretation_stats_df[interpretation_stats_df[\"model_type\"] == \"generalist open\"]\n",
    "\n",
    "# get only biomedical open models\n",
    "biomedical_open_model_stats = interpretation_stats_df[interpretation_stats_df[\"model_type\"] == \"biomedical open\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalist_closed_model_stats_df = calculate_model_stats(generalist_closed_model_stats, method_name = \"generalist closed\")\n",
    "\n",
    "generalist_open_model_stats_df = calculate_model_stats(generalist_open_model_stats, method_name = \"generalist open\")\n",
    "\n",
    "biomedical_open_model_stats_df = calculate_model_stats(biomedical_open_model_stats, method_name = \"biomedical open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.090476</td>\n",
       "      <td>2.708265</td>\n",
       "      <td>3.472687</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371429</td>\n",
       "      <td>-0.177865</td>\n",
       "      <td>0.920723</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.433531</td>\n",
       "      <td>2.137898</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.809524</td>\n",
       "      <td>2.219158</td>\n",
       "      <td>3.399889</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.304762</td>\n",
       "      <td>2.857216</td>\n",
       "      <td>3.752308</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric             method\n",
       "0   3.090476  2.708265  3.472687        benefit_answer  generalist closed\n",
       "1   0.371429 -0.177865  0.920723          rigor_answer  generalist closed\n",
       "2   1.285714  0.433531  2.137898     importance_answer  generalist closed\n",
       "3   2.809524  2.219158  3.399889      full_text_answer  generalist closed\n",
       "4   3.304762  2.857216  3.752308  another_trial_answer  generalist closed"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalist_closed_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.607040</td>\n",
       "      <td>2.784306</td>\n",
       "      <td>4.429774</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.077190</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.987437</td>\n",
       "      <td>1.937563</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.308333</td>\n",
       "      <td>1.180117</td>\n",
       "      <td>3.436550</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.620833</td>\n",
       "      <td>1.978924</td>\n",
       "      <td>3.262743</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric           method\n",
       "0   3.607040  2.784306  4.429774        benefit_answer  generalist open\n",
       "1   0.291667  0.077190  0.506143          rigor_answer  generalist open\n",
       "2   1.462500  0.987437  1.937563     importance_answer  generalist open\n",
       "3   2.308333  1.180117  3.436550      full_text_answer  generalist open\n",
       "4   2.620833  1.978924  3.262743  another_trial_answer  generalist open"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalist_open_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.413711</td>\n",
       "      <td>2.117145</td>\n",
       "      <td>4.710276</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166327</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.015608</td>\n",
       "      <td>0.584498</td>\n",
       "      <td>1.446719</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.482489</td>\n",
       "      <td>0.330245</td>\n",
       "      <td>2.634733</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.030000</td>\n",
       "      <td>1.659212</td>\n",
       "      <td>4.400788</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric           method\n",
       "0   3.413711  2.117145  4.710276        benefit_answer  biomedical open\n",
       "1   0.166327  0.046496  0.286157          rigor_answer  biomedical open\n",
       "2   1.015608  0.584498  1.446719     importance_answer  biomedical open\n",
       "3   1.482489  0.330245  2.634733      full_text_answer  biomedical open\n",
       "4   3.030000  1.659212  4.400788  another_trial_answer  biomedical open"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biomedical_open_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.090476</td>\n",
       "      <td>2.708265</td>\n",
       "      <td>3.472687</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371429</td>\n",
       "      <td>-0.177865</td>\n",
       "      <td>0.920723</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.433531</td>\n",
       "      <td>2.137898</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.809524</td>\n",
       "      <td>2.219158</td>\n",
       "      <td>3.399889</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.304762</td>\n",
       "      <td>2.857216</td>\n",
       "      <td>3.752308</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.607040</td>\n",
       "      <td>2.784306</td>\n",
       "      <td>4.429774</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.077190</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.987437</td>\n",
       "      <td>1.937563</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.308333</td>\n",
       "      <td>1.180117</td>\n",
       "      <td>3.436550</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.620833</td>\n",
       "      <td>1.978924</td>\n",
       "      <td>3.262743</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.413711</td>\n",
       "      <td>2.117145</td>\n",
       "      <td>4.710276</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.166327</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.015608</td>\n",
       "      <td>0.584498</td>\n",
       "      <td>1.446719</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.482489</td>\n",
       "      <td>0.330245</td>\n",
       "      <td>2.634733</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.030000</td>\n",
       "      <td>1.659212</td>\n",
       "      <td>4.400788</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_diff  ci_lower  ci_upper                metric             method\n",
       "0    3.090476  2.708265  3.472687        benefit_answer  generalist closed\n",
       "1    0.371429 -0.177865  0.920723          rigor_answer  generalist closed\n",
       "2    1.285714  0.433531  2.137898     importance_answer  generalist closed\n",
       "3    2.809524  2.219158  3.399889      full_text_answer  generalist closed\n",
       "4    3.304762  2.857216  3.752308  another_trial_answer  generalist closed\n",
       "5    3.607040  2.784306  4.429774        benefit_answer    generalist open\n",
       "6    0.291667  0.077190  0.506143          rigor_answer    generalist open\n",
       "7    1.462500  0.987437  1.937563     importance_answer    generalist open\n",
       "8    2.308333  1.180117  3.436550      full_text_answer    generalist open\n",
       "9    2.620833  1.978924  3.262743  another_trial_answer    generalist open\n",
       "10   3.413711  2.117145  4.710276        benefit_answer    biomedical open\n",
       "11   0.166327  0.046496  0.286157          rigor_answer    biomedical open\n",
       "12   1.015608  0.584498  1.446719     importance_answer    biomedical open\n",
       "13   1.482489  0.330245  2.634733      full_text_answer    biomedical open\n",
       "14   3.030000  1.659212  4.400788  another_trial_answer    biomedical open"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_by_model_type = pd.concat([generalist_closed_model_stats_df, generalist_open_model_stats_df, biomedical_open_model_stats_df], ignore_index=True)\n",
    "\n",
    "average_by_model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>benefit</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-1.130000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>rigor</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.380000</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>importance</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>full_text</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.381165</td>\n",
       "      <td>2.874680</td>\n",
       "      <td>3.887650</td>\n",
       "      <td>benefit</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277165</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>rigor</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264057</td>\n",
       "      <td>0.922720</td>\n",
       "      <td>1.605395</td>\n",
       "      <td>importance</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.205034</td>\n",
       "      <td>1.605838</td>\n",
       "      <td>2.804230</td>\n",
       "      <td>full_text</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.962500</td>\n",
       "      <td>2.496102</td>\n",
       "      <td>3.428898</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.090476</td>\n",
       "      <td>2.708265</td>\n",
       "      <td>3.472687</td>\n",
       "      <td>benefit</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.371429</td>\n",
       "      <td>-0.177865</td>\n",
       "      <td>0.920723</td>\n",
       "      <td>rigor</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.433531</td>\n",
       "      <td>2.137898</td>\n",
       "      <td>importance</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.809524</td>\n",
       "      <td>2.219158</td>\n",
       "      <td>3.399889</td>\n",
       "      <td>full_text</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.304762</td>\n",
       "      <td>2.857216</td>\n",
       "      <td>3.752308</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.607040</td>\n",
       "      <td>2.784306</td>\n",
       "      <td>4.429774</td>\n",
       "      <td>benefit</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.077190</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>rigor</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.987437</td>\n",
       "      <td>1.937563</td>\n",
       "      <td>importance</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.308333</td>\n",
       "      <td>1.180117</td>\n",
       "      <td>3.436550</td>\n",
       "      <td>full_text</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.620833</td>\n",
       "      <td>1.978924</td>\n",
       "      <td>3.262743</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.413711</td>\n",
       "      <td>2.117145</td>\n",
       "      <td>4.710276</td>\n",
       "      <td>benefit</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.166327</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>rigor</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.015608</td>\n",
       "      <td>0.584498</td>\n",
       "      <td>1.446719</td>\n",
       "      <td>importance</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.482489</td>\n",
       "      <td>0.330245</td>\n",
       "      <td>2.634733</td>\n",
       "      <td>full_text</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.030000</td>\n",
       "      <td>1.659212</td>\n",
       "      <td>4.400788</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_diff  ci_lower  ci_upper         metric             method\n",
       "0    0.710000  0.070000  1.350000        benefit      human experts\n",
       "1   -0.590000 -1.130000 -0.050000          rigor      human experts\n",
       "2   -0.380000 -0.950000  0.190000     importance      human experts\n",
       "3    0.770000  0.080000  1.470000      full_text      human experts\n",
       "4    0.640000 -0.030000  1.310000  another_trial      human experts\n",
       "5    3.381165  2.874680  3.887650        benefit           all LLMs\n",
       "6    0.277165  0.088599  0.465730          rigor           all LLMs\n",
       "7    1.264057  0.922720  1.605395     importance           all LLMs\n",
       "8    2.205034  1.605838  2.804230      full_text           all LLMs\n",
       "9    2.962500  2.496102  3.428898  another_trial           all LLMs\n",
       "10   3.090476  2.708265  3.472687        benefit  generalist closed\n",
       "11   0.371429 -0.177865  0.920723          rigor  generalist closed\n",
       "12   1.285714  0.433531  2.137898     importance  generalist closed\n",
       "13   2.809524  2.219158  3.399889      full_text  generalist closed\n",
       "14   3.304762  2.857216  3.752308  another_trial  generalist closed\n",
       "15   3.607040  2.784306  4.429774        benefit    generalist open\n",
       "16   0.291667  0.077190  0.506143          rigor    generalist open\n",
       "17   1.462500  0.987437  1.937563     importance    generalist open\n",
       "18   2.308333  1.180117  3.436550      full_text    generalist open\n",
       "19   2.620833  1.978924  3.262743  another_trial    generalist open\n",
       "20   3.413711  2.117145  4.710276        benefit    biomedical open\n",
       "21   0.166327  0.046496  0.286157          rigor    biomedical open\n",
       "22   1.015608  0.584498  1.446719     importance    biomedical open\n",
       "23   1.482489  0.330245  2.634733      full_text    biomedical open\n",
       "24   3.030000  1.659212  4.400788  another_trial    biomedical open"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine all the dataframes\n",
    "model_stats_final_df = pd.concat([human_expert_stats_df, model_stats_df, average_by_model_type], ignore_index=True)\n",
    "#drop \"_answer\" from the values in metric column\n",
    "model_stats_final_df['metric'] = model_stats_final_df['metric'].str.replace('_answer', '')\n",
    "\n",
    "model_stats_final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-753f9f4ef9354fe9a119c14ffd1e3975.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-753f9f4ef9354fe9a119c14ffd1e3975.vega-embed details,\n",
       "  #altair-viz-753f9f4ef9354fe9a119c14ffd1e3975.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-753f9f4ef9354fe9a119c14ffd1e3975\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-753f9f4ef9354fe9a119c14ffd1e3975\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-753f9f4ef9354fe9a119c14ffd1e3975\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"data\": {\"name\": \"data-a1f1a0b8c0eb40a458b114e64a169a30\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"Treatment Benefit\", \"Study Rigor\", \"Study Importance\", \"Interest to Read Full-Text\", \"Interest to Run Another Trial\"], \"title\": null, \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"method\", \"legend\": null, \"scale\": {\"domain\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"range\": [\"#0868ac\", \"#43a2ca\", \"#7bccc4\", \"#bae4bc\", \"#E3F4D4\"]}, \"title\": \"Method\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"value\": \"gray\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"method\", \"sort\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_lower\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_upper\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": {\"expr\": \"if((datum.mean_diff >= 0),-1,20)\"}, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"mean_diff\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 300}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-a1f1a0b8c0eb40a458b114e64a169a30\": [{\"mean_diff\": 0.71, \"ci_lower\": 0.07, \"ci_upper\": 1.35, \"metric\": \"Treatment Benefit\", \"method\": \"human experts\"}, {\"mean_diff\": -0.59, \"ci_lower\": -1.13, \"ci_upper\": -0.05, \"metric\": \"Study Rigor\", \"method\": \"human experts\"}, {\"mean_diff\": -0.38, \"ci_lower\": -0.95, \"ci_upper\": 0.19, \"metric\": \"Study Importance\", \"method\": \"human experts\"}, {\"mean_diff\": 0.77, \"ci_lower\": 0.08, \"ci_upper\": 1.47, \"metric\": \"Interest to Read Full-Text\", \"method\": \"human experts\"}, {\"mean_diff\": 0.64, \"ci_lower\": -0.03, \"ci_upper\": 1.31, \"metric\": \"Interest to Run Another Trial\", \"method\": \"human experts\"}, {\"mean_diff\": 3.3811649465006997, \"ci_lower\": 2.874679552619501, \"ci_upper\": 3.8876503403818985, \"metric\": \"Treatment Benefit\", \"method\": \"all LLMs\"}, {\"mean_diff\": 0.27716450216450217, \"ci_lower\": 0.08859924356867477, \"ci_upper\": 0.46572976076032957, \"metric\": \"Study Rigor\", \"method\": \"all LLMs\"}, {\"mean_diff\": 1.2640572390572389, \"ci_lower\": 0.9227199205664216, \"ci_upper\": 1.6053945575480562, \"metric\": \"Study Importance\", \"method\": \"all LLMs\"}, {\"mean_diff\": 2.20503441003441, \"ci_lower\": 1.6058384463942166, \"ci_upper\": 2.8042303736746033, \"metric\": \"Interest to Read Full-Text\", \"method\": \"all LLMs\"}, {\"mean_diff\": 2.9625000000000004, \"ci_lower\": 2.4961024839163084, \"ci_upper\": 3.4288975160836923, \"metric\": \"Interest to Run Another Trial\", \"method\": \"all LLMs\"}, {\"mean_diff\": 3.0904761904761906, \"ci_lower\": 2.7082650795265826, \"ci_upper\": 3.4726873014257986, \"metric\": \"Treatment Benefit\", \"method\": \"generalist closed\"}, {\"mean_diff\": 0.3714285714285714, \"ci_lower\": -0.1778653861677703, \"ci_upper\": 0.920722529024913, \"metric\": \"Study Rigor\", \"method\": \"generalist closed\"}, {\"mean_diff\": 1.2857142857142858, \"ci_lower\": 0.43353103294743167, \"ci_upper\": 2.13789753848114, \"metric\": \"Study Importance\", \"method\": \"generalist closed\"}, {\"mean_diff\": 2.8095238095238093, \"ci_lower\": 2.219158197758053, \"ci_upper\": 3.399889421289566, \"metric\": \"Interest to Read Full-Text\", \"method\": \"generalist closed\"}, {\"mean_diff\": 3.3047619047619046, \"ci_lower\": 2.8572158384385804, \"ci_upper\": 3.7523079710852287, \"metric\": \"Interest to Run Another Trial\", \"method\": \"generalist closed\"}, {\"mean_diff\": 3.6070402298850572, \"ci_lower\": 2.784306191956595, \"ci_upper\": 4.429774267813519, \"metric\": \"Treatment Benefit\", \"method\": \"generalist open\"}, {\"mean_diff\": 0.2916666666666665, \"ci_lower\": 0.07719030174243752, \"ci_upper\": 0.5061430315908955, \"metric\": \"Study Rigor\", \"method\": \"generalist open\"}, {\"mean_diff\": 1.4624999999999997, \"ci_lower\": 0.9874374017855936, \"ci_upper\": 1.9375625982144058, \"metric\": \"Study Importance\", \"method\": \"generalist open\"}, {\"mean_diff\": 2.308333333333333, \"ci_lower\": 1.180116598835923, \"ci_upper\": 3.4365500678307432, \"metric\": \"Interest to Read Full-Text\", \"method\": \"generalist open\"}, {\"mean_diff\": 2.620833333333333, \"ci_lower\": 1.978923833827713, \"ci_upper\": 3.262742832838953, \"metric\": \"Interest to Run Another Trial\", \"method\": \"generalist open\"}, {\"mean_diff\": 3.413710521514514, \"ci_lower\": 2.1171452602579586, \"ci_upper\": 4.710275782771069, \"metric\": \"Treatment Benefit\", \"method\": \"biomedical open\"}, {\"mean_diff\": 0.16632653061224487, \"ci_lower\": 0.04649640393594007, \"ci_upper\": 0.28615665728854967, \"metric\": \"Study Rigor\", \"method\": \"biomedical open\"}, {\"mean_diff\": 1.0156084656084654, \"ci_lower\": 0.584497500863677, \"ci_upper\": 1.4467194303532538, \"metric\": \"Study Importance\", \"method\": \"biomedical open\"}, {\"mean_diff\": 1.4824890982033836, \"ci_lower\": 0.33024482377653785, \"ci_upper\": 2.6347333726302296, \"metric\": \"Interest to Read Full-Text\", \"method\": \"biomedical open\"}, {\"mean_diff\": 3.0300000000000002, \"ci_lower\": 1.6592116461279987, \"ci_upper\": 4.400788353872002, \"metric\": \"Interest to Run Another Trial\", \"method\": \"biomedical open\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping for custom facet titles\n",
    "facet_title_mapping = {\n",
    "    'benefit': 'Treatment Benefit',\n",
    "    'rigor': 'Study Rigor',\n",
    "    'importance': 'Study Importance',\n",
    "    'full_text': 'Interest to Read Full-Text',\n",
    "    'another_trial': 'Interest to Run Another Trial'\n",
    "}\n",
    "\n",
    "# Define the desired order for the facets\n",
    "facet_order = ['Treatment Benefit', 'Study Rigor', 'Study Importance', 'Interest to Read Full-Text', 'Interest to Run Another Trial']\n",
    "\n",
    "color_mapping = {\n",
    "    'human experts': '#0868ac', \n",
    "    'all LLMs': '#43a2ca',  \n",
    "    'generalist closed': '#7bccc4',  \n",
    "    'generalist open': '#bae4bc',  \n",
    "    'biomedical open': '#E3F4D4'\n",
    "}\n",
    "\n",
    "method_order = ['human experts', 'all LLMs', 'generalist closed', 'generalist open', 'biomedical open']\n",
    "\n",
    "# Apply the mapping as a calculated field\n",
    "chart_data = model_stats_final_df.copy()\n",
    "chart_data['metric'] = chart_data['metric'].map(facet_title_mapping)\n",
    "\n",
    "# Configure global font sizes\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Facet headers\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "bars = alt.Chart(chart_data).mark_bar().encode(\n",
    "    x=alt.X('method:N', title=None, axis=alt.Axis(labelAngle=-45), sort=method_order),\n",
    "    y=alt.Y('mean_diff:Q', title='Mean Difference'),\n",
    "    color=alt.Color('method:N', title='Method', legend=None, scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())))\n",
    ").properties(\n",
    "    width=300,  # Set the width to 300 pixels\n",
    "    height=300  # Set the height to 300 pixels\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "error_bars = alt.Chart(chart_data).mark_errorbar().encode(\n",
    "    alt.X(\"method:N\", sort=method_order),\n",
    "    alt.Y(\"ci_lower:Q\").title(\"Mean Difference\"),\n",
    "    alt.Y2(\"ci_upper:Q\"),\n",
    "    strokeWidth=alt.value(2),\n",
    "    color=alt.value('gray')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontWeight='bold',\n",
    "    dy=alt.expr(expr=alt.expr.if_(alt.datum.mean_diff >= 0, -1, 20))  # Adjust the position of the text    \n",
    ").encode(\n",
    "    text=alt.Text('mean_diff:Q', format='.2f'),\n",
    "    color=alt.value('black')  # Set text color to black\n",
    ")\n",
    "\n",
    "# Combine layers and facet\n",
    "chart = alt.layer(bars, error_bars, text, data=chart_data).facet(\n",
    "    column=alt.Column('metric:N', title=None, sort=facet_order),\n",
    ").configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# save to html\n",
    "chart.save(\"./plots/interpretation_by_measures.html\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'full_text_answer' has some 'Error' or empty string values. Removing these rows...\n",
      "PMIDs with errors: [11261827, 12177098, 15947110, 16148021, 16314619, 17179098, 18794551, 20087643, 20530276, 21471562, 22112969, 9093724]\n",
      "Remaining rows after cleanup: 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>benefit</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.978884</td>\n",
       "      <td>3.021116</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rigor</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.302308</td>\n",
       "      <td>-0.031026</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>importance</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>-0.872616</td>\n",
       "      <td>-0.394051</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>full_text</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>2.679892</td>\n",
       "      <td>3.786775</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>another_trial</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>2.210635</td>\n",
       "      <td>3.522698</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>benefit</td>\n",
       "      <td>3.566667</td>\n",
       "      <td>2.989786</td>\n",
       "      <td>4.143547</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rigor</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>1.118410</td>\n",
       "      <td>1.814923</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>importance</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>2.283300</td>\n",
       "      <td>3.183367</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>full_text</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.402286</td>\n",
       "      <td>4.464381</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>another_trial</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.281804</td>\n",
       "      <td>4.451529</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>benefit</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>2.626554</td>\n",
       "      <td>3.506779</td>\n",
       "      <td>Gemini1.5 Flash 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rigor</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.272002</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>Gemini1.5 Flash 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>importance</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.692954</td>\n",
       "      <td>1.240379</td>\n",
       "      <td>Gemini1.5 Flash 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>full_text</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>2.177901</td>\n",
       "      <td>3.288766</td>\n",
       "      <td>Gemini1.5 Flash 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>another_trial</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>3.085711</td>\n",
       "      <td>3.780955</td>\n",
       "      <td>Gemini1.5 Flash 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>benefit</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>1.726382</td>\n",
       "      <td>2.673618</td>\n",
       "      <td>Llama3 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rigor</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.331681</td>\n",
       "      <td>Llama3 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>importance</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.612646</td>\n",
       "      <td>1.187354</td>\n",
       "      <td>Llama3 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>full_text</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.082367</td>\n",
       "      <td>1.917633</td>\n",
       "      <td>Llama3 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>another_trial</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>2.283300</td>\n",
       "      <td>3.183367</td>\n",
       "      <td>Llama3 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>benefit</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.718440</td>\n",
       "      <td>5.081560</td>\n",
       "      <td>Llama3 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rigor</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.098667</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>Llama3 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>importance</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.511268</td>\n",
       "      <td>1.422065</td>\n",
       "      <td>Llama3 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>full_text</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>2.847224</td>\n",
       "      <td>3.952776</td>\n",
       "      <td>Llama3 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>another_trial</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>3.321160</td>\n",
       "      <td>4.812174</td>\n",
       "      <td>Llama3 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>benefit</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>3.863438</td>\n",
       "      <td>4.936562</td>\n",
       "      <td>OpenBioLLM 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rigor</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>OpenBioLLM 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>importance</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.275694</td>\n",
       "      <td>0.990973</td>\n",
       "      <td>OpenBioLLM 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>full_text</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>0.225022</td>\n",
       "      <td>1.886089</td>\n",
       "      <td>OpenBioLLM 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>another_trial</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>4.377901</td>\n",
       "      <td>5.488766</td>\n",
       "      <td>OpenBioLLM 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>benefit</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rigor</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-1.130000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>importance</td>\n",
       "      <td>-0.380000</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>full_text</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>another_trial</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           metric  mean_diff  ci_lower  ci_upper              method\n",
       "0         benefit   2.500000  1.978884  3.021116   Claude 3.5 Sonnet\n",
       "1           rigor  -0.166667 -0.302308 -0.031026   Claude 3.5 Sonnet\n",
       "2      importance  -0.633333 -0.872616 -0.394051   Claude 3.5 Sonnet\n",
       "3       full_text   3.233333  2.679892  3.786775   Claude 3.5 Sonnet\n",
       "4   another_trial   2.866667  2.210635  3.522698   Claude 3.5 Sonnet\n",
       "5         benefit   3.566667  2.989786  4.143547          GPT4o Mini\n",
       "6           rigor   1.466667  1.118410  1.814923          GPT4o Mini\n",
       "7      importance   2.733333  2.283300  3.183367          GPT4o Mini\n",
       "8       full_text   3.933333  3.402286  4.464381          GPT4o Mini\n",
       "9   another_trial   3.866667  3.281804  4.451529          GPT4o Mini\n",
       "10        benefit   3.066667  2.626554  3.506779  Gemini1.5 Flash 8B\n",
       "11          rigor  -0.100000 -0.272002  0.072002  Gemini1.5 Flash 8B\n",
       "12     importance   0.966667  0.692954  1.240379  Gemini1.5 Flash 8B\n",
       "13      full_text   2.733333  2.177901  3.288766  Gemini1.5 Flash 8B\n",
       "14  another_trial   3.433333  3.085711  3.780955  Gemini1.5 Flash 8B\n",
       "15        benefit   2.200000  1.726382  2.673618           Llama3 8B\n",
       "16          rigor   0.166667  0.001652  0.331681           Llama3 8B\n",
       "17     importance   0.900000  0.612646  1.187354           Llama3 8B\n",
       "18      full_text   1.500000  1.082367  1.917633           Llama3 8B\n",
       "19  another_trial   2.733333  2.283300  3.183367           Llama3 8B\n",
       "20        benefit   4.400000  3.718440  5.081560          Llama3 70B\n",
       "21          rigor  -0.033333 -0.098667  0.032000          Llama3 70B\n",
       "22     importance   0.966667  0.511268  1.422065          Llama3 70B\n",
       "23      full_text   3.400000  2.847224  3.952776          Llama3 70B\n",
       "24  another_trial   4.066667  3.321160  4.812174          Llama3 70B\n",
       "25        benefit   4.400000  3.863438  4.936562      OpenBioLLM 70B\n",
       "26          rigor   0.000000  0.000000  0.000000      OpenBioLLM 70B\n",
       "27     importance   0.633333  0.275694  0.990973      OpenBioLLM 70B\n",
       "28      full_text   1.055556  0.225022  1.886089      OpenBioLLM 70B\n",
       "29  another_trial   4.933333  4.377901  5.488766      OpenBioLLM 70B\n",
       "30        benefit   0.710000  0.070000  1.350000       human experts\n",
       "31          rigor  -0.590000 -1.130000 -0.050000       human experts\n",
       "32     importance  -0.380000 -0.950000  0.190000       human experts\n",
       "33      full_text   0.770000  0.080000  1.470000       human experts\n",
       "34  another_trial   0.640000 -0.030000  1.310000       human experts"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same plot as above but for only top-6 spin detection accuracy models compare in regards to interpretation\n",
    "\n",
    "claude_sonnet_diff_data = \"eval_outputs/claude_3.5-sonnet/claude_3.5-sonnet_interpretation_outputs.json\"\n",
    "gpt4o_mini_diff_data = \"eval_outputs/gpt4o-mini/gpt4o-mini_interpretation_outputs.json\"\n",
    "gemini_flash_8b_diff_data = \"eval_outputs/gemini_1.5_flash-8B/gemini_1.5_flash-8B_interpretation_outputs.json\"\n",
    "llama3_8b_diff_data = \"eval_outputs/llama3_instruct-8B/llama3_instruct-8B_interpretation_outputs.json\"\n",
    "llama3_70b_diff_data = \"eval_outputs/llama3_instruct-70B/llama3_instruct-70B_interpretation_outputs.json\"\n",
    "openbiollm_70b_diff_data = \"eval_outputs/openbiollm-70B/openbiollm-70B_interpretation_outputs.json\"\n",
    "\n",
    "# read all the data\n",
    "claude_sonnet_data = pd.read_json(claude_sonnet_diff_data, orient=\"record\")\n",
    "gpt4o_mini_data = pd.read_json(gpt4o_mini_diff_data, orient=\"record\")\n",
    "gemini_flash_8b_data = pd.read_json(gemini_flash_8b_diff_data, orient=\"record\")\n",
    "llama3_8b_data = pd.read_json(llama3_8b_diff_data, orient=\"record\")\n",
    "llama3_70b_data = pd.read_json(llama3_70b_diff_data, orient=\"record\")\n",
    "openbiollm_70b_data = pd.read_json(openbiollm_70b_diff_data, orient=\"record\")\n",
    "\n",
    "def calculate_ci(data):\n",
    "    mean_diff = np.mean(data)  # Calculate the mean\n",
    "    std_dev = np.std(data, ddof=1)  # Use ddof=1 for sample standard deviation  # Calculate the standard deviation\n",
    "    n = len(data)  # Sample size\n",
    "\n",
    "    # Calculate the margin of error for 95% CI (z = 1.96)\n",
    "    z = 1.96\n",
    "    margin_of_error = z * (std_dev / sqrt(n))\n",
    "\n",
    "    # Calculate the 95% Confidence Interval\n",
    "    ci_lower = mean_diff - margin_of_error\n",
    "    ci_upper = mean_diff + margin_of_error\n",
    "\n",
    "    return ci_lower, ci_upper\n",
    "\n",
    "def get_metrics(df):\n",
    "    column_names = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\"]\n",
    "    \n",
    "    diff_metrics = []\n",
    "    \n",
    "    for col in column_names:\n",
    "        df_copy = df.copy()\n",
    "        \n",
    "        # Remove rows where the column has 'Error' or empty string\n",
    "        mask = df_copy[col].apply(lambda x: isinstance(x, str) and (\"Error\" in x or x == \"\"))\n",
    "        if mask.any():\n",
    "            error_pmids = df_copy.loc[mask, 'PMID'].unique().tolist()\n",
    "            print(f\"Column '{col}' has some 'Error' or empty string values. Removing these rows...\")\n",
    "            print(f\"PMIDs with errors: {error_pmids}\")\n",
    "            df_copy = df_copy[~df_copy['PMID'].isin(error_pmids)]\n",
    "            print(f\"Remaining rows after cleanup: {len(df_copy)}\")\n",
    "        \n",
    "        # Ensure the column is converted to numeric, coercing errors\n",
    "        df_copy[col] = pd.to_numeric(df_copy[col], errors='coerce')\n",
    "\n",
    "        # For each group by PMID, get the column values difference (abstract_type == spin minus abstract_type == non-spin)\n",
    "        grouped = df_copy.pivot_table(index='PMID', columns='abstract_type', values=col, aggfunc='mean')\n",
    "        diff = grouped['spin'] - grouped['no_spin']\n",
    "        diffs = diff.tolist()\n",
    "\n",
    "        # calculate confidence interval\n",
    "        ci_lower, ci_upper = calculate_ci(diffs)\n",
    "\n",
    "        diff_metrics.append({\n",
    "            \"metric\": col,\n",
    "            \"mean_diff\": diff.mean(),\n",
    "            \"ci_lower\": ci_lower,\n",
    "            \"ci_upper\": ci_upper\n",
    "        })\n",
    "\n",
    "    return diff_metrics\n",
    "\n",
    "\n",
    "# get metrics for each model\n",
    "# save to dataframe for each model\n",
    "model_data = {\n",
    "    \"Claude 3.5 Sonnet\": claude_sonnet_data,\n",
    "    \"GPT4o Mini\": gpt4o_mini_data,\n",
    "    \"Gemini1.5 Flash 8B\": gemini_flash_8b_data,\n",
    "    \"Llama3 8B\": llama3_8b_data,\n",
    "    \"Llama3 70B\": llama3_70b_data,\n",
    "    \"OpenBioLLM 70B\": openbiollm_70b_data\n",
    "}\n",
    "df_for_chart = pd.DataFrame()\n",
    "for model_name, df in model_data.items():\n",
    "    diff_metrics = get_metrics(df)\n",
    "    # create a dataframe\n",
    "    df_model = pd.DataFrame(diff_metrics)\n",
    "    df_model[\"method\"] = model_name\n",
    "    df_for_chart = pd.concat([df_for_chart, df_model], ignore_index=True)\n",
    "\n",
    "df_for_chart = pd.concat([df_for_chart, human_expert_stats_df], ignore_index=True)\n",
    "#drop \"_answer\" from the values in metric column\n",
    "df_for_chart['metric'] = df_for_chart['metric'].str.replace('_answer', '')\n",
    "\n",
    "df_for_chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-60a9ea5617564bd18729521ca4410cf9.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-60a9ea5617564bd18729521ca4410cf9.vega-embed details,\n",
       "  #altair-viz-60a9ea5617564bd18729521ca4410cf9.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-60a9ea5617564bd18729521ca4410cf9\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-60a9ea5617564bd18729521ca4410cf9\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-60a9ea5617564bd18729521ca4410cf9\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"data\": {\"name\": \"data-25f336350738877201292e0f05691aac\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"Treatment Benefit\", \"Study Rigor\", \"Study Importance\", \"Interest to Read Full-Text\", \"Interest to Run Another Trial\"], \"title\": null, \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"method\", \"legend\": null, \"scale\": {\"domain\": [\"human experts\", \"Claude 3.5 Sonnet\", \"GPT4o Mini\", \"Gemini1.5 Flash 8B\", \"Llama3 8B\", \"Llama3 70B\", \"OpenBioLLM 70B\"], \"range\": [\"#0868ac\", \"#43a2ca\", \"#7bccc4\", \"#bae4bc\", \"#E3F4D4\", \"#fdd49e\", \"#fdae61\"]}, \"title\": \"Method\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"Claude 3.5 Sonnet\", \"GPT4o Mini\", \"Gemini1.5 Flash 8B\", \"Llama3 8B\", \"Llama3 70B\", \"OpenBioLLM 70B\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"value\": \"gray\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"method\", \"sort\": [\"human experts\", \"Claude 3.5 Sonnet\", \"GPT4o Mini\", \"Gemini1.5 Flash 8B\", \"Llama3 8B\", \"Llama3 70B\", \"OpenBioLLM 70B\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_lower\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_upper\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": {\"expr\": \"if((datum.mean_diff >= 0),-1,22)\"}, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"mean_diff\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"Claude 3.5 Sonnet\", \"GPT4o Mini\", \"Gemini1.5 Flash 8B\", \"Llama3 8B\", \"Llama3 70B\", \"OpenBioLLM 70B\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 300}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-25f336350738877201292e0f05691aac\": [{\"metric\": \"Treatment Benefit\", \"mean_diff\": 2.5, \"ci_lower\": 1.9788844856364909, \"ci_upper\": 3.021115514363509, \"method\": \"Claude 3.5 Sonnet\"}, {\"metric\": \"Study Rigor\", \"mean_diff\": -0.16666666666666666, \"ci_lower\": -0.302307617094442, \"ci_upper\": -0.03102571623889136, \"method\": \"Claude 3.5 Sonnet\"}, {\"metric\": \"Study Importance\", \"mean_diff\": -0.6333333333333333, \"ci_lower\": -0.8726156574848281, \"ci_upper\": -0.3940510091818386, \"method\": \"Claude 3.5 Sonnet\"}, {\"metric\": \"Interest to Read Full-Text\", \"mean_diff\": 3.2333333333333334, \"ci_lower\": 2.6798916599622773, \"ci_upper\": 3.7867750067043895, \"method\": \"Claude 3.5 Sonnet\"}, {\"metric\": \"Interest to Run Another Trial\", \"mean_diff\": 2.8666666666666667, \"ci_lower\": 2.2106354553728966, \"ci_upper\": 3.5226978779604368, \"method\": \"Claude 3.5 Sonnet\"}, {\"metric\": \"Treatment Benefit\", \"mean_diff\": 3.566666666666667, \"ci_lower\": 2.989785848015879, \"ci_upper\": 4.1435474853174545, \"method\": \"GPT4o Mini\"}, {\"metric\": \"Study Rigor\", \"mean_diff\": 1.4666666666666666, \"ci_lower\": 1.1184100122894565, \"ci_upper\": 1.8149233210438767, \"method\": \"GPT4o Mini\"}, {\"metric\": \"Study Importance\", \"mean_diff\": 2.7333333333333334, \"ci_lower\": 2.283299635148502, \"ci_upper\": 3.1833670315181646, \"method\": \"GPT4o Mini\"}, {\"metric\": \"Interest to Read Full-Text\", \"mean_diff\": 3.933333333333333, \"ci_lower\": 3.4022855870691573, \"ci_upper\": 4.4643810795975085, \"method\": \"GPT4o Mini\"}, {\"metric\": \"Interest to Run Another Trial\", \"mean_diff\": 3.8666666666666667, \"ci_lower\": 3.2818040276535303, \"ci_upper\": 4.451529305679803, \"method\": \"GPT4o Mini\"}, {\"metric\": \"Treatment Benefit\", \"mean_diff\": 3.066666666666667, \"ci_lower\": 2.626554107047994, \"ci_upper\": 3.5067792262853397, \"method\": \"Gemini1.5 Flash 8B\"}, {\"metric\": \"Study Rigor\", \"mean_diff\": -0.1, \"ci_lower\": -0.2720021384523574, \"ci_upper\": 0.07200213845235737, \"method\": \"Gemini1.5 Flash 8B\"}, {\"metric\": \"Study Importance\", \"mean_diff\": 0.9666666666666667, \"ci_lower\": 0.6929541178367433, \"ci_upper\": 1.24037921549659, \"method\": \"Gemini1.5 Flash 8B\"}, {\"metric\": \"Interest to Read Full-Text\", \"mean_diff\": 2.7333333333333334, \"ci_lower\": 2.177900617412036, \"ci_upper\": 3.288766049254631, \"method\": \"Gemini1.5 Flash 8B\"}, {\"metric\": \"Interest to Run Another Trial\", \"mean_diff\": 3.433333333333333, \"ci_lower\": 3.0857112193940486, \"ci_upper\": 3.7809554472726177, \"method\": \"Gemini1.5 Flash 8B\"}, {\"metric\": \"Treatment Benefit\", \"mean_diff\": 2.2, \"ci_lower\": 1.7263818891316247, \"ci_upper\": 2.6736181108683756, \"method\": \"Llama3 8B\"}, {\"metric\": \"Study Rigor\", \"mean_diff\": 0.16666666666666666, \"ci_lower\": 0.0016523284994446885, \"ci_upper\": 0.3316810048338886, \"method\": \"Llama3 8B\"}, {\"metric\": \"Study Importance\", \"mean_diff\": 0.9, \"ci_lower\": 0.6126459990898326, \"ci_upper\": 1.1873540009101675, \"method\": \"Llama3 8B\"}, {\"metric\": \"Interest to Read Full-Text\", \"mean_diff\": 1.5, \"ci_lower\": 1.082366822122131, \"ci_upper\": 1.917633177877869, \"method\": \"Llama3 8B\"}, {\"metric\": \"Interest to Run Another Trial\", \"mean_diff\": 2.7333333333333334, \"ci_lower\": 2.283299635148502, \"ci_upper\": 3.1833670315181646, \"method\": \"Llama3 8B\"}, {\"metric\": \"Treatment Benefit\", \"mean_diff\": 4.4, \"ci_lower\": 3.7184396536277027, \"ci_upper\": 5.081560346372298, \"method\": \"Llama3 70B\"}, {\"metric\": \"Study Rigor\", \"mean_diff\": -0.03333333333333333, \"ci_lower\": -0.09866666666666665, \"ci_upper\": 0.03199999999999998, \"method\": \"Llama3 70B\"}, {\"metric\": \"Study Importance\", \"mean_diff\": 0.9666666666666667, \"ci_lower\": 0.5112684619005362, \"ci_upper\": 1.4220648714327973, \"method\": \"Llama3 70B\"}, {\"metric\": \"Interest to Read Full-Text\", \"mean_diff\": 3.4, \"ci_lower\": 2.84722360114922, \"ci_upper\": 3.95277639885078, \"method\": \"Llama3 70B\"}, {\"metric\": \"Interest to Run Another Trial\", \"mean_diff\": 4.066666666666666, \"ci_lower\": 3.321159521017103, \"ci_upper\": 4.81217381231623, \"method\": \"Llama3 70B\"}, {\"metric\": \"Treatment Benefit\", \"mean_diff\": 4.4, \"ci_lower\": 3.8634375913364742, \"ci_upper\": 4.9365624086635265, \"method\": \"OpenBioLLM 70B\"}, {\"metric\": \"Study Rigor\", \"mean_diff\": 0.0, \"ci_lower\": 0.0, \"ci_upper\": 0.0, \"method\": \"OpenBioLLM 70B\"}, {\"metric\": \"Study Importance\", \"mean_diff\": 0.6333333333333333, \"ci_lower\": 0.2756936465061165, \"ci_upper\": 0.9909730201605501, \"method\": \"OpenBioLLM 70B\"}, {\"metric\": \"Interest to Read Full-Text\", \"mean_diff\": 1.0555555555555556, \"ci_lower\": 0.22502187057452916, \"ci_upper\": 1.886089240536582, \"method\": \"OpenBioLLM 70B\"}, {\"metric\": \"Interest to Run Another Trial\", \"mean_diff\": 4.933333333333334, \"ci_lower\": 4.3779006174120365, \"ci_upper\": 5.488766049254631, \"method\": \"OpenBioLLM 70B\"}, {\"metric\": \"Treatment Benefit\", \"mean_diff\": 0.71, \"ci_lower\": 0.07, \"ci_upper\": 1.35, \"method\": \"human experts\"}, {\"metric\": \"Study Rigor\", \"mean_diff\": -0.59, \"ci_lower\": -1.13, \"ci_upper\": -0.05, \"method\": \"human experts\"}, {\"metric\": \"Study Importance\", \"mean_diff\": -0.38, \"ci_lower\": -0.95, \"ci_upper\": 0.19, \"method\": \"human experts\"}, {\"metric\": \"Interest to Read Full-Text\", \"mean_diff\": 0.77, \"ci_lower\": 0.08, \"ci_upper\": 1.47, \"method\": \"human experts\"}, {\"metric\": \"Interest to Run Another Trial\", \"mean_diff\": 0.64, \"ci_lower\": -0.03, \"ci_upper\": 1.31, \"method\": \"human experts\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping for custom facet titles\n",
    "facet_title_mapping = {\n",
    "    'benefit': 'Treatment Benefit',\n",
    "    'rigor': 'Study Rigor',\n",
    "    'importance': 'Study Importance',\n",
    "    'full_text': 'Interest to Read Full-Text',\n",
    "    'another_trial': 'Interest to Run Another Trial'\n",
    "}\n",
    "\n",
    "# Define the desired order for the facets\n",
    "facet_order = ['Treatment Benefit', 'Study Rigor', 'Study Importance', 'Interest to Read Full-Text', 'Interest to Run Another Trial']\n",
    "\n",
    "color_mapping = {\n",
    "    'human experts': '#0868ac', \n",
    "    'Claude 3.5 Sonnet': '#43a2ca',  \n",
    "    'GPT4o Mini': '#7bccc4',  \n",
    "    'Gemini1.5 Flash 8B': '#bae4bc',  \n",
    "    'Llama3 8B': '#E3F4D4',  \n",
    "    'Llama3 70B': '#fdd49e',  \n",
    "    'OpenBioLLM 70B': '#fdae61'\n",
    "}\n",
    "\n",
    "method_order = ['human experts', 'Claude 3.5 Sonnet', 'GPT4o Mini', 'Gemini1.5 Flash 8B', 'Llama3 8B', 'Llama3 70B', 'OpenBioLLM 70B']\n",
    "\n",
    "# Apply the mapping as a calculated field\n",
    "chart_data = df_for_chart.copy()\n",
    "chart_data['metric'] = chart_data['metric'].map(facet_title_mapping)\n",
    "\n",
    "# Configure global font sizes\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Facet headers\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "bars = alt.Chart(chart_data).mark_bar().encode(\n",
    "    x=alt.X('method:N', title=None, axis=alt.Axis(labelAngle=-45), sort=method_order),\n",
    "    y=alt.Y('mean_diff:Q', title='Mean Difference'),\n",
    "    color=alt.Color('method:N', title='Method', legend=None, scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())))\n",
    ").properties(\n",
    "    width=300,  # Set the width to 300 pixels\n",
    "    height=300  # Set the height to 300 pixels\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "error_bars = alt.Chart(chart_data).mark_errorbar().encode(\n",
    "    alt.X(\"method:N\", sort=method_order),\n",
    "    alt.Y(\"ci_lower:Q\").title(\"Mean Difference\"),\n",
    "    alt.Y2(\"ci_upper:Q\"),\n",
    "    strokeWidth=alt.value(2),\n",
    "    color=alt.value('gray')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontWeight='bold',\n",
    "    dy=alt.expr(expr=alt.expr.if_(alt.datum.mean_diff >= 0, -1, 22))  # Adjust the position of the text    \n",
    ").encode(\n",
    "    text=alt.Text('mean_diff:Q', format='.2f'),\n",
    "    color=alt.value('black')  # Set text color to black\n",
    ")\n",
    "\n",
    "# Combine layers and facet\n",
    "chart = alt.layer(bars, error_bars, text, data=chart_data).facet(\n",
    "    column=alt.Column('metric:N', title=None, sort=facet_order),\n",
    ").configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# save to html\n",
    "chart.save(\"./plots/top_6_models_interpretation_by_measures.html\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigation Strategies Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats_df['method'] = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_labelled_interpretation_overall_metrics.json was manually created\n",
    "gold_labelled_interpretation_stats_df = pd.read_json(\"./eval_outputs/gold_labelled_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "gold_labelled_interpretation_stats_df[\"model_name\"] = gold_labelled_interpretation_stats_df.index\n",
    "gold_labelled_interpretation_stats_df[\"model_type\"] = gold_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "gold_labelled_interpretation_stats_df[\"model_size_in_b\"] = gold_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "gold_labelled_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(gold_labelled_interpretation_stats_df)}\")\n",
    "\n",
    "gold_labelled_interpretation_stats_df.sort_index(inplace=True) # alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.939576</td>\n",
       "      <td>1.467239</td>\n",
       "      <td>2.411913</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.432680</td>\n",
       "      <td>-1.804166</td>\n",
       "      <td>-1.061195</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.446717</td>\n",
       "      <td>-0.918034</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287751</td>\n",
       "      <td>-0.257165</td>\n",
       "      <td>0.832668</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.094828</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>1.648284</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric        method\n",
       "0   1.939576  1.467239  2.411913        benefit_answer  + ref labels\n",
       "1  -1.432680 -1.804166 -1.061195          rigor_answer  + ref labels\n",
       "2  -0.446717 -0.918034  0.024599     importance_answer  + ref labels\n",
       "3   0.287751 -0.257165  0.832668      full_text_answer  + ref labels\n",
       "4   1.094828  0.541371  1.648284  another_trial_answer  + ref labels"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "gold_labelled_model_stats_df = calculate_model_stats(gold_labelled_interpretation_stats_df, method_name = \"+ ref labels\")\n",
    "gold_labelled_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_output_labelled_interpretation_overall_metrics.json was manually created\n",
    "model_output_labelled_interpretation_stats_df = pd.read_json(\"./eval_outputs/model_output_labelled_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "model_output_labelled_interpretation_stats_df[\"model_name\"] = model_output_labelled_interpretation_stats_df.index\n",
    "model_output_labelled_interpretation_stats_df[\"model_type\"] = model_output_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "model_output_labelled_interpretation_stats_df[\"model_size_in_b\"] = model_output_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "model_output_labelled_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(model_output_labelled_interpretation_stats_df)}\")\n",
    "\n",
    "model_output_labelled_interpretation_stats_df.sort_index(inplace=True) # alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.588531</td>\n",
       "      <td>2.070864</td>\n",
       "      <td>3.106198</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.251387</td>\n",
       "      <td>-0.426146</td>\n",
       "      <td>-0.076627</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.771471</td>\n",
       "      <td>0.488157</td>\n",
       "      <td>1.054785</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.357926</td>\n",
       "      <td>0.830169</td>\n",
       "      <td>1.885683</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.147018</td>\n",
       "      <td>1.642268</td>\n",
       "      <td>2.651768</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric          method\n",
       "0   2.588531  2.070864  3.106198        benefit_answer  + model labels\n",
       "1  -0.251387 -0.426146 -0.076627          rigor_answer  + model labels\n",
       "2   0.771471  0.488157  1.054785     importance_answer  + model labels\n",
       "3   1.357926  0.830169  1.885683      full_text_answer  + model labels\n",
       "4   2.147018  1.642268  2.651768  another_trial_answer  + model labels"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "model_output_labelled_model_stats_df = calculate_model_stats(model_output_labelled_interpretation_stats_df, method_name = \"+ model labels\")\n",
    "model_output_labelled_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_detection_interpretation_overall_metrics.json was manually created\n",
    "combined_interpretation_stats_df = pd.read_json(\"./eval_outputs/combined_detection_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "combined_interpretation_stats_df[\"model_name\"] = combined_interpretation_stats_df.index\n",
    "combined_interpretation_stats_df[\"model_type\"] = combined_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "combined_interpretation_stats_df[\"model_size_in_b\"] = combined_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "combined_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(combined_interpretation_stats_df)}\")\n",
    "\n",
    "combined_interpretation_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "# combined_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.140562</td>\n",
       "      <td>0.690811</td>\n",
       "      <td>1.590312</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.643669</td>\n",
       "      <td>-1.143978</td>\n",
       "      <td>-0.143359</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.673458</td>\n",
       "      <td>0.191343</td>\n",
       "      <td>1.155573</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.261905</td>\n",
       "      <td>-0.386231</td>\n",
       "      <td>0.910040</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.118410</td>\n",
       "      <td>0.642599</td>\n",
       "      <td>1.594220</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric              method\n",
       "0   1.140562  0.690811  1.590312        benefit_answer  detect + interpret\n",
       "1  -0.643669 -1.143978 -0.143359          rigor_answer  detect + interpret\n",
       "2   0.673458  0.191343  1.155573     importance_answer  detect + interpret\n",
       "3   0.261905 -0.386231  0.910040      full_text_answer  detect + interpret\n",
       "4   1.118410  0.642599  1.594220  another_trial_answer  detect + interpret"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "combined_interpretation_stats_df = calculate_model_stats(combined_interpretation_stats_df, method_name = \"detect + interpret\")\n",
    "combined_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-1.130000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.380000</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.381165</td>\n",
       "      <td>2.874680</td>\n",
       "      <td>3.887650</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277165</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264057</td>\n",
       "      <td>0.922720</td>\n",
       "      <td>1.605395</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.205034</td>\n",
       "      <td>1.605838</td>\n",
       "      <td>2.804230</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.962500</td>\n",
       "      <td>2.496102</td>\n",
       "      <td>3.428898</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.939576</td>\n",
       "      <td>1.467239</td>\n",
       "      <td>2.411913</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.432680</td>\n",
       "      <td>-1.804166</td>\n",
       "      <td>-1.061195</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.446717</td>\n",
       "      <td>-0.918034</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.287751</td>\n",
       "      <td>-0.257165</td>\n",
       "      <td>0.832668</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.094828</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>1.648284</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.588531</td>\n",
       "      <td>2.070864</td>\n",
       "      <td>3.106198</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.251387</td>\n",
       "      <td>-0.426146</td>\n",
       "      <td>-0.076627</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.771471</td>\n",
       "      <td>0.488157</td>\n",
       "      <td>1.054785</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.357926</td>\n",
       "      <td>0.830169</td>\n",
       "      <td>1.885683</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.147018</td>\n",
       "      <td>1.642268</td>\n",
       "      <td>2.651768</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.140562</td>\n",
       "      <td>0.690811</td>\n",
       "      <td>1.590312</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.643669</td>\n",
       "      <td>-1.143978</td>\n",
       "      <td>-0.143359</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.673458</td>\n",
       "      <td>0.191343</td>\n",
       "      <td>1.155573</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.261905</td>\n",
       "      <td>-0.386231</td>\n",
       "      <td>0.910040</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.118410</td>\n",
       "      <td>0.642599</td>\n",
       "      <td>1.594220</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_diff  ci_lower  ci_upper                metric              method\n",
       "0    0.710000  0.070000  1.350000        benefit_answer       human experts\n",
       "1   -0.590000 -1.130000 -0.050000          rigor_answer       human experts\n",
       "2   -0.380000 -0.950000  0.190000     importance_answer       human experts\n",
       "3    0.770000  0.080000  1.470000      full_text_answer       human experts\n",
       "4    0.640000 -0.030000  1.310000  another_trial_answer       human experts\n",
       "5    3.381165  2.874680  3.887650        benefit_answer            baseline\n",
       "6    0.277165  0.088599  0.465730          rigor_answer            baseline\n",
       "7    1.264057  0.922720  1.605395     importance_answer            baseline\n",
       "8    2.205034  1.605838  2.804230      full_text_answer            baseline\n",
       "9    2.962500  2.496102  3.428898  another_trial_answer            baseline\n",
       "10   1.939576  1.467239  2.411913        benefit_answer        + ref labels\n",
       "11  -1.432680 -1.804166 -1.061195          rigor_answer        + ref labels\n",
       "12  -0.446717 -0.918034  0.024599     importance_answer        + ref labels\n",
       "13   0.287751 -0.257165  0.832668      full_text_answer        + ref labels\n",
       "14   1.094828  0.541371  1.648284  another_trial_answer        + ref labels\n",
       "15   2.588531  2.070864  3.106198        benefit_answer      + model labels\n",
       "16  -0.251387 -0.426146 -0.076627          rigor_answer      + model labels\n",
       "17   0.771471  0.488157  1.054785     importance_answer      + model labels\n",
       "18   1.357926  0.830169  1.885683      full_text_answer      + model labels\n",
       "19   2.147018  1.642268  2.651768  another_trial_answer      + model labels\n",
       "20   1.140562  0.690811  1.590312        benefit_answer  detect + interpret\n",
       "21  -0.643669 -1.143978 -0.143359          rigor_answer  detect + interpret\n",
       "22   0.673458  0.191343  1.155573     importance_answer  detect + interpret\n",
       "23   0.261905 -0.386231  0.910040      full_text_answer  detect + interpret\n",
       "24   1.118410  0.642599  1.594220  another_trial_answer  detect + interpret"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = pd.concat([human_expert_stats_df, model_stats_df, gold_labelled_model_stats_df, model_output_labelled_model_stats_df, combined_interpretation_stats_df], ignore_index=True)\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-526516d115a34c6bad5013ab98ae9985.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-526516d115a34c6bad5013ab98ae9985.vega-embed details,\n",
       "  #altair-viz-526516d115a34c6bad5013ab98ae9985.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-526516d115a34c6bad5013ab98ae9985\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-526516d115a34c6bad5013ab98ae9985\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-526516d115a34c6bad5013ab98ae9985\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"data\": {\"name\": \"data-5b6f166096ab25677e8be2038188b8d9\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"Treatment Benefit\", \"Study Rigor\", \"Study Importance\", \"Interest to Read Full-Text\", \"Interest to Run Another Trial\"], \"title\": null, \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"method\", \"legend\": null, \"scale\": {\"domain\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"range\": [\"#0868ac\", \"#43a2ca\", \"#7bccc4\", \"#bae4bc\", \"#E3F4D4\"]}, \"title\": \"Method\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"value\": \"gray\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"method\", \"sort\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_lower\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_upper\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": {\"expr\": \"if((datum.mean_diff >= 0),-1,22)\"}, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"mean_diff\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 300}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-5b6f166096ab25677e8be2038188b8d9\": [{\"mean_diff\": 0.71, \"ci_lower\": 0.07, \"ci_upper\": 1.35, \"metric\": \"Treatment Benefit\", \"method\": \"human experts\"}, {\"mean_diff\": -0.59, \"ci_lower\": -1.13, \"ci_upper\": -0.05, \"metric\": \"Study Rigor\", \"method\": \"human experts\"}, {\"mean_diff\": -0.38, \"ci_lower\": -0.95, \"ci_upper\": 0.19, \"metric\": \"Study Importance\", \"method\": \"human experts\"}, {\"mean_diff\": 0.77, \"ci_lower\": 0.08, \"ci_upper\": 1.47, \"metric\": \"Interest to Read Full-Text\", \"method\": \"human experts\"}, {\"mean_diff\": 0.64, \"ci_lower\": -0.03, \"ci_upper\": 1.31, \"metric\": \"Interest to Run Another Trial\", \"method\": \"human experts\"}, {\"mean_diff\": 3.3811649465006997, \"ci_lower\": 2.874679552619501, \"ci_upper\": 3.8876503403818985, \"metric\": \"Treatment Benefit\", \"method\": \"baseline\"}, {\"mean_diff\": 0.27716450216450217, \"ci_lower\": 0.08859924356867477, \"ci_upper\": 0.46572976076032957, \"metric\": \"Study Rigor\", \"method\": \"baseline\"}, {\"mean_diff\": 1.2640572390572389, \"ci_lower\": 0.9227199205664216, \"ci_upper\": 1.6053945575480562, \"metric\": \"Study Importance\", \"method\": \"baseline\"}, {\"mean_diff\": 2.20503441003441, \"ci_lower\": 1.6058384463942166, \"ci_upper\": 2.8042303736746033, \"metric\": \"Interest to Read Full-Text\", \"method\": \"baseline\"}, {\"mean_diff\": 2.9625000000000004, \"ci_lower\": 2.4961024839163084, \"ci_upper\": 3.4288975160836923, \"metric\": \"Interest to Run Another Trial\", \"method\": \"baseline\"}, {\"mean_diff\": 1.9395762132604235, \"ci_lower\": 1.4672391057272112, \"ci_upper\": 2.411913320793636, \"metric\": \"Treatment Benefit\", \"method\": \"+ ref labels\"}, {\"mean_diff\": -1.4326802507836989, \"ci_lower\": -1.8041655059964088, \"ci_upper\": -1.061194995570989, \"metric\": \"Study Rigor\", \"method\": \"+ ref labels\"}, {\"mean_diff\": -0.44671717171717157, \"ci_lower\": -0.9180335174395834, \"ci_upper\": 0.024599174005240254, \"metric\": \"Study Importance\", \"method\": \"+ ref labels\"}, {\"mean_diff\": 0.2877514642220523, \"ci_lower\": -0.2571646960797938, \"ci_upper\": 0.8326676245238984, \"metric\": \"Interest to Read Full-Text\", \"method\": \"+ ref labels\"}, {\"mean_diff\": 1.0948275862068964, \"ci_lower\": 0.5413707188866383, \"ci_upper\": 1.6482844535271544, \"metric\": \"Interest to Run Another Trial\", \"method\": \"+ ref labels\"}, {\"mean_diff\": 2.5885309617918306, \"ci_lower\": 2.0708643916172917, \"ci_upper\": 3.1061975319663695, \"metric\": \"Treatment Benefit\", \"method\": \"+ model labels\"}, {\"mean_diff\": -0.2513865444899926, \"ci_lower\": -0.42614574654999465, \"ci_upper\": -0.07662734242999053, \"metric\": \"Study Rigor\", \"method\": \"+ model labels\"}, {\"mean_diff\": 0.7714711214711211, \"ci_lower\": 0.4881574526435565, \"ci_upper\": 1.0547847902986858, \"metric\": \"Study Importance\", \"method\": \"+ model labels\"}, {\"mean_diff\": 1.357926332926333, \"ci_lower\": 0.8301692853415118, \"ci_upper\": 1.885683380511154, \"metric\": \"Interest to Read Full-Text\", \"method\": \"+ model labels\"}, {\"mean_diff\": 2.147018140589569, \"ci_lower\": 1.6422684395758878, \"ci_upper\": 2.65176784160325, \"metric\": \"Interest to Run Another Trial\", \"method\": \"+ model labels\"}, {\"mean_diff\": 1.1405616313511047, \"ci_lower\": 0.6908109889866827, \"ci_upper\": 1.5903122737155266, \"metric\": \"Treatment Benefit\", \"method\": \"detect + interpret\"}, {\"mean_diff\": -0.6436688311688312, \"ci_lower\": -1.1439784447511747, \"ci_upper\": -0.14335921758648762, \"metric\": \"Study Rigor\", \"method\": \"detect + interpret\"}, {\"mean_diff\": 0.6734578991495986, \"ci_lower\": 0.19134295491614778, \"ci_upper\": 1.1555728433830494, \"metric\": \"Study Importance\", \"method\": \"detect + interpret\"}, {\"mean_diff\": 0.26190476190476186, \"ci_lower\": -0.3862309456862836, \"ci_upper\": 0.9100404694958073, \"metric\": \"Interest to Read Full-Text\", \"method\": \"detect + interpret\"}, {\"mean_diff\": 1.1184099234099232, \"ci_lower\": 0.6425994745550674, \"ci_upper\": 1.594220372264779, \"metric\": \"Interest to Run Another Trial\", \"method\": \"detect + interpret\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping for custom facet titles\n",
    "facet_title_mapping = {\n",
    "    'benefit_answer': 'Treatment Benefit',\n",
    "    'rigor_answer': 'Study Rigor',\n",
    "    'importance_answer': 'Study Importance',\n",
    "    'full_text_answer': 'Interest to Read Full-Text',\n",
    "    'another_trial_answer': 'Interest to Run Another Trial'\n",
    "}\n",
    "\n",
    "# Define the desired order for the facets\n",
    "facet_order = ['Treatment Benefit', 'Study Rigor', 'Study Importance', 'Interest to Read Full-Text', 'Interest to Run Another Trial']\n",
    "\n",
    "color_mapping = {\n",
    "    'human experts': '#0868ac',  \n",
    "    'baseline': '#43a2ca',  \n",
    "    '+ ref labels': '#7bccc4',  \n",
    "    '+ model labels': '#bae4bc', \n",
    "    'detect + interpret': '#E3F4D4'  \n",
    "}\n",
    "\n",
    "method_order = ['human experts', 'baseline', '+ ref labels', '+ model labels', 'detect + interpret']\n",
    "\n",
    "# Apply the mapping as a calculated field\n",
    "chart_data = all_results.copy()\n",
    "chart_data['metric'] = chart_data['metric'].map(facet_title_mapping)\n",
    "\n",
    "# Configure global font sizes\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Facet headers\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "bars = alt.Chart(chart_data).mark_bar().encode(\n",
    "    x=alt.X('method:N', title=None, axis=alt.Axis(labelAngle=-45), sort = method_order),\n",
    "    y=alt.Y('mean_diff:Q', title='Mean Difference'),\n",
    "    color=alt.Color('method:N', title='Method', legend=None, scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())))\n",
    ").properties(\n",
    "    width=300,  # Set the width to 300 pixels\n",
    "    height=300  # Set the height to 300 pixels\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "error_bars = alt.Chart(chart_data).mark_errorbar().encode(\n",
    "    alt.X(\"method:N\", sort = method_order),\n",
    "    alt.Y(\"ci_lower:Q\").title(\"Mean Difference\"),\n",
    "    alt.Y2(\"ci_upper:Q\"),\n",
    "    strokeWidth=alt.value(2),\n",
    "    color=alt.value('gray')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontWeight='bold',\n",
    "    dy=alt.expr(expr=alt.expr.if_(alt.datum.mean_diff >= 0, -1, 22))  # Adjust the position of the text    \n",
    ").encode(\n",
    "    text=alt.Text('mean_diff:Q', format='.2f'),\n",
    "    color=alt.value('black')  # Set text color to black\n",
    ")\n",
    "\n",
    "# Combine layers and facet\n",
    "chart = alt.layer(bars, error_bars, text, data=chart_data).facet(\n",
    "    column=alt.Column('metric:N', title=None, sort=facet_order),\n",
    ").configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# save to html\n",
    "chart.save(\"./plots/interpretation_by_measures_all_methods.html\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benefit_answer_mean_diff</th>\n",
       "      <th>rigor_answer_mean_diff</th>\n",
       "      <th>importance_answer_mean_diff</th>\n",
       "      <th>full_text_answer_mean_diff</th>\n",
       "      <th>another_trial_answer_mean_diff</th>\n",
       "      <th>overall_mean_diff_avg</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size_in_b</th>\n",
       "      <th>method_category</th>\n",
       "      <th>overall_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.566667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.113333</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>1.433333</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>2.753333</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>175.0</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>2.253333</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>8.0</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4.633333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>2.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3.304348</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>1.518519</td>\n",
       "      <td>2.518519</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>1.814484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3.833333</td>\n",
       "      <td>-0.183333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>1.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2.866667</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>1.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    benefit_answer_mean_diff  rigor_answer_mean_diff  \\\n",
       "0                   3.133333                0.100000   \n",
       "1                   3.566667                1.466667   \n",
       "2                   3.900000                1.433333   \n",
       "3                   2.500000               -0.100000   \n",
       "4                   3.066667               -0.100000   \n",
       "..                       ...                     ...   \n",
       "61                  4.633333               -0.233333   \n",
       "62                  3.304348               -0.068966   \n",
       "63                  3.833333               -0.183333   \n",
       "64                  2.866667               -0.133333   \n",
       "65                  0.000000               -1.000000   \n",
       "\n",
       "    importance_answer_mean_diff  full_text_answer_mean_diff  \\\n",
       "0                      1.233333                    2.866667   \n",
       "1                      2.733333                    3.933333   \n",
       "2                      2.066667                    2.600000   \n",
       "3                      2.166667                    3.000000   \n",
       "4                      0.966667                    2.733333   \n",
       "..                          ...                         ...   \n",
       "61                     1.366667                    1.900000   \n",
       "62                     1.518519                    2.518519   \n",
       "63                     1.000000                    0.615385   \n",
       "64                     1.533333                    2.600000   \n",
       "65                     0.000000                   -2.333333   \n",
       "\n",
       "    another_trial_answer_mean_diff  overall_mean_diff_avg  \\\n",
       "0                         3.333333               2.133333   \n",
       "1                         3.866667               3.113333   \n",
       "2                         3.766667               2.753333   \n",
       "3                         3.700000               2.253333   \n",
       "4                         3.433333               2.020000   \n",
       "..                             ...                    ...   \n",
       "61                        2.766667                    NaN   \n",
       "62                        1.800000                    NaN   \n",
       "63                        4.733333                    NaN   \n",
       "64                        2.333333                    NaN   \n",
       "65                             NaN                    NaN   \n",
       "\n",
       "             model_name         model_type  model_size_in_b  \\\n",
       "0                 gpt4o  generalist closed              NaN   \n",
       "1            gpt4o-mini  generalist closed              NaN   \n",
       "2                 gpt35  generalist closed            175.0   \n",
       "3      gemini_1.5_flash  generalist closed              NaN   \n",
       "4   gemini_1.5_flash-8B  generalist closed              8.0   \n",
       "..                  ...                ...              ...   \n",
       "61   olmo2_instruct-13B    generalist open             13.0   \n",
       "62        openbiollm-8B    biomedical open              8.0   \n",
       "63       openbiollm-70B    biomedical open             70.0   \n",
       "64   mistral_instruct7B    generalist open              7.0   \n",
       "65          biomedgpt7B    biomedical open              7.0   \n",
       "\n",
       "          method_category  overall_avg  \n",
       "0                baseline          NaN  \n",
       "1                baseline          NaN  \n",
       "2                baseline          NaN  \n",
       "3                baseline          NaN  \n",
       "4                baseline          NaN  \n",
       "..                    ...          ...  \n",
       "61  model_output_labelled     2.086667  \n",
       "62  model_output_labelled     1.814484  \n",
       "63  model_output_labelled     1.999744  \n",
       "64  model_output_labelled     1.840000  \n",
       "65  model_output_labelled          NaN  \n",
       "\n",
       "[66 rows x 11 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretation_stats_df[\"method_category\"] = \"baseline\"\n",
    "gold_labelled_interpretation_stats_df[\"method_category\"] = \"gold_labelled\"\n",
    "model_output_labelled_interpretation_stats_df[\"method_category\"] = \"model_output_labelled\"\n",
    "\n",
    "all_interpretation_stats_df = pd.concat([interpretation_stats_df, gold_labelled_interpretation_stats_df, model_output_labelled_interpretation_stats_df], ignore_index=True)\n",
    "\n",
    "all_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               OLS Regression Results                               \n",
      "====================================================================================\n",
      "Dep. Variable:     benefit_answer_mean_diff   R-squared:                       0.203\n",
      "Model:                                  OLS   Adj. R-squared:                  0.178\n",
      "Method:                       Least Squares   F-statistic:                     8.036\n",
      "Date:                      Sun, 16 Mar 2025   Prob (F-statistic):           0.000779\n",
      "Time:                              21:24:49   Log-Likelihood:                -103.85\n",
      "No. Observations:                        66   AIC:                             213.7\n",
      "Df Residuals:                            63   BIC:                             220.3\n",
      "Df Model:                                 2                                         \n",
      "Covariance Type:                  nonrobust                                         \n",
      "============================================================================================================\n",
      "                                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    3.3812      0.255     13.275      0.000       2.872       3.890\n",
      "method_category[T.gold_labelled]            -1.4416      0.360     -4.002      0.000      -2.161      -0.722\n",
      "method_category[T.model_output_labelled]    -0.7926      0.360     -2.201      0.031      -1.512      -0.073\n",
      "==============================================================================\n",
      "Omnibus:                        1.583   Durbin-Watson:                   1.877\n",
      "Prob(Omnibus):                  0.453   Jarque-Bera (JB):                1.560\n",
      "Skew:                           0.291   Prob(JB):                        0.458\n",
      "Kurtosis:                       2.523   Cond. No.                         3.73\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n",
       "<tr>\n",
       "     <th>group1</th>            <th>group2</th>         <th>meandiff</th>  <th>p-adj</th>  <th>lower</th>   <th>upper</th> <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>baseline</td>        <td>gold_labelled</td>      <td>-1.4416</td> <td>0.0005</td> <td>-2.3062</td> <td>-0.577</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>baseline</td>    <td>model_output_labelled</td>  <td>-0.7926</td> <td>0.0789</td> <td>-1.6572</td> <td>0.0719</td>  <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>gold_labelled</td> <td>model_output_labelled</td>   <td>0.649</td>  <td>0.1773</td> <td>-0.2156</td> <td>1.5135</td>  <td>False</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{ccccccc}\n",
       "\\toprule\n",
       "\\textbf{group1} &     \\textbf{group2}     & \\textbf{meandiff} & \\textbf{p-adj} & \\textbf{lower} & \\textbf{upper} & \\textbf{reject}  \\\\\n",
       "\\midrule\n",
       "    baseline    &      gold\\_labelled     &      -1.4416      &     0.0005     &    -2.3062     &     -0.577     &       True       \\\\\n",
       "    baseline    & model\\_output\\_labelled &      -0.7926      &     0.0789     &    -1.6572     &     0.0719     &      False       \\\\\n",
       " gold\\_labelled & model\\_output\\_labelled &       0.649       &     0.1773     &    -0.2156     &     1.5135     &      False       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Multiple Comparison of Means - Tukey HSD, FWER=0.05}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model = smf.ols(formula=\"benefit_answer_mean_diff ~ method_category\", \n",
    "                            data=all_interpretation_stats_df)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "\n",
    "tukey_oneway = pairwise_tukeyhsd(endog = all_interpretation_stats_df[\"benefit_answer_mean_diff\"], groups = all_interpretation_stats_df[\"method_category\"])\n",
    "\n",
    "# Display the results\n",
    "tukey_oneway.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>baseline_benefit</th>\n",
       "      <th>model_name</th>\n",
       "      <th>detect_interpret_benefit</th>\n",
       "      <th>model_name_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.133333</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>GPT4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.566667</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>2.533333</td>\n",
       "      <td>GPT3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Gemini1.5 Flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.066667</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>Gemini1.5 Flash 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>claude_3.5-sonnet</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>Claude3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.966667</td>\n",
       "      <td>claude_3.5-haiku</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>Claude3.5 Haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.051724</td>\n",
       "      <td>alpacare-7B</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>AlpaCare 7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>biomistral7B</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>BioMistral 7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>llama2_chat-7B</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>Llama2 Chat 7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.933333</td>\n",
       "      <td>llama2_chat-13B</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Llama2 Chat 13B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.689655</td>\n",
       "      <td>llama2_chat-70B</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>Llama2 Chat 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>llama3_instruct-8B</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>Llama3 Instruct 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>llama3_instruct-70B</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>Llama3 Instruct 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.966667</td>\n",
       "      <td>med42-8B</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>Med42 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.833333</td>\n",
       "      <td>med42-70B</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>Med42 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.233333</td>\n",
       "      <td>olmo2_instruct-7B</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>Olmo2 Instruct 7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>Olmo2 Instruct 13B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.736842</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "      <td>-0.105263</td>\n",
       "      <td>OpenBioLLM 8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>OpenBioLLM 70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>Mistral Instruct 7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.240741</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>BioMedGPT 7B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    baseline_benefit           model_name  detect_interpret_benefit  \\\n",
       "0           3.133333                gpt4o                  0.900000   \n",
       "1           3.566667           gpt4o-mini                  1.333333   \n",
       "2           3.900000                gpt35                  2.533333   \n",
       "3           2.500000     gemini_1.5_flash                  0.100000   \n",
       "4           3.066667  gemini_1.5_flash-8B                  0.900000   \n",
       "5           2.500000    claude_3.5-sonnet                  0.866667   \n",
       "6           2.966667     claude_3.5-haiku                  0.733333   \n",
       "7           6.051724          alpacare-7B                 -1.285714   \n",
       "8           1.666667         biomistral7B                  1.000000   \n",
       "9           3.500000       llama2_chat-7B                  1.666667   \n",
       "10          2.933333      llama2_chat-13B                  0.100000   \n",
       "11          2.689655      llama2_chat-70B                  1.533333   \n",
       "12          2.200000   llama3_instruct-8B                  0.066667   \n",
       "13          4.400000  llama3_instruct-70B                  2.100000   \n",
       "14          2.966667             med42-8B                  1.066667   \n",
       "15          4.833333            med42-70B                  3.600000   \n",
       "16          3.233333    olmo2_instruct-7B                  1.500000   \n",
       "17          6.000000   olmo2_instruct-13B                  1.066667   \n",
       "18          2.736842        openbiollm-8B                 -0.105263   \n",
       "19          4.400000       openbiollm-70B                  3.033333   \n",
       "20          3.900000   mistral_instruct7B                  1.400000   \n",
       "21          1.240741          biomedgpt7B                  0.983333   \n",
       "\n",
       "      model_name_custom  \n",
       "0                 GPT4o  \n",
       "1            GPT4o Mini  \n",
       "2                GPT3.5  \n",
       "3       Gemini1.5 Flash  \n",
       "4    Gemini1.5 Flash 8B  \n",
       "5      Claude3.5 Sonnet  \n",
       "6       Claude3.5 Haiku  \n",
       "7           AlpaCare 7B  \n",
       "8         BioMistral 7B  \n",
       "9        Llama2 Chat 7B  \n",
       "10      Llama2 Chat 13B  \n",
       "11      Llama2 Chat 70B  \n",
       "12   Llama3 Instruct 8B  \n",
       "13  Llama3 Instruct 70B  \n",
       "14             Med42 8B  \n",
       "15            Med42 70B  \n",
       "16    Olmo2 Instruct 7B  \n",
       "17   Olmo2 Instruct 13B  \n",
       "18        OpenBioLLM 8B  \n",
       "19       OpenBioLLM 70B  \n",
       "20  Mistral Instruct 7B  \n",
       "21         BioMedGPT 7B  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create forest plot that shows the difference in scores between baseline and detect + interpret method for treatment benefit\n",
    "\n",
    "baseline_stats_df = pd.read_json(\"./eval_outputs/interpretation_overall_metrics.json\", orient=\"index\")\n",
    "baseline_stats_df[\"model_name\"] = baseline_stats_df.index\n",
    "baseline_stats_df.drop([\"overall_mean_diff_avg\", \"rigor_answer_mean_diff\", \"importance_answer_mean_diff\", \"full_text_answer_mean_diff\", \"another_trial_answer_mean_diff\"], axis=1, inplace=True)\n",
    "# remove index\n",
    "baseline_stats_df.reset_index(drop=True, inplace=True)\n",
    "# rename column name benefit_answer_mean_diff to baseline_benefit\n",
    "baseline_stats_df.rename(columns={\"benefit_answer_mean_diff\": \"baseline_benefit\"}, inplace=True)\n",
    "\n",
    "combined_interpretation_stats_df = pd.read_json(\"./eval_outputs/combined_detection_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "combined_interpretation_stats_df[\"model_name\"] = combined_interpretation_stats_df.index\n",
    "combined_interpretation_stats_df.drop([\"overall_avg\", \"rigor_answer_mean_diff\", \"importance_answer_mean_diff\", \"full_text_answer_mean_diff\", \"another_trial_answer_mean_diff\"], axis=1, inplace=True)\n",
    "# remove index\n",
    "combined_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "# rename column name benefit_answer_mean_diff to detect_interpret_benefit\n",
    "combined_interpretation_stats_df.rename(columns={\"benefit_answer_mean_diff\": \"detect_interpret_benefit\"}, inplace=True)\n",
    "\n",
    "# merge the dataframes by model_name\n",
    "combined_methods_stats_df = pd.merge(baseline_stats_df, combined_interpretation_stats_df, on=\"model_name\")\n",
    "combined_methods_stats_df[\"model_name_custom\"] = combined_methods_stats_df[\"model_name\"].map(custom_labels)\n",
    "\n",
    "combined_methods_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-560540293ad14ac4946d36cbe0efea78.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-560540293ad14ac4946d36cbe0efea78.vega-embed details,\n",
       "  #altair-viz-560540293ad14ac4946d36cbe0efea78.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-560540293ad14ac4946d36cbe0efea78\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-560540293ad14ac4946d36cbe0efea78\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-560540293ad14ac4946d36cbe0efea78\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 18}}, \"layer\": [{\"mark\": {\"type\": \"bar\", \"cornerRadius\": 10, \"height\": 10}, \"encoding\": {\"x\": {\"field\": \"detect_interpret_benefit\", \"scale\": {\"domain\": [-2, 6.5]}, \"title\": \"Mean Difference for Treatment Benefit\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"baseline_benefit\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": [\"Claude3.5 Sonnet\", \"GPT4o Mini\", \"Gemini1.5 Flash 8B\", \"Llama3 Instruct 8B\", \"Llama3 Instruct 70B\", \"OpenBioLLM 70B\", \"Med42 70B\", \"GPT4o\", \"Gemini1.5 Flash\", \"Olmo2 Instruct 7B\", \"AlpaCare 7B\", \"Llama2 Chat 70B\", \"Med42 8B\", \"Claude3.5 Haiku\", \"Llama2 Chat 13B\", \"GPT3.5\", \"BioMistral 7B\", \"Olmo2 Instruct 13B\", \"OpenBioLLM 8B\", \"Mistral Instruct 7B\", \"Llama2 Chat 7B\", \"BioMedGPT 7B\"], \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"right\", \"dx\": -5, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#FF8100\"}, \"text\": {\"field\": \"detect_interpret_benefit\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"detect_interpret_benefit\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": [\"Claude3.5 Sonnet\", \"GPT4o Mini\", \"Gemini1.5 Flash 8B\", \"Llama3 Instruct 8B\", \"Llama3 Instruct 70B\", \"OpenBioLLM 70B\", \"Med42 70B\", \"GPT4o\", \"Gemini1.5 Flash\", \"Olmo2 Instruct 7B\", \"AlpaCare 7B\", \"Llama2 Chat 70B\", \"Med42 8B\", \"Claude3.5 Haiku\", \"Llama2 Chat 13B\", \"GPT3.5\", \"BioMistral 7B\", \"Olmo2 Instruct 13B\", \"OpenBioLLM 8B\", \"Mistral Instruct 7B\", \"Llama2 Chat 7B\", \"BioMedGPT 7B\"], \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"dx\": 5, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"text\": {\"field\": \"baseline_benefit\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"baseline_benefit\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": [\"Claude3.5 Sonnet\", \"GPT4o Mini\", \"Gemini1.5 Flash 8B\", \"Llama3 Instruct 8B\", \"Llama3 Instruct 70B\", \"OpenBioLLM 70B\", \"Med42 70B\", \"GPT4o\", \"Gemini1.5 Flash\", \"Olmo2 Instruct 7B\", \"AlpaCare 7B\", \"Llama2 Chat 70B\", \"Med42 8B\", \"Claude3.5 Haiku\", \"Llama2 Chat 13B\", \"GPT3.5\", \"BioMistral 7B\", \"Olmo2 Instruct 13B\", \"OpenBioLLM 8B\", \"Mistral Instruct 7B\", \"Llama2 Chat 7B\", \"BioMedGPT 7B\"], \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-cbc618bdfd635edb9dbb775ad351cfaa\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-cbc618bdfd635edb9dbb775ad351cfaa\": [{\"baseline_benefit\": 3.133333333333333, \"model_name\": \"gpt4o\", \"detect_interpret_benefit\": 0.899999999999999, \"model_name_custom\": \"GPT4o\"}, {\"baseline_benefit\": 3.5666666666666673, \"model_name\": \"gpt4o-mini\", \"detect_interpret_benefit\": 1.333333333333333, \"model_name_custom\": \"GPT4o Mini\"}, {\"baseline_benefit\": 3.9, \"model_name\": \"gpt35\", \"detect_interpret_benefit\": 2.533333333333332, \"model_name_custom\": \"GPT3.5\"}, {\"baseline_benefit\": 2.5, \"model_name\": \"gemini_1.5_flash\", \"detect_interpret_benefit\": 0.1, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"baseline_benefit\": 3.066666666666667, \"model_name\": \"gemini_1.5_flash-8B\", \"detect_interpret_benefit\": 0.899999999999999, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"baseline_benefit\": 2.499999999999999, \"model_name\": \"claude_3.5-sonnet\", \"detect_interpret_benefit\": 0.866666666666666, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"baseline_benefit\": 2.966666666666666, \"model_name\": \"claude_3.5-haiku\", \"detect_interpret_benefit\": 0.7333333333333331, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"baseline_benefit\": 6.051724137931034, \"model_name\": \"alpacare-7B\", \"detect_interpret_benefit\": -1.285714285714284, \"model_name_custom\": \"AlpaCare 7B\"}, {\"baseline_benefit\": 1.666666666666667, \"model_name\": \"biomistral7B\", \"detect_interpret_benefit\": 1.0, \"model_name_custom\": \"BioMistral 7B\"}, {\"baseline_benefit\": 3.5, \"model_name\": \"llama2_chat-7B\", \"detect_interpret_benefit\": 1.666666666666667, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"baseline_benefit\": 2.933333333333333, \"model_name\": \"llama2_chat-13B\", \"detect_interpret_benefit\": 0.1, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"baseline_benefit\": 2.689655172413792, \"model_name\": \"llama2_chat-70B\", \"detect_interpret_benefit\": 1.533333333333333, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"baseline_benefit\": 2.2, \"model_name\": \"llama3_instruct-8B\", \"detect_interpret_benefit\": 0.066666666666666, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"baseline_benefit\": 4.399999999999999, \"model_name\": \"llama3_instruct-70B\", \"detect_interpret_benefit\": 2.1, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"baseline_benefit\": 2.9666666666666672, \"model_name\": \"med42-8B\", \"detect_interpret_benefit\": 1.066666666666666, \"model_name_custom\": \"Med42 8B\"}, {\"baseline_benefit\": 4.833333333333333, \"model_name\": \"med42-70B\", \"detect_interpret_benefit\": 3.599999999999999, \"model_name_custom\": \"Med42 70B\"}, {\"baseline_benefit\": 3.233333333333333, \"model_name\": \"olmo2_instruct-7B\", \"detect_interpret_benefit\": 1.5, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"baseline_benefit\": 6.0, \"model_name\": \"olmo2_instruct-13B\", \"detect_interpret_benefit\": 1.066666666666666, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"baseline_benefit\": 2.736842105263157, \"model_name\": \"openbiollm-8B\", \"detect_interpret_benefit\": -0.105263157894737, \"model_name_custom\": \"OpenBioLLM 8B\"}, {\"baseline_benefit\": 4.4, \"model_name\": \"openbiollm-70B\", \"detect_interpret_benefit\": 3.033333333333333, \"model_name_custom\": \"OpenBioLLM 70B\"}, {\"baseline_benefit\": 3.9, \"model_name\": \"mistral_instruct7B\", \"detect_interpret_benefit\": 1.4, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"baseline_benefit\": 1.24074074074074, \"model_name\": \"biomedgpt7B\", \"detect_interpret_benefit\": 0.9833333333333341, \"model_name_custom\": \"BioMedGPT 7B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_order = ['Claude3.5 Sonnet', \n",
    "    'GPT4o Mini', 'Gemini1.5 Flash 8B', 'Llama3 Instruct 8B', 'Llama3 Instruct 70B', 'OpenBioLLM 70B', 'Med42 70B',\n",
    "    'GPT4o', 'Gemini1.5 Flash', 'Olmo2 Instruct 7B', 'AlpaCare 7B', 'Llama2 Chat 70B', 'Med42 8B', 'Claude3.5 Haiku', 'Llama2 Chat 13B',\n",
    "    'GPT3.5', 'BioMistral 7B', 'Olmo2 Instruct 13B', 'OpenBioLLM 8B', 'Mistral Instruct 7B', 'Llama2 Chat 7B', 'BioMedGPT 7B']\n",
    "\n",
    "bar = alt.Chart(combined_methods_stats_df).mark_bar(cornerRadius=10, height=10).encode(\n",
    "    x=alt.X('detect_interpret_benefit:Q').scale(domain=[-2, 6.5]).title('Mean Difference for Treatment Benefit'),\n",
    "    x2='baseline_benefit:Q',\n",
    "    y=alt.Y('model_name_custom:N', title=\"LLM Name\", sort=model_order)  # Specify custom order\n",
    ")\n",
    "\n",
    "text_min = alt.Chart(combined_methods_stats_df).mark_text(align='right', dx=-5, fontSize=14, fontWeight='bold').encode(\n",
    "    x='detect_interpret_benefit:Q',\n",
    "    y=alt.Y('model_name_custom:N', sort=model_order),\n",
    "    text=alt.Text('detect_interpret_benefit:Q', format='.2f'),\n",
    "    color=alt.value('#FF8100')  # Set text color to orange\n",
    ")\n",
    "\n",
    "text_max = alt.Chart(combined_methods_stats_df).mark_text(align='left', dx=5, fontSize=14, fontWeight='bold').encode(\n",
    "    x='baseline_benefit:Q',\n",
    "    y=alt.Y('model_name_custom:N', sort=model_order),\n",
    "    text=alt.Text('baseline_benefit:Q', format='.2f')\n",
    ")\n",
    "\n",
    "chart = (bar + text_min + text_max).properties(\n",
    "    width=800,\n",
    "    config={\n",
    "        'axis': {\n",
    "            'labelFontSize': 16,\n",
    "            'titleFontSize': 18\n",
    "        }\n",
    "    })\n",
    "\n",
    "# # Save to HTML\n",
    "chart.save(\"./plots/baseline_detect_interpret_treatment_benefit_diff.html\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between spin / spin detection and spin interpretation\n",
    "\n",
    "Linear Regression with statsmodels Python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all model names\n",
    "model_names = model_metadata.keys()\n",
    "# remove alpacare-13B\n",
    "model_names = [x for x in model_names if x != \"alpacare-13B\"]\n",
    "\n",
    "len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\"]\n",
    "gpt_models = [\"gpt4o\", \"gpt4o-mini\", \"gpt35\"]\n",
    "huggingface_models = [\"alpacare-7B\", \"biomedgpt7B\", \"biomistral7B\", \n",
    "                      \"llama2_chat-7B\", \"llama2_chat-13B\", \"llama2_chat-70B\",\n",
    "                      \"llama3_instruct-8B\", \"llama3_instruct-70B\",\n",
    "                      \"med42-8B\", \"med42-70B\", \"mistral_instruct7B\", \n",
    "                      \"olmo2_instruct-7B\", \"olmo2_instruct-13B\",\n",
    "                      \"openbiollm-8B\", \"openbiollm-70B\"]\n",
    "no_probability_models = [\"claude_3.5-haiku\", \"claude_3.5-sonnet\", \"gemini_1.5_flash\", \"gemini_1.5_flash-8B\"]\n",
    "\n",
    "def get_is_detection_correct(row):\n",
    "    if row['abstract_type'] == \"spin\":\n",
    "        return row['model_answer'] == \"yes\"\n",
    "    else:\n",
    "        return row['model_answer'] == \"no\"\n",
    "    \n",
    "def get_is_abstract_type_spin(row):\n",
    "    return row['abstract_type'] == \"spin\"\n",
    "    \n",
    "def detection_probability_gpt(row):\n",
    "    # find the first instance of \"yes\" or \"no\"\n",
    "    token_probabilties = row['model_log_probabilities']\n",
    "    for token_prob in token_probabilties:\n",
    "        if token_prob['token'].lower() == \"yes\":\n",
    "            return np.exp(token_prob['logprob'])\n",
    "        elif token_prob['token'].lower() == \"no\":\n",
    "            return np.exp(token_prob['logprob'])\n",
    "    return None # this should not happen but just in case\n",
    "\n",
    "def detection_probability_huggingface(row):\n",
    "    # find the first instance of \"yes\" or \"no\"\n",
    "    token_probabilties = row['model_log_probabilities']\n",
    "    for token_prob in token_probabilties:\n",
    "        if token_prob['token_string'].lower() == \"yes\":\n",
    "            return token_prob['probability']\n",
    "        elif token_prob['token_string'].lower() == \"no\":\n",
    "            return token_prob['probability']\n",
    "    return None # this should not happen but just in case\n",
    "\n",
    "\n",
    "def prepare_data_for_regression(model_names):\n",
    "    for model_name in tqdm(model_names):\n",
    "        # print(f\"Processing {model_name}...\")\n",
    "        final_data = []\n",
    "        detection_output_file_path = f\"./eval_outputs/{model_name}/{model_name}_detection_outputs.json\"\n",
    "        interpretation_output_file_path = f\"./eval_outputs/{model_name}/{model_name}_interpretation_outputs.json\"\n",
    "        model_detection_data = pd.read_json(detection_output_file_path, orient=\"records\")\n",
    "        model_interpretation_data = pd.read_json(interpretation_output_file_path, orient=\"records\")\n",
    "\n",
    "        # merge model_detection_data and model_interpretation_data by PMID and abstract_type\n",
    "        model_data = pd.merge(model_detection_data, model_interpretation_data, on=['PMID', 'abstract_type'])\n",
    "\n",
    "        # loop through each row in model_data\n",
    "        for _, row in model_data.iterrows():\n",
    "            detection_model_prediction = 1 if row['model_answer'] == \"yes\" else 0\n",
    "            is_detection_correct = 1 if get_is_detection_correct(row) else 0\n",
    "            is_spin_in_abstract = 1 if get_is_abstract_type_spin(row) else 0\n",
    "\n",
    "            if model_name in gpt_models:\n",
    "                detection_probability = detection_probability_gpt(row)\n",
    "            elif model_name in huggingface_models:\n",
    "                detection_probability = detection_probability_huggingface(row)\n",
    "            else:\n",
    "                detection_probability = None\n",
    "            \n",
    "            for measure in measures:\n",
    "                final_data.append({\n",
    "                    \"pmid\": row['PMID'],\n",
    "                    \"measure\": measure,\n",
    "                    \"is_spin_in_abstract\": is_spin_in_abstract,\n",
    "                    \"is_detection_correct\": is_detection_correct,\n",
    "                    \"detection_model_prediction\": detection_model_prediction,\n",
    "                    \"detection_probability\": detection_probability,\n",
    "                    \"interpretation_answer\": float(row[measure]) if row[measure] != \"\" else None\n",
    "                })\n",
    "            # calculate the average of the differences\n",
    "            answers = []\n",
    "            for measure in measures:\n",
    "                if row[measure] != \"\":\n",
    "                    answers.append(float(row[measure]))\n",
    "            if len(answers) > 0:\n",
    "                avg_answer= round(np.mean(answers), 6)\n",
    "            else:\n",
    "                avg_answer = None\n",
    "            # add the average difference to the data\n",
    "            final_data.append({\n",
    "                \"pmid\": row['PMID'],\n",
    "                \"measure\": \"overall\",\n",
    "                \"is_spin_in_abstract\": is_spin_in_abstract,\n",
    "                \"is_detection_correct\": is_detection_correct,\n",
    "                \"detection_model_prediction\": detection_model_prediction,\n",
    "                \"detection_probability\": detection_probability,\n",
    "                \"interpretation_answer\": avg_answer\n",
    "            })\n",
    "\n",
    "        # save the final data to a json file\n",
    "        json_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "        save_dataset_to_csv(final_data, json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:02<00:00, 10.90it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_data_for_regression(model_names=model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplest Regression\n",
    "\n",
    "Is spin in abstract and the measures answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_names:\n",
    "    output_string = \"\"\n",
    "    csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "\n",
    "    measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "    for measure in measures:\n",
    "        # get the data for the current measure\n",
    "        measure_data = data[data['measure'] == measure]\n",
    "        nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "        # remove rows with NaN values in interpretation_answer\n",
    "        measure_data = measure_data.dropna(subset=['interpretation_answer'])\n",
    "\n",
    "        # check if there are less than 2 rows\n",
    "        if len(measure_data) < 2:\n",
    "            continue\n",
    "        \n",
    "        # fit the model\n",
    "        model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract\", \n",
    "                                    data=measure_data)\n",
    "        results = model.fit()\n",
    "\n",
    "        output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "        # print number of rows with NaN value(s)\n",
    "        output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "        output_string += results.summary().as_text()\n",
    "        output_string += \"\\n\"\n",
    "\n",
    "    # save the model summary\n",
    "    with open(f\"./eval_outputs/{model_name}/{model_name}_simple_regression_summary.txt\", \"w\") as f:\n",
    "        f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forest Plot for \"Benefit\" Linear Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-844a6be55c8b4dd4a439d200b6b53d71.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-844a6be55c8b4dd4a439d200b6b53d71.vega-embed details,\n",
       "  #altair-viz-844a6be55c8b4dd4a439d200b6b53d71.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-844a6be55c8b4dd4a439d200b6b53d71\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-844a6be55c8b4dd4a439d200b6b53d71\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-844a6be55c8b4dd4a439d200b6b53d71\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 18}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"data\": {\"name\": \"data-1292b99921b64b6908a0bdde39c795ed\"}, \"mark\": {\"type\": \"rule\", \"strokeWidth\": 2}, \"encoding\": {\"size\": {\"value\": 2}, \"x\": {\"field\": \"ci_lower\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"ci_upper\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-1292b99921b64b6908a0bdde39c795ed\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"field\": \"coef\", \"title\": \"Coefficient\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-d684fefd2a8cfbdc8777b890f4681082\"}, \"mark\": {\"type\": \"rule\", \"color\": \"blue\", \"strokeDash\": [4, 4], \"strokeWidth\": 2}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-79df26acf32424da04c414a86a2aea39\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"dx\": 5, \"dy\": -10, \"fontSize\": 14, \"fontWeight\": \"bold\", \"text\": \"Human Experts\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"value\": 0}}}, {\"data\": {\"name\": \"data-cb65bf961175d1be7a6eb8feef57f39f\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 24, \"dy\": 195, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-bc56d21eb652852fb5fd16e0219fda39\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 10, \"dy\": 195, \"fontSize\": 24, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-f2bbc3422d20d47e11b79ac3e5c3cba7\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 0, \"dy\": 195, \"fontSize\": 24, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-1292b99921b64b6908a0bdde39c795ed\": [{\"model_name\": \"gpt4o\", \"coef\": 3.1333, \"ci_lower\": 2.442, \"ci_upper\": 3.824, \"p_value\": 0, \"model_name_custom\": \"GPT4o\"}, {\"model_name\": \"gpt4o-mini\", \"coef\": 3.5667, \"ci_lower\": 2.9130000000000003, \"ci_upper\": 4.221, \"p_value\": 0, \"model_name_custom\": \"GPT4o Mini\"}, {\"model_name\": \"gpt35\", \"coef\": 3.9, \"ci_lower\": 3.205, \"ci_upper\": 4.595, \"p_value\": 0, \"model_name_custom\": \"GPT3.5\"}, {\"model_name\": \"gemini_1.5_flash\", \"coef\": 2.5, \"ci_lower\": 1.82, \"ci_upper\": 3.18, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"model_name\": \"gemini_1.5_flash-8B\", \"coef\": 3.0667, \"ci_lower\": 2.517, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"model_name\": \"claude_3.5-sonnet\", \"coef\": 2.5, \"ci_lower\": 1.896, \"ci_upper\": 3.104, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"model_name\": \"claude_3.5-haiku\", \"coef\": 2.9667, \"ci_lower\": 2.317, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"model_name\": \"biomistral7B\", \"coef\": 1.6667, \"ci_lower\": 1.165, \"ci_upper\": 2.169, \"p_value\": 0, \"model_name_custom\": \"BioMistral 7B\"}, {\"model_name\": \"llama2_chat-13B\", \"coef\": 2.9333, \"ci_lower\": 2.351, \"ci_upper\": 3.515, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"model_name\": \"llama2_chat-70B\", \"coef\": 2.6414, \"ci_lower\": 2.17, \"ci_upper\": 3.112, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"model_name\": \"llama3_instruct-8B\", \"coef\": 2.2, \"ci_lower\": 1.716, \"ci_upper\": 2.684, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"model_name\": \"llama3_instruct-70B\", \"coef\": 4.4, \"ci_lower\": 3.473, \"ci_upper\": 5.327, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"model_name\": \"med42-8B\", \"coef\": 2.9667, \"ci_lower\": 2.396, \"ci_upper\": 3.5380000000000003, \"p_value\": 0, \"model_name_custom\": \"Med42 8B\"}, {\"model_name\": \"med42-70B\", \"coef\": 4.8333, \"ci_lower\": 4.021, \"ci_upper\": 5.646, \"p_value\": 0, \"model_name_custom\": \"Med42 70B\"}, {\"model_name\": \"olmo2_instruct-7B\", \"coef\": 3.2333, \"ci_lower\": 2.535, \"ci_upper\": 3.932, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"model_name\": \"olmo2_instruct-13B\", \"coef\": 6.0, \"ci_lower\": 5.118, \"ci_upper\": 6.882, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"model_name\": \"mistral_instruct7B\", \"coef\": 3.9, \"ci_lower\": 3.321, \"ci_upper\": 4.479, \"p_value\": 0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"model_name\": \"openbiollm-8B\", \"coef\": 2.8036000000000003, \"ci_lower\": 2.076, \"ci_upper\": 3.532, \"p_value\": 0, \"model_name_custom\": \"OpenBioLLM 8B\"}, {\"model_name\": \"openbiollm-70B\", \"coef\": 4.4, \"ci_lower\": 3.748, \"ci_upper\": 5.052, \"p_value\": 0, \"model_name_custom\": \"OpenBioLLM 70B\"}, {\"model_name\": \"alpacare-7B\", \"coef\": 6.0937, \"ci_lower\": 5.069, \"ci_upper\": 7.118, \"p_value\": 0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"model_name\": \"llama2_chat-7B\", \"coef\": 3.5, \"ci_lower\": 2.907, \"ci_upper\": 4.093, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"model_name\": \"biomedgpt7B\", \"coef\": 1.2824, \"ci_lower\": 0.908, \"ci_upper\": 1.6560000000000001, \"p_value\": 0, \"model_name_custom\": \"BioMedGPT 7B\"}], \"data-d684fefd2a8cfbdc8777b890f4681082\": [{\"x\": 0.71}], \"data-79df26acf32424da04c414a86a2aea39\": [{\"x\": 0.71, \"y\": \"GPT4o\"}], \"data-cb65bf961175d1be7a6eb8feef57f39f\": [{\"x\": 1.2824, \"text\": \"Less susceptible to spin\"}, {\"x\": 6.0937, \"text\": \"More susceptible to spin\"}], \"data-bc56d21eb652852fb5fd16e0219fda39\": [{\"x\": 0.2, \"text\": \"\\u2190\"}], \"data-f2bbc3422d20d47e11b79ac3e5c3cba7\": [{\"x\": 7.7, \"text\": \"\\u2192\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON data into a DataFrame\n",
    "# this json file was manually created\n",
    "regression_results_df = pd.read_json(\"./eval_outputs/simple_linear_regression_benefit_data.json\", orient=\"index\")\n",
    "\n",
    "# Ensure index is reset and available as a column\n",
    "regression_results_df.reset_index(inplace=True)\n",
    "regression_results_df = regression_results_df.rename(columns={'index': 'model_name'})\n",
    "\n",
    "regression_results_df[\"model_name_custom\"] = regression_results_df[\"model_name\"].map(custom_labels)\n",
    "\n",
    "# Create the Altair chart\n",
    "points = alt.Chart(regression_results_df).mark_point(\n",
    "    filled=True,\n",
    "    color='red',\n",
    "    size=50  # Increase point size\n",
    ").encode(\n",
    "    x=alt.X('coef:Q').title('Coefficient'),\n",
    "    y=alt.Y('model_name_custom:N').title('LLM Name').sort(\n",
    "        field='coef',  # Sort by coefficient values\n",
    "        order='descending'\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Add error bars\n",
    "error_bars = points.mark_rule(\n",
    "    strokeWidth=2  # Increase width of error bars\n",
    ").encode(\n",
    "    x='ci_lower:Q',\n",
    "    x2='ci_upper:Q',\n",
    "    size=alt.value(2)  # Set the width of error bars\n",
    ")\n",
    "\n",
    "# Add vertical line at x = 0.71\n",
    "vertical_line = alt.Chart(pd.DataFrame({'x': [0.71]})).mark_rule(\n",
    "    color='blue',\n",
    "    strokeDash=[4, 4],  # Make it dashed\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Add label for vertical line\n",
    "label = alt.Chart(pd.DataFrame({'x': [0.71], 'y': [regression_results_df['model_name_custom'].iloc[0]]})).mark_text(\n",
    "    text='Human Experts',\n",
    "    align='center',\n",
    "    dx=5,  # Adjust text position\n",
    "    dy=-10,\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y=alt.value(0),  # Adjust position if necessary\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Define custom x-axis labels\n",
    "custom_labels_df = pd.DataFrame({\n",
    "    'x': [regression_results_df['coef'].min(), regression_results_df['coef'].max()],\n",
    "    'text': ['Less susceptible to spin', 'More susceptible to spin']\n",
    "})\n",
    "\n",
    "# Define custom x-axis labels\n",
    "left_arrow_df = pd.DataFrame({\n",
    "    'x': [0.2],\n",
    "    'text': ['←']\n",
    "})\n",
    "\n",
    "# Define custom x-axis labels\n",
    "right_arrow_df = pd.DataFrame({\n",
    "    'x': [7.7],\n",
    "    'text': ['→']\n",
    "})\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_labels = alt.Chart(custom_labels_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=24, # adjust horizontal positioning\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_left_arrow = alt.Chart(left_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=10, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_right_arrow = alt.Chart(right_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=0, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Combine all layers, including the new x-axis labels\n",
    "chart = alt.layer(error_bars, points, vertical_line, label, custom_x_labels, custom_x_left_arrow, custom_x_right_arrow).configure_axis(\n",
    "    labelFontSize=16,\n",
    "    titleFontSize=18\n",
    ").configure_title(\n",
    "    fontSize=20\n",
    ")\n",
    "\n",
    "# # Save to HTML\n",
    "chart.save(\"./plots/simple_regression_benefit_data.html\")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-41a5e43c23b2426d9f81ecf5706e39e4.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-41a5e43c23b2426d9f81ecf5706e39e4.vega-embed details,\n",
       "  #altair-viz-41a5e43c23b2426d9f81ecf5706e39e4.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-41a5e43c23b2426d9f81ecf5706e39e4\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-41a5e43c23b2426d9f81ecf5706e39e4\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-41a5e43c23b2426d9f81ecf5706e39e4\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 18}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"data\": {\"name\": \"data-1292b99921b64b6908a0bdde39c795ed\"}, \"mark\": {\"type\": \"rule\", \"strokeWidth\": 2}, \"encoding\": {\"size\": {\"value\": 2}, \"x\": {\"field\": \"ci_lower\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"ci_upper\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-1292b99921b64b6908a0bdde39c795ed\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"field\": \"coef\", \"title\": \"Coefficient\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-d684fefd2a8cfbdc8777b890f4681082\"}, \"mark\": {\"type\": \"rule\", \"color\": \"blue\", \"strokeDash\": [4, 4], \"strokeWidth\": 2}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-79df26acf32424da04c414a86a2aea39\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"dx\": 5, \"dy\": -10, \"fontSize\": 14, \"fontWeight\": \"bold\", \"text\": \"Human Experts\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"value\": 0}}}, {\"data\": {\"name\": \"data-cb65bf961175d1be7a6eb8feef57f39f\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 24, \"dy\": 195, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-bc56d21eb652852fb5fd16e0219fda39\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 10, \"dy\": 195, \"fontSize\": 24, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-f2bbc3422d20d47e11b79ac3e5c3cba7\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 0, \"dy\": 195, \"fontSize\": 24, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-1292b99921b64b6908a0bdde39c795ed\": [{\"model_name\": \"gpt4o\", \"coef\": 3.1333, \"ci_lower\": 2.442, \"ci_upper\": 3.824, \"p_value\": 0, \"model_name_custom\": \"GPT4o\"}, {\"model_name\": \"gpt4o-mini\", \"coef\": 3.5667, \"ci_lower\": 2.9130000000000003, \"ci_upper\": 4.221, \"p_value\": 0, \"model_name_custom\": \"GPT4o Mini\"}, {\"model_name\": \"gpt35\", \"coef\": 3.9, \"ci_lower\": 3.205, \"ci_upper\": 4.595, \"p_value\": 0, \"model_name_custom\": \"GPT3.5\"}, {\"model_name\": \"gemini_1.5_flash\", \"coef\": 2.5, \"ci_lower\": 1.82, \"ci_upper\": 3.18, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"model_name\": \"gemini_1.5_flash-8B\", \"coef\": 3.0667, \"ci_lower\": 2.517, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"model_name\": \"claude_3.5-sonnet\", \"coef\": 2.5, \"ci_lower\": 1.896, \"ci_upper\": 3.104, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"model_name\": \"claude_3.5-haiku\", \"coef\": 2.9667, \"ci_lower\": 2.317, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"model_name\": \"biomistral7B\", \"coef\": 1.6667, \"ci_lower\": 1.165, \"ci_upper\": 2.169, \"p_value\": 0, \"model_name_custom\": \"BioMistral 7B\"}, {\"model_name\": \"llama2_chat-13B\", \"coef\": 2.9333, \"ci_lower\": 2.351, \"ci_upper\": 3.515, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"model_name\": \"llama2_chat-70B\", \"coef\": 2.6414, \"ci_lower\": 2.17, \"ci_upper\": 3.112, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"model_name\": \"llama3_instruct-8B\", \"coef\": 2.2, \"ci_lower\": 1.716, \"ci_upper\": 2.684, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"model_name\": \"llama3_instruct-70B\", \"coef\": 4.4, \"ci_lower\": 3.473, \"ci_upper\": 5.327, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"model_name\": \"med42-8B\", \"coef\": 2.9667, \"ci_lower\": 2.396, \"ci_upper\": 3.5380000000000003, \"p_value\": 0, \"model_name_custom\": \"Med42 8B\"}, {\"model_name\": \"med42-70B\", \"coef\": 4.8333, \"ci_lower\": 4.021, \"ci_upper\": 5.646, \"p_value\": 0, \"model_name_custom\": \"Med42 70B\"}, {\"model_name\": \"olmo2_instruct-7B\", \"coef\": 3.2333, \"ci_lower\": 2.535, \"ci_upper\": 3.932, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"model_name\": \"olmo2_instruct-13B\", \"coef\": 6.0, \"ci_lower\": 5.118, \"ci_upper\": 6.882, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"model_name\": \"mistral_instruct7B\", \"coef\": 3.9, \"ci_lower\": 3.321, \"ci_upper\": 4.479, \"p_value\": 0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"model_name\": \"openbiollm-8B\", \"coef\": 2.8036000000000003, \"ci_lower\": 2.076, \"ci_upper\": 3.532, \"p_value\": 0, \"model_name_custom\": \"OpenBioLLM 8B\"}, {\"model_name\": \"openbiollm-70B\", \"coef\": 4.4, \"ci_lower\": 3.748, \"ci_upper\": 5.052, \"p_value\": 0, \"model_name_custom\": \"OpenBioLLM 70B\"}, {\"model_name\": \"alpacare-7B\", \"coef\": 6.0937, \"ci_lower\": 5.069, \"ci_upper\": 7.118, \"p_value\": 0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"model_name\": \"llama2_chat-7B\", \"coef\": 3.5, \"ci_lower\": 2.907, \"ci_upper\": 4.093, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"model_name\": \"biomedgpt7B\", \"coef\": 1.2824, \"ci_lower\": 0.908, \"ci_upper\": 1.6560000000000001, \"p_value\": 0, \"model_name_custom\": \"BioMedGPT 7B\"}], \"data-d684fefd2a8cfbdc8777b890f4681082\": [{\"x\": 0.71}], \"data-79df26acf32424da04c414a86a2aea39\": [{\"x\": 0.71, \"y\": \"GPT4o\"}], \"data-cb65bf961175d1be7a6eb8feef57f39f\": [{\"x\": 1.2824, \"text\": \"Less susceptible to spin\"}, {\"x\": 6.0937, \"text\": \"More susceptible to spin\"}], \"data-bc56d21eb652852fb5fd16e0219fda39\": [{\"x\": 0.2, \"text\": \"\\u2190\"}], \"data-f2bbc3422d20d47e11b79ac3e5c3cba7\": [{\"x\": 7.7, \"text\": \"\\u2192\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FOR KAREN\n",
    "\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: CHANGE FILE NAME HERE\n",
    "# Load the JSON data into a DataFrame\n",
    "regression_results_df = pd.read_json(\"./eval_outputs/simple_linear_regression_benefit_data.json\", orient=\"index\")\n",
    "\n",
    "# Ensure index is reset and available as a column\n",
    "regression_results_df.reset_index(inplace=True)\n",
    "regression_results_df = regression_results_df.rename(columns={'index': 'model_name'})\n",
    "\n",
    "regression_results_df[\"model_name_custom\"] = regression_results_df[\"model_name\"].map(custom_labels)\n",
    "\n",
    "# Create the Altair chart\n",
    "points = alt.Chart(regression_results_df).mark_point(\n",
    "    filled=True,\n",
    "    color='red',\n",
    "    size=50  # Increase point size\n",
    ").encode(\n",
    "    x=alt.X('coef:Q').title('Coefficient'),\n",
    "    y=alt.Y('model_name_custom:N').title('LLM Name').sort(\n",
    "        field='coef',  # Sort by coefficient values\n",
    "        order='descending'\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Add error bars\n",
    "error_bars = points.mark_rule(\n",
    "    strokeWidth=2  # Increase width of error bars\n",
    ").encode(\n",
    "    x='ci_lower:Q',\n",
    "    x2='ci_upper:Q',\n",
    "    size=alt.value(2)  # Set the width of error bars\n",
    ")\n",
    "\n",
    "# Add vertical line at x = 0.71\n",
    "# TODO: change the x value to what the human expert values are\n",
    "# 1\t-0.590000\trigor_answer\thuman experts\n",
    "# 2\t-0.380000\timportance_answer\thuman experts\n",
    "# 3\t0.770000\tfull_text_answer\thuman experts\n",
    "# 4\t0.640000\tanother_trial_answer\thuman experts\n",
    "vertical_line = alt.Chart(pd.DataFrame({'x': [0.71]})).mark_rule(\n",
    "    color='blue',\n",
    "    strokeDash=[4, 4],  # Make it dashed\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Add label for vertical line\n",
    "label = alt.Chart(pd.DataFrame({'x': [0.71], 'y': [regression_results_df['model_name_custom'].iloc[0]]})).mark_text(\n",
    "    text='Human Experts',\n",
    "    align='center',\n",
    "    dx=5,  # Adjust text position\n",
    "    dy=-10,\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y=alt.value(0),  # Adjust position if necessary\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Define custom x-axis labels\n",
    "custom_labels_df = pd.DataFrame({\n",
    "    'x': [regression_results_df['coef'].min(), regression_results_df['coef'].max()],\n",
    "    'text': ['Less susceptible to spin', 'More susceptible to spin']\n",
    "})\n",
    "\n",
    "# TODO: hard coded x-axis for the arrows\n",
    "# MIGHT NEED TO ADJUST AS NEEDED\n",
    "# Define custom x-axis labels\n",
    "left_arrow_df = pd.DataFrame({\n",
    "    'x': [0.2],\n",
    "    'text': ['←']\n",
    "})\n",
    "\n",
    "# TODO: hard coded x-axis for the arrows\n",
    "# MIGHT NEED TO ADJUST AS NEEDED\n",
    "# Define custom x-axis labels\n",
    "right_arrow_df = pd.DataFrame({\n",
    "    'x': [7.7],\n",
    "    'text': ['→']\n",
    "})\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_labels = alt.Chart(custom_labels_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=24, # adjust horizontal positioning\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_left_arrow = alt.Chart(left_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=10, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_right_arrow = alt.Chart(right_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=0, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Combine all layers, including the new x-axis labels\n",
    "chart = alt.layer(error_bars, points, vertical_line, label, custom_x_labels, custom_x_left_arrow, custom_x_right_arrow).configure_axis(\n",
    "    labelFontSize=16,\n",
    "    titleFontSize=18\n",
    ").configure_title(\n",
    "    fontSize=20\n",
    ")\n",
    "\n",
    "# Save to HTML\n",
    "# TODO: \n",
    "# CHANGE FILE NAME HERE\n",
    "chart.save(\"./plots/simple_regression_benefit_data.html\")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Spin Detection Results Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer'])\n",
    "\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "        \n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * is_detection_correct\", \n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_binary_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what the model predicts rather than whether it was correct or not\n",
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer'])\n",
    "\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "        \n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * detection_model_prediction\", \n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_binary_direct_model_prediction_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Spin Detection Results Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = gpt_models + huggingface_models # remove no token probability models\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer', 'detection_probability'])\n",
    "        \n",
    "#         # if is_detection_no_spin_correct == 1, then detection_probability. Otherwise, 1 - detection_probability\n",
    "#         measure_data['regression_detection_variable'] = measure_data.apply(lambda x: x['detection_probability'] if x['is_detection_correct'] == 1 else 1 - x['detection_probability'], axis=1)\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "\n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * regression_detection_variable\",\n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_probability_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what the model predicts rather than whether it was correct or not\n",
    "\n",
    "# model_names = gpt_models + huggingface_models # remove no token probability models\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer', 'detection_probability'])\n",
    "        \n",
    "#         # if is_detection_no_spin_correct == 1, then detection_probability. Otherwise, 1 - detection_probability\n",
    "#         measure_data['regression_detection_variable'] = measure_data.apply(lambda x: x['detection_probability'] if x['detection_model_prediction'] == 1 else 1 - x['detection_probability'], axis=1)\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "\n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * regression_detection_variable\",\n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_probability_direct_model_prediction_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS LLM Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_number_of_tokens</th>\n",
       "      <th>sd_number_of_tokens</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpacare-7B</th>\n",
       "      <td>120.416667</td>\n",
       "      <td>56.264936</td>\n",
       "      <td>alpacare-7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomedgpt7B</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>59.498459</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomistral7B</th>\n",
       "      <td>140.766667</td>\n",
       "      <td>73.807941</td>\n",
       "      <td>biomistral7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_3.5-haiku</th>\n",
       "      <td>225.033333</td>\n",
       "      <td>15.084171</td>\n",
       "      <td>claude_3.5-haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_3.5-sonnet</th>\n",
       "      <td>230.516667</td>\n",
       "      <td>19.185491</td>\n",
       "      <td>claude_3.5-sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_1.5_flash</th>\n",
       "      <td>214.216667</td>\n",
       "      <td>30.953778</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_1.5_flash-8B</th>\n",
       "      <td>207.700000</td>\n",
       "      <td>37.768285</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o</th>\n",
       "      <td>207.850000</td>\n",
       "      <td>44.255254</td>\n",
       "      <td>gpt4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o-mini</th>\n",
       "      <td>253.783333</td>\n",
       "      <td>38.084595</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>94.483333</td>\n",
       "      <td>18.754992</td>\n",
       "      <td>gpt35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2_chat-7B</th>\n",
       "      <td>230.450000</td>\n",
       "      <td>32.119270</td>\n",
       "      <td>llama2_chat-7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2_chat-13B</th>\n",
       "      <td>225.733333</td>\n",
       "      <td>31.079397</td>\n",
       "      <td>llama2_chat-13B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2_chat-70B</th>\n",
       "      <td>227.900000</td>\n",
       "      <td>35.466745</td>\n",
       "      <td>llama2_chat-70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3_instruct-8B</th>\n",
       "      <td>266.533333</td>\n",
       "      <td>27.110556</td>\n",
       "      <td>llama3_instruct-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3_instruct-70B</th>\n",
       "      <td>248.816667</td>\n",
       "      <td>40.183534</td>\n",
       "      <td>llama3_instruct-70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med42-8B</th>\n",
       "      <td>172.616667</td>\n",
       "      <td>50.387860</td>\n",
       "      <td>med42-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med42-70B</th>\n",
       "      <td>290.533333</td>\n",
       "      <td>12.620706</td>\n",
       "      <td>med42-70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral_instruct7B</th>\n",
       "      <td>150.833333</td>\n",
       "      <td>55.947942</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olmo2_instruct-7B</th>\n",
       "      <td>282.100000</td>\n",
       "      <td>3.176476</td>\n",
       "      <td>olmo2_instruct-7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olmo2_instruct-13B</th>\n",
       "      <td>272.033333</td>\n",
       "      <td>20.209706</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openbiollm-8B</th>\n",
       "      <td>165.566667</td>\n",
       "      <td>71.853408</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openbiollm-70B</th>\n",
       "      <td>155.400000</td>\n",
       "      <td>54.012097</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     average_number_of_tokens  sd_number_of_tokens  \\\n",
       "alpacare-7B                        120.416667            56.264936   \n",
       "biomedgpt7B                        195.000000            59.498459   \n",
       "biomistral7B                       140.766667            73.807941   \n",
       "claude_3.5-haiku                   225.033333            15.084171   \n",
       "claude_3.5-sonnet                  230.516667            19.185491   \n",
       "gemini_1.5_flash                   214.216667            30.953778   \n",
       "gemini_1.5_flash-8B                207.700000            37.768285   \n",
       "gpt4o                              207.850000            44.255254   \n",
       "gpt4o-mini                         253.783333            38.084595   \n",
       "gpt35                               94.483333            18.754992   \n",
       "llama2_chat-7B                     230.450000            32.119270   \n",
       "llama2_chat-13B                    225.733333            31.079397   \n",
       "llama2_chat-70B                    227.900000            35.466745   \n",
       "llama3_instruct-8B                 266.533333            27.110556   \n",
       "llama3_instruct-70B                248.816667            40.183534   \n",
       "med42-8B                           172.616667            50.387860   \n",
       "med42-70B                          290.533333            12.620706   \n",
       "mistral_instruct7B                 150.833333            55.947942   \n",
       "olmo2_instruct-7B                  282.100000             3.176476   \n",
       "olmo2_instruct-13B                 272.033333            20.209706   \n",
       "openbiollm-8B                      165.566667            71.853408   \n",
       "openbiollm-70B                     155.400000            54.012097   \n",
       "\n",
       "                              model_name  \n",
       "alpacare-7B                  alpacare-7B  \n",
       "biomedgpt7B                  biomedgpt7B  \n",
       "biomistral7B                biomistral7B  \n",
       "claude_3.5-haiku        claude_3.5-haiku  \n",
       "claude_3.5-sonnet      claude_3.5-sonnet  \n",
       "gemini_1.5_flash        gemini_1.5_flash  \n",
       "gemini_1.5_flash-8B  gemini_1.5_flash-8B  \n",
       "gpt4o                              gpt4o  \n",
       "gpt4o-mini                    gpt4o-mini  \n",
       "gpt35                              gpt35  \n",
       "llama2_chat-7B            llama2_chat-7B  \n",
       "llama2_chat-13B          llama2_chat-13B  \n",
       "llama2_chat-70B          llama2_chat-70B  \n",
       "llama3_instruct-8B    llama3_instruct-8B  \n",
       "llama3_instruct-70B  llama3_instruct-70B  \n",
       "med42-8B                        med42-8B  \n",
       "med42-70B                      med42-70B  \n",
       "mistral_instruct7B    mistral_instruct7B  \n",
       "olmo2_instruct-7B      olmo2_instruct-7B  \n",
       "olmo2_instruct-13B    olmo2_instruct-13B  \n",
       "openbiollm-8B              openbiollm-8B  \n",
       "openbiollm-70B            openbiollm-70B  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all PLS outputs from all LLMs\n",
    "enc = tiktoken.get_encoding(\"o200k_base\") # for gpt-4o and gpt-4o mini\n",
    "\n",
    "model_token_stats = {}\n",
    "number_of_tokens_total = [] # for all models\n",
    "for model_name in model_names:\n",
    "    csv_file_path = f\"./pls_outputs/{model_name}/{model_name}_outputs.csv\"\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    # calculate the number of tokens for each row in plain_language_summary\n",
    "    plain_language_summaries = data['plain_language_summary'].tolist()\n",
    "\n",
    "    number_of_tokens = []\n",
    "    for summary in plain_language_summaries:\n",
    "        token_integers = enc.encode(summary)\n",
    "        number_of_tokens.append(len(token_integers))\n",
    "        number_of_tokens_total.append(len(token_integers))\n",
    "\n",
    "    # average number of tokens\n",
    "    average_number_of_tokens = np.mean(number_of_tokens)\n",
    "    # SD of tokens\n",
    "    sd_number_of_tokens = np.std(number_of_tokens)\n",
    "    model_token_stats[model_name] = {\"average_number_of_tokens\": average_number_of_tokens, \"sd_number_of_tokens\": sd_number_of_tokens}\n",
    "\n",
    "model_token_stats_df = pd.DataFrame(model_token_stats).T\n",
    "model_token_stats_df[\"model_name\"] = model_token_stats_df.index\n",
    "\n",
    "model_token_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208.10378787878787, 67.01472464306116)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the average across all\n",
    "average_number_of_tokens = np.mean(number_of_tokens_total)\n",
    "sd_number_of_tokens = np.std(number_of_tokens_total)\n",
    "\n",
    "average_number_of_tokens, sd_number_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208.10378787878787, 37.62843632260712)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average across all models\n",
    "average_number_of_tokens = model_token_stats_df[\"average_number_of_tokens\"].mean()\n",
    "sd_number_of_tokens = model_token_stats_df[\"sd_number_of_tokens\"].mean()\n",
    "\n",
    "average_number_of_tokens, sd_number_of_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following files were manually created\n",
    "claude_evaluator_results = pd.read_json(\"./pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-sonnet_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "gpt4o_mini_evaluator_results = pd.read_json(\"./pls_outputs/_interpretation_eval_results/gpt4o-mini/gpt4o-mini_interpretation_overall_metrics.json\", orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_interval(df, df_column_name):\n",
    "    mean_diff = df[df_column_name].mean()  # Calculate the mean\n",
    "    std_dev = df[df_column_name].std()  # Calculate the standard deviation\n",
    "    n = len(df[df_column_name])  # Sample size\n",
    "\n",
    "    # Calculate the margin of error for 95% CI (z = 1.96)\n",
    "    z = 1.96\n",
    "    margin_of_error = z * (std_dev / sqrt(n))\n",
    "\n",
    "    # Calculate the 95% Confidence Interval\n",
    "    ci_lower = mean_diff - margin_of_error\n",
    "    ci_upper = mean_diff + margin_of_error\n",
    "\n",
    "    return ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.592424</td>\n",
       "      <td>3.573721</td>\n",
       "      <td>3.611128</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.353030</td>\n",
       "      <td>1.332122</td>\n",
       "      <td>1.373939</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.730303</td>\n",
       "      <td>2.707594</td>\n",
       "      <td>2.753012</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.686364</td>\n",
       "      <td>3.655170</td>\n",
       "      <td>3.717557</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.868182</td>\n",
       "      <td>3.840497</td>\n",
       "      <td>3.895866</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric   evaluator\n",
       "0   3.592424  3.573721  3.611128        benefit_answer  GPT4o Mini\n",
       "1   1.353030  1.332122  1.373939          rigor_answer  GPT4o Mini\n",
       "2   2.730303  2.707594  2.753012     importance_answer  GPT4o Mini\n",
       "3   3.686364  3.655170  3.717557      full_text_answer  GPT4o Mini\n",
       "4   3.868182  3.840497  3.895866  another_trial_answer  GPT4o Mini"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "average_model_pls_benefit = gpt4o_mini_evaluator_results[\"benefit_answer_mean_diff\"].mean()\n",
    "ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"benefit_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_rigor = gpt4o_mini_evaluator_results[\"rigor_answer_mean_diff\"].mean()\n",
    "ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"rigor_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_importance = gpt4o_mini_evaluator_results[\"importance_answer_mean_diff\"].mean()\n",
    "ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"importance_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_full_text = gpt4o_mini_evaluator_results[\"full_text_answer_mean_diff\"].mean()\n",
    "ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"full_text_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_another_trial = gpt4o_mini_evaluator_results[\"another_trial_answer_mean_diff\"].mean()\n",
    "ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "gpt4o_mini_pls_model_stats = {\n",
    "    \"benefit_answer\": {\"mean_diff\": average_model_pls_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "    \"rigor_answer\": {\"mean_diff\": average_pls_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "    \"importance_answer\": {\"mean_diff\": average_pls_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "    \"full_text_answer\": {\"mean_diff\": average_pls_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "    \"another_trial_answer\": {\"mean_diff\": average_pls_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "}\n",
    "\n",
    "pls_gpt4o_mini_model_stats_df = pd.DataFrame(gpt4o_mini_pls_model_stats).T\n",
    "pls_gpt4o_mini_model_stats_df[\"metric\"] = pls_gpt4o_mini_model_stats_df.index\n",
    "# remove index\n",
    "pls_gpt4o_mini_model_stats_df.reset_index(drop=True, inplace=True)\n",
    "pls_gpt4o_mini_model_stats_df[\"evaluator\"] = \"GPT4o Mini\"\n",
    "\n",
    "pls_gpt4o_mini_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.471212</td>\n",
       "      <td>2.466320</td>\n",
       "      <td>2.476105</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.175758</td>\n",
       "      <td>-0.182107</td>\n",
       "      <td>-0.169408</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.337879</td>\n",
       "      <td>-0.345682</td>\n",
       "      <td>-0.330075</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.818182</td>\n",
       "      <td>2.804775</td>\n",
       "      <td>2.831589</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.706061</td>\n",
       "      <td>2.687012</td>\n",
       "      <td>2.725109</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric          evaluator\n",
       "0   2.471212  2.466320  2.476105        benefit_answer  Claude 3.5 Sonnet\n",
       "1  -0.175758 -0.182107 -0.169408          rigor_answer  Claude 3.5 Sonnet\n",
       "2  -0.337879 -0.345682 -0.330075     importance_answer  Claude 3.5 Sonnet\n",
       "3   2.818182  2.804775  2.831589      full_text_answer  Claude 3.5 Sonnet\n",
       "4   2.706061  2.687012  2.725109  another_trial_answer  Claude 3.5 Sonnet"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pls_claude_model_stats_df = calculate_model_stats(claude_evaluator_results, method_name = \"Claude 3.5 Sonnet\")\n",
    "\n",
    "pls_claude_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.592424</td>\n",
       "      <td>3.573721</td>\n",
       "      <td>3.611128</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.353030</td>\n",
       "      <td>1.332122</td>\n",
       "      <td>1.373939</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.730303</td>\n",
       "      <td>2.707594</td>\n",
       "      <td>2.753012</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.686364</td>\n",
       "      <td>3.655170</td>\n",
       "      <td>3.717557</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.868182</td>\n",
       "      <td>3.840497</td>\n",
       "      <td>3.895866</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.471212</td>\n",
       "      <td>2.466320</td>\n",
       "      <td>2.476105</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.175758</td>\n",
       "      <td>-0.182107</td>\n",
       "      <td>-0.169408</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.337879</td>\n",
       "      <td>-0.345682</td>\n",
       "      <td>-0.330075</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.818182</td>\n",
       "      <td>2.804775</td>\n",
       "      <td>2.831589</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.706061</td>\n",
       "      <td>2.687012</td>\n",
       "      <td>2.725109</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric          evaluator\n",
       "0   3.592424  3.573721  3.611128        benefit_answer         GPT4o Mini\n",
       "1   1.353030  1.332122  1.373939          rigor_answer         GPT4o Mini\n",
       "2   2.730303  2.707594  2.753012     importance_answer         GPT4o Mini\n",
       "3   3.686364  3.655170  3.717557      full_text_answer         GPT4o Mini\n",
       "4   3.868182  3.840497  3.895866  another_trial_answer         GPT4o Mini\n",
       "5   2.471212  2.466320  2.476105        benefit_answer  Claude 3.5 Sonnet\n",
       "6  -0.175758 -0.182107 -0.169408          rigor_answer  Claude 3.5 Sonnet\n",
       "7  -0.337879 -0.345682 -0.330075     importance_answer  Claude 3.5 Sonnet\n",
       "8   2.818182  2.804775  2.831589      full_text_answer  Claude 3.5 Sonnet\n",
       "9   2.706061  2.687012  2.725109  another_trial_answer  Claude 3.5 Sonnet"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine two dataframes\n",
    "all_pls_model_stats_df = pd.concat([pls_gpt4o_mini_model_stats_df, pls_claude_model_stats_df], ignore_index=True)\n",
    "\n",
    "all_pls_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-f519e01618e648648530d568e281214f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-f519e01618e648648530d568e281214f.vega-embed details,\n",
       "  #altair-viz-f519e01618e648648530d568e281214f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-f519e01618e648648530d568e281214f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f519e01618e648648530d568e281214f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f519e01618e648648530d568e281214f\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"data\": {\"name\": \"data-dd7820b508f2d37605685e43e9aa3a90\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"Benefit\", \"Rigor\", \"Importance\", \"Full-Text\", \"Another Trial\"], \"title\": null, \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"evaluator\", \"legend\": null, \"scale\": {\"domain\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"range\": [\"#0868ac\", \"#43a2ca\"]}, \"title\": \"Evaluator\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"evaluator\", \"sort\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": {\"expr\": \"if((datum.mean_diff >= 0),-1,20)\"}, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"mean_diff\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"evaluator\", \"sort\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"value\": \"gray\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"evaluator\", \"sort\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_lower\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_upper\"}}}], \"height\": 250, \"width\": 120}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-dd7820b508f2d37605685e43e9aa3a90\": [{\"mean_diff\": 3.592424242424241, \"ci_lower\": 3.573720651762486, \"ci_upper\": 3.611127833085996, \"metric\": \"Benefit\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 1.3530303030303024, \"ci_lower\": 1.332121563463645, \"ci_upper\": 1.3739390425969598, \"metric\": \"Rigor\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 2.7303030303030305, \"ci_lower\": 2.70759383884234, \"ci_upper\": 2.7530122217637207, \"metric\": \"Importance\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 3.686363636363637, \"ci_lower\": 3.655170035896047, \"ci_upper\": 3.717557236831227, \"metric\": \"Full-Text\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 3.8681818181818186, \"ci_lower\": 3.8404974942114825, \"ci_upper\": 3.8958661421521548, \"metric\": \"Another Trial\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 2.471212121212122, \"ci_lower\": 2.4663195188992315, \"ci_upper\": 2.4761047235250127, \"metric\": \"Benefit\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": -0.1757575757575753, \"ci_lower\": -0.18210705495937363, \"ci_upper\": -0.169408096555777, \"metric\": \"Rigor\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": -0.33787878787878745, \"ci_lower\": -0.34568223495993894, \"ci_upper\": -0.33007534079763595, \"metric\": \"Importance\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": 2.818181818181818, \"ci_lower\": 2.8047750415739086, \"ci_upper\": 2.8315885947897272, \"metric\": \"Full-Text\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": 2.706060606060605, \"ci_lower\": 2.6870121684552104, \"ci_upper\": 2.725109043666, \"metric\": \"Another Trial\", \"evaluator\": \"Claude 3.5 Sonnet\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create altair grouped barchart\n",
    "# grouped by metric and evaluator\n",
    "\n",
    "# Create a mapping for custom facet titles\n",
    "facet_title_mapping = {\n",
    "    'benefit_answer': 'Benefit',\n",
    "    'rigor_answer': 'Rigor',\n",
    "    'importance_answer': 'Importance',\n",
    "    'full_text_answer': 'Full-Text',\n",
    "    'another_trial_answer': 'Another Trial'\n",
    "}\n",
    "\n",
    "# Define the desired order for the facets\n",
    "facet_order = ['Benefit', 'Rigor', 'Importance', 'Full-Text', 'Another Trial']\n",
    "\n",
    "color_mapping = {\n",
    "    'Claude 3.5 Sonnet': '#0868ac',  \n",
    "    'GPT4o Mini': '#43a2ca',  \n",
    "}\n",
    "\n",
    "method_order = ['Claude 3.5 Sonnet', 'GPT4o Mini']\n",
    "\n",
    "# Apply the mapping as a calculated field\n",
    "chart_data = all_pls_model_stats_df.copy()\n",
    "chart_data['metric'] = chart_data['metric'].map(facet_title_mapping)\n",
    "\n",
    "# Configure global font sizes\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Facet headers\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "bars = alt.Chart(chart_data).mark_bar().encode(\n",
    "    x=alt.X('evaluator:N', title=None, axis=alt.Axis(labelAngle=-45), sort = method_order),\n",
    "    y=alt.Y('mean_diff:Q', title='Mean Difference'),\n",
    "    color=alt.Color('evaluator:N', title='Evaluator', legend=None, scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())))\n",
    ").properties(\n",
    "    width=120,  # Set the width to 300 pixels\n",
    "    height=250  # Set the height to 300 pixels\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "error_bars = alt.Chart(chart_data).mark_errorbar().encode(\n",
    "    alt.X(\"evaluator:N\", sort = method_order),\n",
    "    alt.Y(\"ci_lower:Q\").title(\"Mean Difference\"),\n",
    "    alt.Y2(\"ci_upper:Q\"),\n",
    "    strokeWidth=alt.value(2),\n",
    "    color=alt.value('gray')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontWeight='bold',\n",
    "    dy=alt.expr(expr=alt.expr.if_(alt.datum.mean_diff >= 0, -1, 20))  # Adjust the position of the text    \n",
    ").encode(\n",
    "    text=alt.Text('mean_diff:Q', format='.2f'),\n",
    "    color=alt.value('black')  # Set text color to black\n",
    ")\n",
    "\n",
    "# Combine layers and facet\n",
    "chart = alt.layer(bars, text, error_bars, data=chart_data).facet(\n",
    "    column=alt.Column('metric:N', title=None, sort=facet_order),\n",
    ").configure(**chart_config)  # Apply\n",
    "\n",
    "# save to html\n",
    "chart.save(\"./plots/pls_evaluator_comparison_by_measures.html\")\n",
    "\n",
    "chart\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
