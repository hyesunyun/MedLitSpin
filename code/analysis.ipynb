{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for Calculating Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import altair as alt\n",
    "from utils import save_dataset_to_json, save_dataset_to_csv\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from tqdm import tqdm\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metadata = {\n",
    "    \"alpacare-7B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 7},\n",
    "    \"biomedgpt7B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 7},\n",
    "    \"biomistral7B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 7},\n",
    "    \"claude_3.5-haiku\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None}, # 175?\n",
    "    \"claude_3.5-sonnet\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None}, # 175?\n",
    "    \"gemini_1.5_flash\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None},\n",
    "    \"gemini_1.5_flash-8B\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": 8},\n",
    "    \"gpt4o\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None}, # around 1 trillion (1000B)\n",
    "    \"gpt4o-mini\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": None}, # 175?\n",
    "    \"gpt35\": {\"model_type\": \"generalist closed\", \"model_size_in_b\": 175},\n",
    "    \"llama2_chat-7B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 7},\n",
    "    \"llama2_chat-13B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 13},\n",
    "    \"llama2_chat-70B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 70},\n",
    "    \"llama3_instruct-8B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 8},\n",
    "    \"llama3_instruct-70B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 70},\n",
    "    \"med42-8B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 8},\n",
    "    \"med42-70B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 70},\n",
    "    \"mistral_instruct7B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 7},\n",
    "    \"olmo2_instruct-7B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 7},\n",
    "    \"olmo2_instruct-13B\": {\"model_type\": \"generalist open\", \"model_size_in_b\": 13},\n",
    "    \"openbiollm-8B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 8},\n",
    "    \"openbiollm-70B\": {\"model_type\": \"biomedical open\", \"model_size_in_b\": 70}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spin Detection Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size_in_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>claude_3.5-sonnet</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>claude_3.5-haiku</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>biomistral7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>llama2_chat-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>llama2_chat-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>llama3_instruct-8B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>llama3_instruct-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>med42-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>med42-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>olmo2_instruct-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>alpacare-7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>llama2_chat-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  precision    recall        f1           model_name  \\\n",
       "0   0.783333   0.707317  0.966667  0.816901                gpt4o   \n",
       "1   0.850000   0.783784  0.966667  0.865672           gpt4o-mini   \n",
       "2   0.516667   1.000000  0.033333  0.064516                gpt35   \n",
       "3   0.733333   0.652174  1.000000  0.789474     gemini_1.5_flash   \n",
       "4   0.833333   0.794118  0.900000  0.843750  gemini_1.5_flash-8B   \n",
       "5   0.966667   1.000000  0.933333  0.965517    claude_3.5-sonnet   \n",
       "6   0.566667   0.535714  1.000000  0.697674     claude_3.5-haiku   \n",
       "7   0.516667   1.000000  0.033333  0.064516         biomistral7B   \n",
       "8   0.566667   0.537037  0.966667  0.690476      llama2_chat-13B   \n",
       "9   0.633333   0.580000  0.966667  0.725000      llama2_chat-70B   \n",
       "10  0.833333   1.000000  0.666667  0.800000   llama3_instruct-8B   \n",
       "11  0.833333   1.000000  0.666667  0.800000  llama3_instruct-70B   \n",
       "12  0.583333   1.000000  0.166667  0.285714             med42-8B   \n",
       "13  0.800000   0.909091  0.666667  0.769231            med42-70B   \n",
       "14  0.700000   1.000000  0.400000  0.571429    olmo2_instruct-7B   \n",
       "15  0.516667   1.000000  0.033333  0.064516   olmo2_instruct-13B   \n",
       "16  0.500000   0.000000  0.000000  0.000000   mistral_instruct7B   \n",
       "17  0.508475   0.500000  1.000000  0.666667        openbiollm-8B   \n",
       "18  0.833333   0.857143  0.800000  0.827586       openbiollm-70B   \n",
       "19  0.683333   0.923077  0.400000  0.558140          alpacare-7B   \n",
       "20  0.500000   0.500000  1.000000  0.666667       llama2_chat-7B   \n",
       "21  0.500000   0.500000  0.966667  0.659091          biomedgpt7B   \n",
       "\n",
       "           model_type  model_size_in_b  \n",
       "0   generalist closed              NaN  \n",
       "1   generalist closed              NaN  \n",
       "2   generalist closed            175.0  \n",
       "3   generalist closed              NaN  \n",
       "4   generalist closed              8.0  \n",
       "5   generalist closed              NaN  \n",
       "6   generalist closed              NaN  \n",
       "7     biomedical open              7.0  \n",
       "8     generalist open             13.0  \n",
       "9     generalist open             70.0  \n",
       "10    generalist open              8.0  \n",
       "11    generalist open             70.0  \n",
       "12    biomedical open              8.0  \n",
       "13    biomedical open             70.0  \n",
       "14    generalist open              7.0  \n",
       "15    generalist open             13.0  \n",
       "16    generalist open              7.0  \n",
       "17    biomedical open              8.0  \n",
       "18    biomedical open             70.0  \n",
       "19    biomedical open              7.0  \n",
       "20    generalist open              7.0  \n",
       "21    biomedical open              7.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection_stats_df = pd.read_json(\"./eval_outputs/detection_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "detection_stats_df[\"model_name\"] = detection_stats_df.index\n",
    "detection_stats_df[\"model_type\"] = detection_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "detection_stats_df[\"model_size_in_b\"] = detection_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "detection_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(detection_stats_df)}\")\n",
    "\n",
    "detection_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "detection_stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of accuracy, precision, recall, and F1 score by model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_type  mean_accuracy  std_deviation\n",
      "0    biomedical open       0.632163       0.141272\n",
      "1  generalist closed       0.750000       0.159861\n",
      "2    generalist open       0.635417       0.140418\n"
     ]
    }
   ],
   "source": [
    "# Group by model type and calculate mean accuracy and standard deviation\n",
    "accuracy_by_model_type = detection_stats_df.groupby('model_type')['accuracy'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "accuracy_by_model_type.columns = ['model_type', 'mean_accuracy', 'std_deviation']\n",
    "\n",
    "print(accuracy_by_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_type  mean_precision  std_deviation\n",
      "0    biomedical open        0.812759       0.219535\n",
      "1  generalist closed        0.781872       0.172379\n",
      "2    generalist open        0.702130       0.364676\n"
     ]
    }
   ],
   "source": [
    "# Group by model type and calculate mean precision and standard deviation\n",
    "precision_by_model_type = detection_stats_df.groupby('model_type')['precision'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "precision_by_model_type.columns = ['model_type', 'mean_precision', 'std_deviation']\n",
    "\n",
    "print(precision_by_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_type  mean_recall  std_deviation\n",
      "0    biomedical open     0.576190       0.383799\n",
      "1  generalist closed     0.828571       0.352467\n",
      "2    generalist open     0.587500       0.406666\n"
     ]
    }
   ],
   "source": [
    "# Group by model type and calculate mean recall and standard deviation\n",
    "recall_by_model_type = detection_stats_df.groupby('model_type')['recall'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "recall_by_model_type.columns = ['model_type', 'mean_recall', 'std_deviation']\n",
    "\n",
    "print(recall_by_model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          model_type   mean_f1  std_deviation\n",
      "0    biomedical open  0.547278       0.275737\n",
      "1  generalist closed  0.720501       0.300329\n",
      "2    generalist open  0.539761       0.322221\n"
     ]
    }
   ],
   "source": [
    "# Group by model type and calculate mean f1 and standard deviation\n",
    "f1_by_model_type = detection_stats_df.groupby('model_type')['f1'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "f1_by_model_type.columns = ['model_type', 'mean_f1', 'std_deviation']\n",
    "\n",
    "print(f1_by_model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7dd8c755ee354e099552ca6ecf3d23ec.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7dd8c755ee354e099552ca6ecf3d23ec.vega-embed details,\n",
       "  #altair-viz-7dd8c755ee354e099552ca6ecf3d23ec.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7dd8c755ee354e099552ca6ecf3d23ec\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7dd8c755ee354e099552ca6ecf3d23ec\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7dd8c755ee354e099552ca6ecf3d23ec\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"legend\": {\"direction\": \"horizontal\", \"legendX\": 130, \"legendY\": -45, \"orient\": \"none\", \"titleAnchor\": \"middle\"}, \"scale\": {\"domain\": [\"biomedical open\", \"generalist closed\", \"generalist open\"], \"range\": [\"#0868ac\", \"#7bccc4\", \"#bae4bc\"]}, \"title\": \"Model Type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": \"-x\", \"title\": \"Model Name\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"rule\", \"color\": \"red\"}, \"encoding\": {\"size\": {\"value\": 2}, \"x\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"rule\", \"color\": \"gray\"}, \"encoding\": {\"size\": {\"value\": 2}, \"strokeDash\": {\"value\": [10, 10]}, \"x\": {\"aggregate\": \"min\", \"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"middle\", \"dx\": 20, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": \"-x\", \"title\": \"Model Name\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-c3321923785084b1c147abcaf5231d76\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-c3321923785084b1c147abcaf5231d76\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLM 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLM 70B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary for custom labels\n",
    "custom_labels = {\n",
    "    \"alpacare-7B\": \"AlpaCare 7B\",\n",
    "    \"biomedgpt7B\": \"BioMedGPT 7B\",\n",
    "    \"biomistral7B\": \"BioMistral 7B\",\n",
    "    \"claude_3.5-haiku\": \"Claude3.5 Haiku\", # 175?\n",
    "    \"claude_3.5-sonnet\": \"Claude3.5 Sonnet\", # 175?\n",
    "    \"gemini_1.5_flash\": \"Gemini1.5 Flash\",\n",
    "    \"gemini_1.5_flash-8B\": \"Gemini1.5 Flash 8B\",\n",
    "    \"gpt4o\": \"GPT4o\", # around 1 trillion (1000B)\n",
    "    \"gpt4o-mini\": \"GPT4o Mini\", # 175?\n",
    "    \"gpt35\": \"GPT3.5\",\n",
    "    \"llama2_chat-7B\": \"Llama2 Chat 7B\",\n",
    "    \"llama2_chat-13B\": \"Llama2 Chat 13B\",\n",
    "    \"llama2_chat-70B\": \"Llama2 Chat 70B\",\n",
    "    \"llama3_instruct-8B\": \"Llama3 Instruct 8B\",\n",
    "    \"llama3_instruct-70B\": \"Llama3 Instruct 70B\",\n",
    "    \"med42-8B\": \"Med42 8B\",\n",
    "    \"med42-70B\": \"Med42 70B\",\n",
    "    \"mistral_instruct7B\": \"Mistral Instruct 7B\",\n",
    "    \"olmo2_instruct-7B\": \"Olmo2 Instruct 7B\",\n",
    "    \"olmo2_instruct-13B\": \"Olmo2 Instruct 13B\",\n",
    "    \"openbiollm-8B\": \"OpenBioLM 8B\",\n",
    "    \"openbiollm-70B\": \"OpenBioLM 70B\"\n",
    "}\n",
    "\n",
    "detection_stats_df['model_name_custom'] = detection_stats_df['model_name'].map(custom_labels)\n",
    "\n",
    "color_mapping = {\n",
    "    'biomedical open': '#0868ac', \n",
    "    'generalist closed': '#7bccc4',\n",
    "    'generalist open': '#bae4bc',\n",
    "}\n",
    "\n",
    "# Create the bar chart\n",
    "chart = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    y=alt.Y('model_name_custom:N', sort='-x', title='Model Name'),\n",
    "    x=alt.X('accuracy:Q', title='Accuracy'),\n",
    "    color=alt.Color('model_type:N', title='Model Type',\n",
    "                    scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())),\n",
    "                    legend=alt.Legend(\n",
    "                    orient='none',\n",
    "                    legendX=130, legendY=-45,\n",
    "                    direction='horizontal',\n",
    "                    titleAnchor='middle'))  # Legend at the bottom\n",
    ").properties(\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Add value labels with increased font size\n",
    "text = chart.mark_text(\n",
    "    align='center',\n",
    "    baseline='middle',\n",
    "    fontWeight='bold',\n",
    "    dx=20  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('accuracy:Q', format='.2f'),\n",
    "    color=alt.value('black'),\n",
    ")\n",
    "\n",
    "# Add a mean rule\n",
    "avg_rule = alt.Chart(detection_stats_df).mark_rule(color='red').encode(\n",
    "    x='mean(accuracy):Q',\n",
    "    size=alt.value(2)\n",
    ")\n",
    "\n",
    "# Add a 50% chance rule\n",
    "chance_rule = alt.Chart(detection_stats_df).mark_rule(color='gray').encode(\n",
    "    x='min(accuracy):Q',\n",
    "    size=alt.value(2),\n",
    "    strokeDash=alt.value([10, 10])\n",
    ")\n",
    "\n",
    "# Increase font size for axis labels, titles, and other components\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Title and facet headers (if any)\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Combine chart and text, and apply the config\n",
    "c_t = chart + avg_rule + chance_rule + text\n",
    "c_t = c_t.configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# Save to HTML\n",
    "c_t.save(\"./plots/detection_accuracy_by_model.html\")\n",
    "\n",
    "# Display the chart\n",
    "c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the bar chart\n",
    "# chart = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "#     y=alt.Y('model_name_custom:N', sort='-x', title='Model Name'),\n",
    "#     x=alt.X('accuracy:Q', title='Accuracy'),\n",
    "#    color=alt.Color('model_type:N', title='Model Type', legend=alt.Legend(\n",
    "#         orient='none',\n",
    "#         legendX=130, legendY=-45,\n",
    "#         direction='horizontal',\n",
    "#         titleAnchor='middle'), scale=alt.Scale(range=[\"#808080\", \"#A9A9A9\", \"#D3D3D3\", \"#BEBEBE\"]))  # Legend at the bottom\n",
    "# ).properties(\n",
    "#     width=800,\n",
    "# )\n",
    "\n",
    "# # Add value labels with increased font size\n",
    "# text = chart.mark_text(\n",
    "#     align='center',\n",
    "#     baseline='middle',\n",
    "#     fontWeight='bold',\n",
    "#     dx=18  # Adjust the position of the text\n",
    "# ).encode(\n",
    "#     text=alt.Text('accuracy:Q', format='.2f'),\n",
    "#     color=alt.value('black')  # Set text color to black\n",
    "# )\n",
    "\n",
    "# # Add a mean rule\n",
    "# rule = alt.Chart(detection_stats_df).mark_rule(color='gray').encode(\n",
    "#     x='mean(accuracy):Q',\n",
    "#     size=alt.value(2)\n",
    "# )\n",
    "\n",
    "# # Increase font size for axis labels, titles, and other components\n",
    "# chart_config = {\n",
    "#     \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "#     \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Title and facet headers (if any)\n",
    "#     \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "#     \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "# }\n",
    "\n",
    "# # Combine chart and text, and apply the config\n",
    "# c_t = chart + rule + text\n",
    "# c_t = c_t.configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# # Save to HTML\n",
    "# c_t.save(\"./plots/detection_accuracy_by_model_gray.html\")\n",
    "\n",
    "# # Display the chart\n",
    "# c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-3eb84b9523af4325b1aee67d706c794f.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-3eb84b9523af4325b1aee67d706c794f.vega-embed details,\n",
       "  #altair-viz-3eb84b9523af4325b1aee67d706c794f.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-3eb84b9523af4325b1aee67d706c794f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3eb84b9523af4325b1aee67d706c794f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3eb84b9523af4325b1aee67d706c794f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"legend\": null, \"title\": \"Model Type\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Type\"}, {\"mark\": {\"type\": \"errorbar\", \"extent\": \"stdev\"}, \"encoding\": {\"x\": {\"field\": \"model_type\", \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"legend\": null, \"title\": \"Model Type\", \"type\": \"nominal\"}, \"text\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Type\"}], \"data\": {\"name\": \"data-c3321923785084b1c147abcaf5231d76\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-c3321923785084b1c147abcaf5231d76\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLM 8B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLM 70B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot average accuracy by model_type and add error bars\n",
    "bars = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    x=alt.X('model_type:N', title='Model Type', axis=alt.Axis(labelAngle=0)),\n",
    "    y=alt.Y('mean(accuracy):Q', title='Mean Accuracy'),\n",
    "    color=alt.Color('model_type:N', title='Model Type', legend=None)\n",
    ").properties(\n",
    "    title='Average Accuracy by Model Type',\n",
    "    width=800  # Set the width to 800 pixels\n",
    ")\n",
    "\n",
    "error_bars = alt.Chart(detection_stats_df).mark_errorbar(extent='stdev').encode(\n",
    "    x=alt.X('model_type:N'),\n",
    "    y=alt.Y('accuracy:Q')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-5  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('mean(accuracy):Q', format='.2f')\n",
    ")\n",
    "\n",
    "alt.layer(bars, error_bars, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average of accuracy, precision, recall, and F1 score by model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model size in buckets (0-10B, 11-20B, 22-100B, 100B+/NaN)\n",
    "def model_size_bucket(model_size): \n",
    "    if model_size is None or pd.isna(model_size):\n",
    "        return \"Unknown\"\n",
    "    elif model_size >= 100:\n",
    "        return \"100B+\"\n",
    "    elif model_size <= 10:\n",
    "        return \"0-10B\"\n",
    "    elif model_size <= 20:\n",
    "        return \"11-20B\"\n",
    "    else:\n",
    "        return \"21-100B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_size_bucket  mean_accuracy  std_deviation\n",
      "0             0-10B       0.615847       0.137000\n",
      "1             100B+       0.516667            NaN\n",
      "2            11-20B       0.541667       0.035355\n",
      "3           21-100B       0.775000       0.095743\n",
      "4           Unknown       0.780000       0.147855\n"
     ]
    }
   ],
   "source": [
    "# average accuracy by model size\n",
    "detection_stats_df[\"model_size_bucket\"] = detection_stats_df[\"model_size_in_b\"].map(model_size_bucket)\n",
    "\n",
    "accuracy_by_model_size = detection_stats_df.groupby('model_size_bucket')['accuracy'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "accuracy_by_model_size.columns = ['model_size_bucket', 'mean_accuracy', 'std_deviation']\n",
    "\n",
    "print(accuracy_by_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_size_bucket  mean_precision  std_deviation\n",
      "0             0-10B        0.721719       0.337294\n",
      "1             100B+        1.000000            NaN\n",
      "2            11-20B        0.768519       0.327364\n",
      "3           21-100B        0.836558       0.180942\n",
      "4           Unknown        0.735798       0.173164\n"
     ]
    }
   ],
   "source": [
    "# average precision by model size\n",
    "precision_by_model_size = detection_stats_df.groupby('model_size_bucket')['precision'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "precision_by_model_size.columns = ['model_size_bucket', 'mean_precision', 'std_deviation']\n",
    "\n",
    "print(precision_by_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_size_bucket  mean_recall  std_deviation\n",
      "0             0-10B     0.553333       0.404969\n",
      "1             100B+     0.033333            NaN\n",
      "2            11-20B     0.500000       0.659966\n",
      "3           21-100B     0.775000       0.142400\n",
      "4           Unknown     0.973333       0.027889\n"
     ]
    }
   ],
   "source": [
    "# average recall by model size\n",
    "recall_by_model_size = detection_stats_df.groupby('model_size_bucket')['recall'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "recall_by_model_size.columns = ['model_size_bucket', 'mean_recall', 'std_deviation']\n",
    "\n",
    "print(recall_by_model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_size_bucket   mean_f1  std_deviation\n",
      "0             0-10B  0.511597       0.294719\n",
      "1             100B+  0.064516            NaN\n",
      "2            11-20B  0.377496       0.442621\n",
      "3           21-100B  0.780454       0.043987\n",
      "4           Unknown  0.827048       0.098638\n"
     ]
    }
   ],
   "source": [
    "# average f1 score by model size \n",
    "f1_by_model_size_bucket = detection_stats_df.groupby('model_size_bucket')['f1'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "f1_by_model_size_bucket.columns = ['model_size_bucket', 'mean_f1', 'std_deviation']\n",
    "\n",
    "print(f1_by_model_size_bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-27c11f07aaa54eb8934429d6835d1130.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-27c11f07aaa54eb8934429d6835d1130.vega-embed details,\n",
       "  #altair-viz-27c11f07aaa54eb8934429d6835d1130.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-27c11f07aaa54eb8934429d6835d1130\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-27c11f07aaa54eb8934429d6835d1130\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-27c11f07aaa54eb8934429d6835d1130\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_name\", \"sort\": \"-y\", \"title\": \"Model Name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy by Model Size Bucket\"}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"text\": {\"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"model_name\", \"sort\": \"-y\", \"title\": \"Model Name\", \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Accuracy by Model Size Bucket\"}], \"data\": {\"name\": \"data-17c76e63d35cd08f1dfdf89a32beee6c\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-17c76e63d35cd08f1dfdf89a32beee6c\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\", \"model_size_bucket\": \"100B+\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLM 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLM 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\", \"model_size_bucket\": \"0-10B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    x=alt.X('model_name:N', sort='-y', title='Model Name'),\n",
    "    y=alt.Y('accuracy:Q', title='Accuracy'),\n",
    "    color=alt.Color('model_size_bucket:N', title='Model Size Bucket')\n",
    ").properties(\n",
    "    title='Accuracy by Model Size Bucket',\n",
    "    width=800,\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-5  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('accuracy:Q', format='.2f')\n",
    ")\n",
    "\n",
    "bars + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-13658e2ae476409a848eef192ea399a7.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-13658e2ae476409a848eef192ea399a7.vega-embed details,\n",
       "  #altair-viz-13658e2ae476409a848eef192ea399a7.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-13658e2ae476409a848eef192ea399a7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-13658e2ae476409a848eef192ea399a7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-13658e2ae476409a848eef192ea399a7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"legend\": null, \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_size_bucket\", \"sort\": [\"0-10B\", \"11-20B\", \"21-100B\", \"100B+\", \"Unknown\"], \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Size\"}, {\"mark\": {\"type\": \"errorbar\", \"extent\": \"stdev\"}, \"encoding\": {\"x\": {\"field\": \"model_size_bucket\", \"sort\": [\"0-10B\", \"11-20B\", \"21-100B\", \"100B+\", \"Unknown\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"accuracy\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_size_bucket\", \"legend\": null, \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"text\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": 0}, \"field\": \"model_size_bucket\", \"sort\": [\"0-10B\", \"11-20B\", \"21-100B\", \"100B+\", \"Unknown\"], \"title\": \"Model Size Bucket\", \"type\": \"nominal\"}, \"y\": {\"aggregate\": \"mean\", \"field\": \"accuracy\", \"title\": \"Mean Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Average Accuracy by Model Size\"}], \"data\": {\"name\": \"data-17c76e63d35cd08f1dfdf89a32beee6c\"}, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-17c76e63d35cd08f1dfdf89a32beee6c\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\", \"model_size_bucket\": \"100B+\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLM 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLM 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\", \"model_size_bucket\": \"0-10B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot average accuracy by model_size_bucket and add error bars\n",
    "bars = alt.Chart(detection_stats_df).mark_bar().encode(\n",
    "    x=alt.X('model_size_bucket:N', title='Model Size Bucket', axis=alt.Axis(labelAngle=0), sort=['0-10B', '11-20B', '21-100B', '100B+', 'Unknown']),\n",
    "    y=alt.Y('mean(accuracy):Q', title='Mean Accuracy'),\n",
    "    color=alt.Color('model_size_bucket:N', title='Model Size Bucket', legend=None)\n",
    ").properties(\n",
    "    title='Average Accuracy by Model Size',\n",
    "    width=800  # Set the width to 800 pixels\n",
    ")\n",
    "\n",
    "error_bars = alt.Chart(detection_stats_df).mark_errorbar(extent='stdev').encode(\n",
    "    x=alt.X('model_size_bucket:N', sort=['0-10B', '11-20B', '21-100B', '100B+', 'Unknown']),\n",
    "    y=alt.Y('accuracy:Q')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=-5  # Adjust the position of the text\n",
    ").encode(\n",
    "    text=alt.Text('mean(accuracy):Q', format='.2f')\n",
    ")\n",
    "\n",
    "alt.layer(bars, error_bars, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-4b69f0c327464d1db37df969b7a0e844.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-4b69f0c327464d1db37df969b7a0e844.vega-embed details,\n",
       "  #altair-viz-4b69f0c327464d1db37df969b7a0e844.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-4b69f0c327464d1db37df969b7a0e844\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4b69f0c327464d1db37df969b7a0e844\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4b69f0c327464d1db37df969b7a0e844\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"circle\"}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_size_in_b\", \"title\": \"Model Size (in Billion Parameters)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Model Size vs Accuracy\"}, {\"mark\": {\"type\": \"text\", \"align\": \"left\", \"baseline\": \"middle\", \"dx\": 7, \"dy\": -5}, \"encoding\": {\"color\": {\"field\": \"model_type\", \"title\": \"Model Type\", \"type\": \"nominal\"}, \"text\": {\"field\": \"model_name\", \"type\": \"nominal\"}, \"x\": {\"field\": \"model_size_in_b\", \"title\": \"Model Size (in Billion Parameters)\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"accuracy\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"title\": \"Model Size vs Accuracy\"}], \"data\": {\"name\": \"data-17c76e63d35cd08f1dfdf89a32beee6c\"}, \"height\": 400, \"width\": 800, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-17c76e63d35cd08f1dfdf89a32beee6c\": [{\"accuracy\": 0.7833333333333331, \"precision\": 0.707317073170731, \"recall\": 0.9666666666666661, \"f1\": 0.816901408450704, \"model_name\": \"gpt4o\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.85, \"precision\": 0.7837837837837831, \"recall\": 0.9666666666666661, \"f1\": 0.865671641791044, \"model_name\": \"gpt4o-mini\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"GPT4o Mini\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"gpt35\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 175.0, \"model_name_custom\": \"GPT3.5\", \"model_size_bucket\": \"100B+\"}, {\"accuracy\": 0.7333333333333331, \"precision\": 0.652173913043478, \"recall\": 1.0, \"f1\": 0.7894736842105261, \"model_name\": \"gemini_1.5_flash\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Gemini1.5 Flash\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.794117647058823, \"recall\": 0.9, \"f1\": 0.8437500000000001, \"model_name\": \"gemini_1.5_flash-8B\", \"model_type\": \"generalist closed\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Gemini1.5 Flash 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.9666666666666661, \"precision\": 1.0, \"recall\": 0.9333333333333331, \"f1\": 0.96551724137931, \"model_name\": \"claude_3.5-sonnet\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Sonnet\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.535714285714285, \"recall\": 1.0, \"f1\": 0.6976744186046511, \"model_name\": \"claude_3.5-haiku\", \"model_type\": \"generalist closed\", \"model_size_in_b\": null, \"model_name_custom\": \"Claude3.5 Haiku\", \"model_size_bucket\": \"Unknown\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"biomistral7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMistral 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5666666666666661, \"precision\": 0.5370370370370371, \"recall\": 0.9666666666666661, \"f1\": 0.69047619047619, \"model_name\": \"llama2_chat-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Llama2 Chat 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.6333333333333331, \"precision\": 0.58, \"recall\": 0.9666666666666661, \"f1\": 0.725, \"model_name\": \"llama2_chat-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama2 Chat 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-8B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Llama3 Instruct 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 1.0, \"recall\": 0.6666666666666661, \"f1\": 0.8, \"model_name\": \"llama3_instruct-70B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Llama3 Instruct 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.583333333333333, \"precision\": 1.0, \"recall\": 0.16666666666666602, \"f1\": 0.28571428571428503, \"model_name\": \"med42-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"Med42 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.8, \"precision\": 0.9090909090909091, \"recall\": 0.6666666666666661, \"f1\": 0.769230769230769, \"model_name\": \"med42-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"Med42 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.7000000000000001, \"precision\": 1.0, \"recall\": 0.4, \"f1\": 0.5714285714285711, \"model_name\": \"olmo2_instruct-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Olmo2 Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.516666666666666, \"precision\": 1.0, \"recall\": 0.033333333333333, \"f1\": 0.06451612903225801, \"model_name\": \"olmo2_instruct-13B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 13.0, \"model_name_custom\": \"Olmo2 Instruct 13B\", \"model_size_bucket\": \"11-20B\"}, {\"accuracy\": 0.5, \"precision\": 0.0, \"recall\": 0.0, \"f1\": 0.0, \"model_name\": \"mistral_instruct7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Mistral Instruct 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5084745762711861, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"openbiollm-8B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 8.0, \"model_name_custom\": \"OpenBioLM 8B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.833333333333333, \"precision\": 0.8571428571428571, \"recall\": 0.8, \"f1\": 0.827586206896551, \"model_name\": \"openbiollm-70B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 70.0, \"model_name_custom\": \"OpenBioLM 70B\", \"model_size_bucket\": \"21-100B\"}, {\"accuracy\": 0.683333333333333, \"precision\": 0.923076923076923, \"recall\": 0.4, \"f1\": 0.55813953488372, \"model_name\": \"alpacare-7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"AlpaCare 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 1.0, \"f1\": 0.6666666666666661, \"model_name\": \"llama2_chat-7B\", \"model_type\": \"generalist open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"Llama2 Chat 7B\", \"model_size_bucket\": \"0-10B\"}, {\"accuracy\": 0.5, \"precision\": 0.5, \"recall\": 0.9666666666666661, \"f1\": 0.6590909090909091, \"model_name\": \"biomedgpt7B\", \"model_type\": \"biomedical open\", \"model_size_in_b\": 7.0, \"model_name_custom\": \"BioMedGPT 7B\", \"model_size_bucket\": \"0-10B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scatter plot of model size vs accuracy with model names as labels\n",
    "scatter_plot = alt.Chart(detection_stats_df).mark_circle().encode(\n",
    "    x=alt.X('model_size_in_b:Q', title='Model Size (in Billion Parameters)'),\n",
    "    y=alt.Y('accuracy:Q', title='Accuracy'),\n",
    "    color=alt.Color('model_type:N', title='Model Type')\n",
    ").properties(\n",
    "    title='Model Size vs Accuracy',\n",
    "    width=800,  # Set the width to 800 pixels\n",
    "    height=400  # Set the height to 400 pixels\n",
    ")\n",
    "\n",
    "text = scatter_plot.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=7,  # Adjust the position of the text\n",
    "    dy=-5,  # Adjust the vertical position of the text\n",
    ").encode(\n",
    "    text='model_name:N'\n",
    ")\n",
    "\n",
    "scatter_plot + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RCT Trial Result Interpretation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benefit_answer_mean_diff</th>\n",
       "      <th>rigor_answer_mean_diff</th>\n",
       "      <th>importance_answer_mean_diff</th>\n",
       "      <th>full_text_answer_mean_diff</th>\n",
       "      <th>another_trial_answer_mean_diff</th>\n",
       "      <th>overall_mean_diff_avg</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size_in_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.566667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.113333</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>1.433333</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>2.753333</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>2.253333</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>3.233333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>claude_3.5-sonnet</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.966667</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>1.373333</td>\n",
       "      <td>claude_3.5-haiku</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.051724</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alpacare-7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>1.035714</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.167143</td>\n",
       "      <td>biomistral7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.066667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>1.420000</td>\n",
       "      <td>llama2_chat-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.933333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>2.366667</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>2.186667</td>\n",
       "      <td>llama2_chat-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.689655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>1.004598</td>\n",
       "      <td>llama2_chat-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>llama3_instruct-8B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>llama3_instruct-70B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.966667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.633333</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>1.913333</td>\n",
       "      <td>med42-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>4.366667</td>\n",
       "      <td>4.766667</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>med42-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.233333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>2.013333</td>\n",
       "      <td>olmo2_instruct-7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2.233333</td>\n",
       "      <td>5.466667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.486667</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.736842</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.592593</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.546744</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>1.055556</td>\n",
       "      <td>4.933333</td>\n",
       "      <td>2.204444</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.633333</td>\n",
       "      <td>2.293333</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.240741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    benefit_answer_mean_diff  rigor_answer_mean_diff  \\\n",
       "0                   3.133333                0.100000   \n",
       "1                   3.566667                1.466667   \n",
       "2                   3.900000                1.433333   \n",
       "3                   2.500000               -0.100000   \n",
       "4                   3.066667               -0.100000   \n",
       "5                   2.500000               -0.166667   \n",
       "6                   2.966667               -0.033333   \n",
       "7                   6.051724                0.266667   \n",
       "8                   1.666667                0.350000   \n",
       "9                   3.500000                0.500000   \n",
       "10                  2.933333                0.833333   \n",
       "11                  2.689655                0.000000   \n",
       "12                  2.200000                0.166667   \n",
       "13                  4.400000               -0.033333   \n",
       "14                  2.966667                0.333333   \n",
       "15                  4.833333                0.000000   \n",
       "16                  3.233333                0.466667   \n",
       "17                  6.000000                0.400000   \n",
       "18                  2.736842                0.214286   \n",
       "19                  4.400000                0.000000   \n",
       "20                  3.900000                0.000000   \n",
       "21                  1.240741                0.000000   \n",
       "\n",
       "    importance_answer_mean_diff  full_text_answer_mean_diff  \\\n",
       "0                      1.233333                    2.866667   \n",
       "1                      2.733333                    3.933333   \n",
       "2                      2.066667                    2.600000   \n",
       "3                      2.166667                    3.000000   \n",
       "4                      0.966667                    2.733333   \n",
       "5                     -0.633333                    3.233333   \n",
       "6                      0.466667                    1.300000   \n",
       "7                      0.800000                    0.000000   \n",
       "8                      1.116667                    1.035714   \n",
       "9                      1.066667                    0.333333   \n",
       "10                     2.033333                    2.366667   \n",
       "11                     0.666667                    0.633333   \n",
       "12                     0.900000                    1.500000   \n",
       "13                     0.966667                    3.400000   \n",
       "14                     1.600000                    1.633333   \n",
       "15                     1.366667                    4.366667   \n",
       "16                     1.366667                    2.300000   \n",
       "17                     2.233333                    5.466667   \n",
       "18                     1.592593                    2.440000   \n",
       "19                     0.633333                    1.055556   \n",
       "20                     2.466667                    2.466667   \n",
       "21                     0.000000                   -0.153846   \n",
       "\n",
       "    another_trial_answer_mean_diff  overall_mean_diff_avg  \\\n",
       "0                         3.333333               2.133333   \n",
       "1                         3.866667               3.113333   \n",
       "2                         3.766667               2.753333   \n",
       "3                         3.700000               2.253333   \n",
       "4                         3.433333               2.020000   \n",
       "5                         2.866667               1.560000   \n",
       "6                         2.166667               1.373333   \n",
       "7                              NaN                    NaN   \n",
       "8                         1.666667               1.167143   \n",
       "9                         1.700000               1.420000   \n",
       "10                        2.766667               2.186667   \n",
       "11                        1.033333               1.004598   \n",
       "12                        2.733333               1.500000   \n",
       "13                        4.066667               2.560000   \n",
       "14                        3.033333               1.913333   \n",
       "15                        4.766667               3.066667   \n",
       "16                        2.700000               2.013333   \n",
       "17                        3.333333               3.486667   \n",
       "18                        0.750000               1.546744   \n",
       "19                        4.933333               2.204444   \n",
       "20                        2.633333               2.293333   \n",
       "21                             NaN                    NaN   \n",
       "\n",
       "             model_name         model_type  model_size_in_b  \n",
       "0                 gpt4o  generalist closed              NaN  \n",
       "1            gpt4o-mini  generalist closed              NaN  \n",
       "2                 gpt35  generalist closed            175.0  \n",
       "3      gemini_1.5_flash  generalist closed              NaN  \n",
       "4   gemini_1.5_flash-8B  generalist closed              8.0  \n",
       "5     claude_3.5-sonnet  generalist closed              NaN  \n",
       "6      claude_3.5-haiku  generalist closed              NaN  \n",
       "7           alpacare-7B    biomedical open              7.0  \n",
       "8          biomistral7B    biomedical open              7.0  \n",
       "9        llama2_chat-7B    generalist open              7.0  \n",
       "10      llama2_chat-13B    generalist open             13.0  \n",
       "11      llama2_chat-70B    generalist open             70.0  \n",
       "12   llama3_instruct-8B    generalist open              8.0  \n",
       "13  llama3_instruct-70B    generalist open             70.0  \n",
       "14             med42-8B    biomedical open              8.0  \n",
       "15            med42-70B    biomedical open             70.0  \n",
       "16    olmo2_instruct-7B    generalist open              7.0  \n",
       "17   olmo2_instruct-13B    generalist open             13.0  \n",
       "18        openbiollm-8B    biomedical open              8.0  \n",
       "19       openbiollm-70B    biomedical open             70.0  \n",
       "20   mistral_instruct7B    generalist open              7.0  \n",
       "21          biomedgpt7B    biomedical open              7.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"interpretation_overall_metrics.json\"\n",
    "# \"gold_labelled_interpretation_overall_metrics.json\"\n",
    "# \"model_output_labelled_interpretation_overall_metrics.json\"\n",
    "\n",
    "interpretation_stats_df = pd.read_json(\"./eval_outputs/interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "interpretation_stats_df[\"model_name\"] = interpretation_stats_df.index\n",
    "interpretation_stats_df[\"model_type\"] = interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "interpretation_stats_df[\"model_size_in_b\"] = interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(interpretation_stats_df)}\")\n",
    "\n",
    "interpretation_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.35</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.59</td>\n",
       "      <td>-1.13</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>0.19</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.47</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.31</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric         method\n",
       "0       0.71      0.07      1.35        benefit_answer  human experts\n",
       "1      -0.59     -1.13     -0.05          rigor_answer  human experts\n",
       "2      -0.38     -0.95      0.19     importance_answer  human experts\n",
       "3       0.77      0.08      1.47      full_text_answer  human experts\n",
       "4       0.64     -0.03      1.31  another_trial_answer  human experts"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_expert_stats = {\n",
    "        \"benefit_answer\": {\"mean_diff\": 0.71, \"ci_lower\": 0.07, \"ci_upper\": 1.35},\n",
    "        \"rigor_answer\": {\"mean_diff\": -0.59, \"ci_lower\": -1.13, \"ci_upper\": -0.05},\n",
    "        \"importance_answer\": {\"mean_diff\": -0.38, \"ci_lower\": -0.95, \"ci_upper\": 0.19},\n",
    "        \"full_text_answer\": {\"mean_diff\": 0.77, \"ci_lower\": 0.08, \"ci_upper\": 1.47},\n",
    "        \"another_trial_answer\": {\"mean_diff\": 0.64, \"ci_lower\": -0.03, \"ci_upper\": 1.31}\n",
    "    }\n",
    "\n",
    "human_expert_stats_df = pd.DataFrame(human_expert_stats).T\n",
    "human_expert_stats_df[\"metric\"] = human_expert_stats_df.index\n",
    "# remove index\n",
    "human_expert_stats_df.reset_index(drop=True, inplace=True)\n",
    "human_expert_stats_df[\"method\"] = \"human experts\"\n",
    "\n",
    "human_expert_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_interval(df, df_column_name):\n",
    "    mean_diff = df[df_column_name].mean()  # Calculate the mean\n",
    "    std_dev = df[df_column_name].std()  # Calculate the standard deviation\n",
    "    n = len(df[df_column_name])  # Sample size\n",
    "\n",
    "    # Calculate the margin of error for 95% CI (z = 1.96)\n",
    "    z = 1.96\n",
    "    margin_of_error = z * (std_dev / sqrt(n))\n",
    "\n",
    "    # Calculate the 95% Confidence Interval\n",
    "    ci_lower = mean_diff - margin_of_error\n",
    "    ci_upper = mean_diff + margin_of_error\n",
    "\n",
    "    return ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.381165</td>\n",
       "      <td>2.874680</td>\n",
       "      <td>3.887650</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.277165</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.264057</td>\n",
       "      <td>0.922720</td>\n",
       "      <td>1.605395</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.205034</td>\n",
       "      <td>1.605838</td>\n",
       "      <td>2.804230</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.962500</td>\n",
       "      <td>2.496102</td>\n",
       "      <td>3.428898</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric    method\n",
       "0   3.381165  2.874680  3.887650        benefit_answer  all LLMs\n",
       "1   0.277165  0.088599  0.465730          rigor_answer  all LLMs\n",
       "2   1.264057  0.922720  1.605395     importance_answer  all LLMs\n",
       "3   2.205034  1.605838  2.804230      full_text_answer  all LLMs\n",
       "4   2.962500  2.496102  3.428898  another_trial_answer  all LLMs"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "average_model_benefit = interpretation_stats_df[\"benefit_answer_mean_diff\"].mean()\n",
    "ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(interpretation_stats_df, \"benefit_answer_mean_diff\")\n",
    "\n",
    "average_model_rigor = interpretation_stats_df[\"rigor_answer_mean_diff\"].mean()\n",
    "ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(interpretation_stats_df, \"rigor_answer_mean_diff\")\n",
    "\n",
    "average_model_importance = interpretation_stats_df[\"importance_answer_mean_diff\"].mean()\n",
    "ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(interpretation_stats_df, \"importance_answer_mean_diff\")\n",
    "\n",
    "average_model_full_text = interpretation_stats_df[\"full_text_answer_mean_diff\"].mean()\n",
    "ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(interpretation_stats_df, \"full_text_answer_mean_diff\")\n",
    "\n",
    "average_model_another_trial = interpretation_stats_df[\"another_trial_answer_mean_diff\"].mean()\n",
    "ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(interpretation_stats_df, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "model_stats = {\n",
    "    \"benefit_answer\": {\"mean_diff\": average_model_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "    \"rigor_answer\": {\"mean_diff\": average_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "    \"importance_answer\": {\"mean_diff\": average_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "    \"full_text_answer\": {\"mean_diff\": average_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "    \"another_trial_answer\": {\"mean_diff\": average_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "}\n",
    "\n",
    "model_stats_df = pd.DataFrame(model_stats).T\n",
    "model_stats_df[\"metric\"] = model_stats_df.index\n",
    "# remove index\n",
    "model_stats_df.reset_index(drop=True, inplace=True)\n",
    "model_stats_df[\"method\"] = \"all LLMs\"\n",
    "\n",
    "model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average and 95% CI by model_type from interpretation_stats_df\n",
    "average_benefit_by_model_type = interpretation_stats_df.groupby('model_type')['benefit_answer_mean_diff'].mean().reset_index()\n",
    "average_benefit_by_model_type.columns = ['method', 'mean_diff']\n",
    "ci_lower_benefit_by_model_type, ci_upper_benefit_by_model_type = calculate_confidence_interval(average_benefit_by_model_type, \"mean_diff\")\n",
    "average_benefit_by_model_type['ci_lower'] = ci_lower_benefit_by_model_type\n",
    "average_benefit_by_model_type['ci_upper'] = ci_upper_benefit_by_model_type\n",
    "average_benefit_by_model_type['metric'] = 'benefit_answer'\n",
    "\n",
    "average_rigor_by_model_type = interpretation_stats_df.groupby('model_type')['rigor_answer_mean_diff'].mean().reset_index()\n",
    "average_rigor_by_model_type.columns = ['method', 'mean_diff']\n",
    "ci_lower_rigor_by_model_type, ci_upper_rigor_by_model_type = calculate_confidence_interval(average_rigor_by_model_type, \"mean_diff\")\n",
    "average_rigor_by_model_type['ci_lower'] = ci_lower_rigor_by_model_type\n",
    "average_rigor_by_model_type['ci_upper'] = ci_upper_rigor_by_model_type\n",
    "average_rigor_by_model_type['metric'] = 'rigor_answer'\n",
    "\n",
    "average_importance_by_model_type = interpretation_stats_df.groupby('model_type')['importance_answer_mean_diff'].mean().reset_index()\n",
    "average_importance_by_model_type.columns = ['method', 'mean_diff']\n",
    "ci_lower_importance_by_model_type, ci_upper_importance_by_model_type = calculate_confidence_interval(average_importance_by_model_type, \"mean_diff\")\n",
    "average_importance_by_model_type['ci_lower'] = ci_lower_importance_by_model_type\n",
    "average_importance_by_model_type['ci_upper'] = ci_upper_importance_by_model_type\n",
    "average_importance_by_model_type['metric'] = 'importance_answer'\n",
    "\n",
    "average_full_text_by_model_type = interpretation_stats_df.groupby('model_type')['full_text_answer_mean_diff'].mean().reset_index()\n",
    "average_full_text_by_model_type.columns = ['method', 'mean_diff']\n",
    "ci_lower_full_text_by_model_type, ci_upper_full_text_by_model_type = calculate_confidence_interval(average_full_text_by_model_type, \"mean_diff\")\n",
    "average_full_text_by_model_type['ci_lower'] = ci_lower_full_text_by_model_type\n",
    "average_full_text_by_model_type['ci_upper'] = ci_upper_full_text_by_model_type\n",
    "average_full_text_by_model_type['metric'] = 'full_text_answer'\n",
    "\n",
    "average_another_trial_by_model_type = interpretation_stats_df.groupby('model_type')['another_trial_answer_mean_diff'].mean().reset_index()\n",
    "average_another_trial_by_model_type.columns = ['method', 'mean_diff']\n",
    "ci_lower_another_trial_by_model_type, ci_upper_another_trial_by_model_type = calculate_confidence_interval(average_another_trial_by_model_type, \"mean_diff\")\n",
    "average_another_trial_by_model_type['ci_lower'] = ci_lower_another_trial_by_model_type\n",
    "average_another_trial_by_model_type['ci_upper'] = ci_upper_another_trial_by_model_type\n",
    "average_another_trial_by_model_type['metric'] = 'another_trial_answer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biomedical open</td>\n",
       "      <td>3.413711</td>\n",
       "      <td>3.075071</td>\n",
       "      <td>3.665747</td>\n",
       "      <td>benefit_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generalist closed</td>\n",
       "      <td>3.090476</td>\n",
       "      <td>3.075071</td>\n",
       "      <td>3.665747</td>\n",
       "      <td>benefit_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>generalist open</td>\n",
       "      <td>3.607040</td>\n",
       "      <td>3.075071</td>\n",
       "      <td>3.665747</td>\n",
       "      <td>benefit_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biomedical open</td>\n",
       "      <td>0.166327</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.393473</td>\n",
       "      <td>rigor_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generalist closed</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.393473</td>\n",
       "      <td>rigor_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>generalist open</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.393473</td>\n",
       "      <td>rigor_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biomedical open</td>\n",
       "      <td>1.015608</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.509291</td>\n",
       "      <td>importance_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>generalist closed</td>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.509291</td>\n",
       "      <td>importance_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>generalist open</td>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.509291</td>\n",
       "      <td>importance_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>biomedical open</td>\n",
       "      <td>1.482489</td>\n",
       "      <td>1.441822</td>\n",
       "      <td>2.958409</td>\n",
       "      <td>full_text_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>generalist closed</td>\n",
       "      <td>2.809524</td>\n",
       "      <td>1.441822</td>\n",
       "      <td>2.958409</td>\n",
       "      <td>full_text_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>generalist open</td>\n",
       "      <td>2.308333</td>\n",
       "      <td>1.441822</td>\n",
       "      <td>2.958409</td>\n",
       "      <td>full_text_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>biomedical open</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>2.595747</td>\n",
       "      <td>3.374650</td>\n",
       "      <td>another_trial_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>generalist closed</td>\n",
       "      <td>3.304762</td>\n",
       "      <td>2.595747</td>\n",
       "      <td>3.374650</td>\n",
       "      <td>another_trial_answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>generalist open</td>\n",
       "      <td>2.620833</td>\n",
       "      <td>2.595747</td>\n",
       "      <td>3.374650</td>\n",
       "      <td>another_trial_answer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               method  mean_diff  ci_lower  ci_upper                metric\n",
       "0     biomedical open   3.413711  3.075071  3.665747        benefit_answer\n",
       "1   generalist closed   3.090476  3.075071  3.665747        benefit_answer\n",
       "2     generalist open   3.607040  3.075071  3.665747        benefit_answer\n",
       "3     biomedical open   0.166327  0.159475  0.393473          rigor_answer\n",
       "4   generalist closed   0.371429  0.159475  0.393473          rigor_answer\n",
       "5     generalist open   0.291667  0.159475  0.393473          rigor_answer\n",
       "6     biomedical open   1.015608  0.999924  1.509291     importance_answer\n",
       "7   generalist closed   1.285714  0.999924  1.509291     importance_answer\n",
       "8     generalist open   1.462500  0.999924  1.509291     importance_answer\n",
       "9     biomedical open   1.482489  1.441822  2.958409      full_text_answer\n",
       "10  generalist closed   2.809524  1.441822  2.958409      full_text_answer\n",
       "11    generalist open   2.308333  1.441822  2.958409      full_text_answer\n",
       "12    biomedical open   3.030000  2.595747  3.374650  another_trial_answer\n",
       "13  generalist closed   3.304762  2.595747  3.374650  another_trial_answer\n",
       "14    generalist open   2.620833  2.595747  3.374650  another_trial_answer"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_by_model_type = pd.concat([average_benefit_by_model_type, average_rigor_by_model_type, average_importance_by_model_type, average_full_text_by_model_type, average_another_trial_by_model_type], ignore_index=True)\n",
    "\n",
    "average_by_model_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>benefit</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-1.130000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>rigor</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.380000</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>importance</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>full_text</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.381165</td>\n",
       "      <td>2.874680</td>\n",
       "      <td>3.887650</td>\n",
       "      <td>benefit</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277165</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>rigor</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264057</td>\n",
       "      <td>0.922720</td>\n",
       "      <td>1.605395</td>\n",
       "      <td>importance</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.205034</td>\n",
       "      <td>1.605838</td>\n",
       "      <td>2.804230</td>\n",
       "      <td>full_text</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.962500</td>\n",
       "      <td>2.496102</td>\n",
       "      <td>3.428898</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>all LLMs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.413711</td>\n",
       "      <td>3.075071</td>\n",
       "      <td>3.665747</td>\n",
       "      <td>benefit</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.090476</td>\n",
       "      <td>3.075071</td>\n",
       "      <td>3.665747</td>\n",
       "      <td>benefit</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.607040</td>\n",
       "      <td>3.075071</td>\n",
       "      <td>3.665747</td>\n",
       "      <td>benefit</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.166327</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.393473</td>\n",
       "      <td>rigor</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.393473</td>\n",
       "      <td>rigor</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.159475</td>\n",
       "      <td>0.393473</td>\n",
       "      <td>rigor</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.015608</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.509291</td>\n",
       "      <td>importance</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.285714</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.509291</td>\n",
       "      <td>importance</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.462500</td>\n",
       "      <td>0.999924</td>\n",
       "      <td>1.509291</td>\n",
       "      <td>importance</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.482489</td>\n",
       "      <td>1.441822</td>\n",
       "      <td>2.958409</td>\n",
       "      <td>full_text</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.809524</td>\n",
       "      <td>1.441822</td>\n",
       "      <td>2.958409</td>\n",
       "      <td>full_text</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.308333</td>\n",
       "      <td>1.441822</td>\n",
       "      <td>2.958409</td>\n",
       "      <td>full_text</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.030000</td>\n",
       "      <td>2.595747</td>\n",
       "      <td>3.374650</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>biomedical open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.304762</td>\n",
       "      <td>2.595747</td>\n",
       "      <td>3.374650</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>generalist closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.620833</td>\n",
       "      <td>2.595747</td>\n",
       "      <td>3.374650</td>\n",
       "      <td>another_trial</td>\n",
       "      <td>generalist open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_diff  ci_lower  ci_upper         metric             method\n",
       "0    0.710000  0.070000  1.350000        benefit      human experts\n",
       "1   -0.590000 -1.130000 -0.050000          rigor      human experts\n",
       "2   -0.380000 -0.950000  0.190000     importance      human experts\n",
       "3    0.770000  0.080000  1.470000      full_text      human experts\n",
       "4    0.640000 -0.030000  1.310000  another_trial      human experts\n",
       "5    3.381165  2.874680  3.887650        benefit           all LLMs\n",
       "6    0.277165  0.088599  0.465730          rigor           all LLMs\n",
       "7    1.264057  0.922720  1.605395     importance           all LLMs\n",
       "8    2.205034  1.605838  2.804230      full_text           all LLMs\n",
       "9    2.962500  2.496102  3.428898  another_trial           all LLMs\n",
       "10   3.413711  3.075071  3.665747        benefit    biomedical open\n",
       "11   3.090476  3.075071  3.665747        benefit  generalist closed\n",
       "12   3.607040  3.075071  3.665747        benefit    generalist open\n",
       "13   0.166327  0.159475  0.393473          rigor    biomedical open\n",
       "14   0.371429  0.159475  0.393473          rigor  generalist closed\n",
       "15   0.291667  0.159475  0.393473          rigor    generalist open\n",
       "16   1.015608  0.999924  1.509291     importance    biomedical open\n",
       "17   1.285714  0.999924  1.509291     importance  generalist closed\n",
       "18   1.462500  0.999924  1.509291     importance    generalist open\n",
       "19   1.482489  1.441822  2.958409      full_text    biomedical open\n",
       "20   2.809524  1.441822  2.958409      full_text  generalist closed\n",
       "21   2.308333  1.441822  2.958409      full_text    generalist open\n",
       "22   3.030000  2.595747  3.374650  another_trial    biomedical open\n",
       "23   3.304762  2.595747  3.374650  another_trial  generalist closed\n",
       "24   2.620833  2.595747  3.374650  another_trial    generalist open"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine all the dataframes\n",
    "model_stats_final_df = pd.concat([human_expert_stats_df, model_stats_df, average_by_model_type], ignore_index=True)\n",
    "#drop \"_answer\" from the values in metric column\n",
    "model_stats_final_df['metric'] = model_stats_final_df['metric'].str.replace('_answer', '')\n",
    "\n",
    "model_stats_final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-da3b6566a0b34cf5b5153e0b73e764b7.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-da3b6566a0b34cf5b5153e0b73e764b7.vega-embed details,\n",
       "  #altair-viz-da3b6566a0b34cf5b5153e0b73e764b7.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-da3b6566a0b34cf5b5153e0b73e764b7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-da3b6566a0b34cf5b5153e0b73e764b7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-da3b6566a0b34cf5b5153e0b73e764b7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"data\": {\"name\": \"data-32e8eca4b250bc6aecd8b826acce8eff\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"Treatment Benefit\", \"Study Rigor\", \"Study Importance\", \"Interest to Read Full-Text\", \"Interest to Run Another Trial\"], \"title\": null, \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"method\", \"legend\": null, \"scale\": {\"domain\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"range\": [\"#0868ac\", \"#43a2ca\", \"#7bccc4\", \"#bae4bc\", \"#E3F4D4\"]}, \"title\": \"Method\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"value\": \"gray\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"method\", \"sort\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_lower\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_upper\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": {\"expr\": \"if((datum.mean_diff >= 0),-1,20)\"}, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"mean_diff\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"all LLMs\", \"generalist closed\", \"generalist open\", \"biomedical open\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 300}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-32e8eca4b250bc6aecd8b826acce8eff\": [{\"mean_diff\": 0.71, \"ci_lower\": 0.07, \"ci_upper\": 1.35, \"metric\": \"Treatment Benefit\", \"method\": \"human experts\"}, {\"mean_diff\": -0.59, \"ci_lower\": -1.13, \"ci_upper\": -0.05, \"metric\": \"Study Rigor\", \"method\": \"human experts\"}, {\"mean_diff\": -0.38, \"ci_lower\": -0.95, \"ci_upper\": 0.19, \"metric\": \"Study Importance\", \"method\": \"human experts\"}, {\"mean_diff\": 0.77, \"ci_lower\": 0.08, \"ci_upper\": 1.47, \"metric\": \"Interest to Read Full-Text\", \"method\": \"human experts\"}, {\"mean_diff\": 0.64, \"ci_lower\": -0.03, \"ci_upper\": 1.31, \"metric\": \"Interest to Run Another Trial\", \"method\": \"human experts\"}, {\"mean_diff\": 3.3811649465006997, \"ci_lower\": 2.874679552619501, \"ci_upper\": 3.8876503403818985, \"metric\": \"Treatment Benefit\", \"method\": \"all LLMs\"}, {\"mean_diff\": 0.27716450216450217, \"ci_lower\": 0.08859924356867477, \"ci_upper\": 0.46572976076032957, \"metric\": \"Study Rigor\", \"method\": \"all LLMs\"}, {\"mean_diff\": 1.2640572390572389, \"ci_lower\": 0.9227199205664216, \"ci_upper\": 1.6053945575480562, \"metric\": \"Study Importance\", \"method\": \"all LLMs\"}, {\"mean_diff\": 2.20503441003441, \"ci_lower\": 1.6058384463942166, \"ci_upper\": 2.8042303736746033, \"metric\": \"Interest to Read Full-Text\", \"method\": \"all LLMs\"}, {\"mean_diff\": 2.9625000000000004, \"ci_lower\": 2.4961024839163084, \"ci_upper\": 3.4288975160836923, \"metric\": \"Interest to Run Another Trial\", \"method\": \"all LLMs\"}, {\"mean_diff\": 3.413710521514514, \"ci_lower\": 3.0750707996384445, \"ci_upper\": 3.665747161612063, \"metric\": \"Treatment Benefit\", \"method\": \"biomedical open\"}, {\"mean_diff\": 3.0904761904761906, \"ci_lower\": 3.0750707996384445, \"ci_upper\": 3.665747161612063, \"metric\": \"Treatment Benefit\", \"method\": \"generalist closed\"}, {\"mean_diff\": 3.607040229885057, \"ci_lower\": 3.0750707996384445, \"ci_upper\": 3.665747161612063, \"metric\": \"Treatment Benefit\", \"method\": \"generalist open\"}, {\"mean_diff\": 0.16632653061224487, \"ci_lower\": 0.1594752946526482, \"ci_upper\": 0.39347255115234037, \"metric\": \"Study Rigor\", \"method\": \"biomedical open\"}, {\"mean_diff\": 0.37142857142857144, \"ci_lower\": 0.1594752946526482, \"ci_upper\": 0.39347255115234037, \"metric\": \"Study Rigor\", \"method\": \"generalist closed\"}, {\"mean_diff\": 0.2916666666666665, \"ci_lower\": 0.1594752946526482, \"ci_upper\": 0.39347255115234037, \"metric\": \"Study Rigor\", \"method\": \"generalist open\"}, {\"mean_diff\": 1.0156084656084654, \"ci_lower\": 0.9999238758617582, \"ci_upper\": 1.509291291686742, \"metric\": \"Study Importance\", \"method\": \"biomedical open\"}, {\"mean_diff\": 1.2857142857142854, \"ci_lower\": 0.9999238758617582, \"ci_upper\": 1.509291291686742, \"metric\": \"Study Importance\", \"method\": \"generalist closed\"}, {\"mean_diff\": 1.4624999999999997, \"ci_lower\": 0.9999238758617582, \"ci_upper\": 1.509291291686742, \"metric\": \"Study Importance\", \"method\": \"generalist open\"}, {\"mean_diff\": 1.4824890982033836, \"ci_lower\": 1.4418219871776787, \"ci_upper\": 2.958408840196005, \"metric\": \"Interest to Read Full-Text\", \"method\": \"biomedical open\"}, {\"mean_diff\": 2.8095238095238093, \"ci_lower\": 1.4418219871776787, \"ci_upper\": 2.958408840196005, \"metric\": \"Interest to Read Full-Text\", \"method\": \"generalist closed\"}, {\"mean_diff\": 2.308333333333333, \"ci_lower\": 1.4418219871776787, \"ci_upper\": 2.958408840196005, \"metric\": \"Interest to Read Full-Text\", \"method\": \"generalist open\"}, {\"mean_diff\": 3.0300000000000002, \"ci_lower\": 2.5957465945719913, \"ci_upper\": 3.3746502308248343, \"metric\": \"Interest to Run Another Trial\", \"method\": \"biomedical open\"}, {\"mean_diff\": 3.3047619047619046, \"ci_lower\": 2.5957465945719913, \"ci_upper\": 3.3746502308248343, \"metric\": \"Interest to Run Another Trial\", \"method\": \"generalist closed\"}, {\"mean_diff\": 2.620833333333333, \"ci_lower\": 2.5957465945719913, \"ci_upper\": 3.3746502308248343, \"metric\": \"Interest to Run Another Trial\", \"method\": \"generalist open\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping for custom facet titles\n",
    "facet_title_mapping = {\n",
    "    'benefit': 'Treatment Benefit',\n",
    "    'rigor': 'Study Rigor',\n",
    "    'importance': 'Study Importance',\n",
    "    'full_text': 'Interest to Read Full-Text',\n",
    "    'another_trial': 'Interest to Run Another Trial'\n",
    "}\n",
    "\n",
    "# Define the desired order for the facets\n",
    "facet_order = ['Treatment Benefit', 'Study Rigor', 'Study Importance', 'Interest to Read Full-Text', 'Interest to Run Another Trial']\n",
    "\n",
    "color_mapping = {\n",
    "    'human experts': '#0868ac', \n",
    "    'all LLMs': '#43a2ca',  \n",
    "    'generalist closed': '#7bccc4',  \n",
    "    'generalist open': '#bae4bc',  \n",
    "    'biomedical open': '#E3F4D4'\n",
    "}\n",
    "\n",
    "method_order = ['human experts', 'all LLMs', 'generalist closed', 'generalist open', 'biomedical open']\n",
    "\n",
    "# Apply the mapping as a calculated field\n",
    "chart_data = model_stats_final_df.copy()\n",
    "chart_data['metric'] = chart_data['metric'].map(facet_title_mapping)\n",
    "\n",
    "# Configure global font sizes\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Facet headers\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "bars = alt.Chart(chart_data).mark_bar().encode(\n",
    "    x=alt.X('method:N', title=None, axis=alt.Axis(labelAngle=-45), sort=method_order),\n",
    "    y=alt.Y('mean_diff:Q', title='Mean Difference'),\n",
    "    color=alt.Color('method:N', title='Method', legend=None, scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())))\n",
    ").properties(\n",
    "    width=300,  # Set the width to 300 pixels\n",
    "    height=300  # Set the height to 300 pixels\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "error_bars = alt.Chart(chart_data).mark_errorbar().encode(\n",
    "    alt.X(\"method:N\", sort=method_order),\n",
    "    alt.Y(\"ci_lower:Q\").title(\"Mean Difference\"),\n",
    "    alt.Y2(\"ci_upper:Q\"),\n",
    "    strokeWidth=alt.value(2),\n",
    "    color=alt.value('gray')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontWeight='bold',\n",
    "    dy=alt.expr(expr=alt.expr.if_(alt.datum.mean_diff >= 0, -1, 20))  # Adjust the position of the text    \n",
    ").encode(\n",
    "    text=alt.Text('mean_diff:Q', format='.2f'),\n",
    "    color=alt.value('black')  # Set text color to black\n",
    ")\n",
    "\n",
    "# Combine layers and facet\n",
    "chart = alt.layer(bars, error_bars, text, data=chart_data).facet(\n",
    "    column=alt.Column('metric:N', title=None, sort=facet_order),\n",
    ").configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# save to html\n",
    "chart.save(\"./plots/interpretation_by_measures.html\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigation Strategies Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stats_df['method'] = 'baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 22\n"
     ]
    }
   ],
   "source": [
    "# \"interpretation_overall_metrics.json\"\n",
    "# \"gold_labelled_interpretation_overall_metrics.json\"\n",
    "# \"model_output_labelled_interpretation_overall_metrics.json\"\n",
    "\n",
    "gold_labelled_interpretation_stats_df = pd.read_json(\"./eval_outputs/gold_labelled_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "gold_labelled_interpretation_stats_df[\"model_name\"] = gold_labelled_interpretation_stats_df.index\n",
    "gold_labelled_interpretation_stats_df[\"model_type\"] = gold_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "gold_labelled_interpretation_stats_df[\"model_size_in_b\"] = gold_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "gold_labelled_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(gold_labelled_interpretation_stats_df)}\")\n",
    "\n",
    "gold_labelled_interpretation_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "# gold_labelled_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.939576</td>\n",
       "      <td>1.467239</td>\n",
       "      <td>2.411913</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.432680</td>\n",
       "      <td>-1.804166</td>\n",
       "      <td>-1.061195</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.446717</td>\n",
       "      <td>-0.918034</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287751</td>\n",
       "      <td>-0.257165</td>\n",
       "      <td>0.832668</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.094828</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>1.648284</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric        method\n",
       "0   1.939576  1.467239  2.411913        benefit_answer  + ref labels\n",
       "1  -1.432680 -1.804166 -1.061195          rigor_answer  + ref labels\n",
       "2  -0.446717 -0.918034  0.024599     importance_answer  + ref labels\n",
       "3   0.287751 -0.257165  0.832668      full_text_answer  + ref labels\n",
       "4   1.094828  0.541371  1.648284  another_trial_answer  + ref labels"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "average_model_benefit = gold_labelled_interpretation_stats_df[\"benefit_answer_mean_diff\"].mean()\n",
    "ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(gold_labelled_interpretation_stats_df, \"benefit_answer_mean_diff\")\n",
    "\n",
    "average_model_rigor = gold_labelled_interpretation_stats_df[\"rigor_answer_mean_diff\"].mean()\n",
    "ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(gold_labelled_interpretation_stats_df, \"rigor_answer_mean_diff\")\n",
    "\n",
    "average_model_importance = gold_labelled_interpretation_stats_df[\"importance_answer_mean_diff\"].mean()\n",
    "ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(gold_labelled_interpretation_stats_df, \"importance_answer_mean_diff\")\n",
    "\n",
    "average_model_full_text = gold_labelled_interpretation_stats_df[\"full_text_answer_mean_diff\"].mean()\n",
    "ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(gold_labelled_interpretation_stats_df, \"full_text_answer_mean_diff\")\n",
    "\n",
    "average_model_another_trial = gold_labelled_interpretation_stats_df[\"another_trial_answer_mean_diff\"].mean()\n",
    "ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(gold_labelled_interpretation_stats_df, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "model_stats = {\n",
    "    \"benefit_answer\": {\"mean_diff\": average_model_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "    \"rigor_answer\": {\"mean_diff\": average_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "    \"importance_answer\": {\"mean_diff\": average_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "    \"full_text_answer\": {\"mean_diff\": average_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "    \"another_trial_answer\": {\"mean_diff\": average_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "}\n",
    "\n",
    "gold_labelled_model_stats_df = pd.DataFrame(model_stats).T\n",
    "gold_labelled_model_stats_df[\"metric\"] = gold_labelled_model_stats_df.index\n",
    "# remove index\n",
    "gold_labelled_model_stats_df.reset_index(drop=True, inplace=True)\n",
    "gold_labelled_model_stats_df[\"method\"] = \"+ ref labels\"\n",
    "\n",
    "gold_labelled_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 22\n"
     ]
    }
   ],
   "source": [
    "# \"interpretation_overall_metrics.json\"\n",
    "# \"gold_labelled_interpretation_overall_metrics.json\"\n",
    "# \"model_output_labelled_interpretation_overall_metrics.json\"\n",
    "\n",
    "model_output_labelled_interpretation_stats_df = pd.read_json(\"./eval_outputs/model_output_labelled_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "model_output_labelled_interpretation_stats_df[\"model_name\"] = model_output_labelled_interpretation_stats_df.index\n",
    "model_output_labelled_interpretation_stats_df[\"model_type\"] = model_output_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "model_output_labelled_interpretation_stats_df[\"model_size_in_b\"] = model_output_labelled_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "model_output_labelled_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(model_output_labelled_interpretation_stats_df)}\")\n",
    "\n",
    "model_output_labelled_interpretation_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "# model_output_labelled_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.588531</td>\n",
       "      <td>2.070864</td>\n",
       "      <td>3.106198</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.251387</td>\n",
       "      <td>-0.426146</td>\n",
       "      <td>-0.076627</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.771471</td>\n",
       "      <td>0.488157</td>\n",
       "      <td>1.054785</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.357926</td>\n",
       "      <td>0.830169</td>\n",
       "      <td>1.885683</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.147018</td>\n",
       "      <td>1.642268</td>\n",
       "      <td>2.651768</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric          method\n",
       "0   2.588531  2.070864  3.106198        benefit_answer  + model labels\n",
       "1  -0.251387 -0.426146 -0.076627          rigor_answer  + model labels\n",
       "2   0.771471  0.488157  1.054785     importance_answer  + model labels\n",
       "3   1.357926  0.830169  1.885683      full_text_answer  + model labels\n",
       "4   2.147018  1.642268  2.651768  another_trial_answer  + model labels"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "average_model_benefit = model_output_labelled_interpretation_stats_df[\"benefit_answer_mean_diff\"].mean()\n",
    "ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(model_output_labelled_interpretation_stats_df, \"benefit_answer_mean_diff\")\n",
    "\n",
    "average_model_rigor = model_output_labelled_interpretation_stats_df[\"rigor_answer_mean_diff\"].mean()\n",
    "ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(model_output_labelled_interpretation_stats_df, \"rigor_answer_mean_diff\")\n",
    "\n",
    "average_model_importance = model_output_labelled_interpretation_stats_df[\"importance_answer_mean_diff\"].mean()\n",
    "ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(model_output_labelled_interpretation_stats_df, \"importance_answer_mean_diff\")\n",
    "\n",
    "average_model_full_text = model_output_labelled_interpretation_stats_df[\"full_text_answer_mean_diff\"].mean()\n",
    "ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(model_output_labelled_interpretation_stats_df, \"full_text_answer_mean_diff\")\n",
    "\n",
    "average_model_another_trial = model_output_labelled_interpretation_stats_df[\"another_trial_answer_mean_diff\"].mean()\n",
    "ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(model_output_labelled_interpretation_stats_df, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "model_stats = {\n",
    "    \"benefit_answer\": {\"mean_diff\": average_model_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "    \"rigor_answer\": {\"mean_diff\": average_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "    \"importance_answer\": {\"mean_diff\": average_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "    \"full_text_answer\": {\"mean_diff\": average_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "    \"another_trial_answer\": {\"mean_diff\": average_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "}\n",
    "\n",
    "model_output_labelled_model_stats_df = pd.DataFrame(model_stats).T\n",
    "model_output_labelled_model_stats_df[\"metric\"] = model_output_labelled_model_stats_df.index\n",
    "# remove index\n",
    "model_output_labelled_model_stats_df.reset_index(drop=True, inplace=True)\n",
    "model_output_labelled_model_stats_df[\"method\"] = \"+ model labels\"\n",
    "\n",
    "model_output_labelled_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models: 7\n"
     ]
    }
   ],
   "source": [
    "# \"interpretation_overall_metrics.json\"\n",
    "# \"gold_labelled_interpretation_overall_metrics.json\"\n",
    "# \"model_output_labelled_interpretation_overall_metrics.json\"\n",
    "# \"combined_detection_interpretation_overall_metrics.json\"\n",
    "\n",
    "combined_interpretation_stats_df = pd.read_json(\"./eval_outputs/combined_detection_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "\n",
    "combined_interpretation_stats_df[\"model_name\"] = combined_interpretation_stats_df.index\n",
    "combined_interpretation_stats_df[\"model_type\"] = combined_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_type\"])\n",
    "combined_interpretation_stats_df[\"model_size_in_b\"] = combined_interpretation_stats_df.index.map(lambda x: model_metadata[x][\"model_size_in_b\"])\n",
    "# remove index\n",
    "combined_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Number of models: {len(combined_interpretation_stats_df)}\")\n",
    "\n",
    "combined_interpretation_stats_df.sort_index(inplace=True) # alphabetical order\n",
    "# combined_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.052381</td>\n",
       "      <td>0.497852</td>\n",
       "      <td>1.606910</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.928571</td>\n",
       "      <td>-2.586930</td>\n",
       "      <td>-1.270213</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-1.164081</td>\n",
       "      <td>0.697414</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.842857</td>\n",
       "      <td>-2.216687</td>\n",
       "      <td>0.530972</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.163872</td>\n",
       "      <td>1.474223</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric              method\n",
       "0   1.052381  0.497852  1.606910        benefit_answer  detect + interpret\n",
       "1  -1.928571 -2.586930 -1.270213          rigor_answer  detect + interpret\n",
       "2  -0.233333 -1.164081  0.697414     importance_answer  detect + interpret\n",
       "3  -0.842857 -2.216687  0.530972      full_text_answer  detect + interpret\n",
       "4   0.819048  0.163872  1.474223  another_trial_answer  detect + interpret"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "average_model_benefit = combined_interpretation_stats_df[\"benefit_answer_mean_diff\"].mean()\n",
    "ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(combined_interpretation_stats_df, \"benefit_answer_mean_diff\")\n",
    "\n",
    "average_model_rigor = combined_interpretation_stats_df[\"rigor_answer_mean_diff\"].mean()\n",
    "ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(combined_interpretation_stats_df, \"rigor_answer_mean_diff\")\n",
    "\n",
    "average_model_importance = combined_interpretation_stats_df[\"importance_answer_mean_diff\"].mean()\n",
    "ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(combined_interpretation_stats_df, \"importance_answer_mean_diff\")\n",
    "\n",
    "average_model_full_text = combined_interpretation_stats_df[\"full_text_answer_mean_diff\"].mean()\n",
    "ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(combined_interpretation_stats_df, \"full_text_answer_mean_diff\")\n",
    "\n",
    "average_model_another_trial = combined_interpretation_stats_df[\"another_trial_answer_mean_diff\"].mean()\n",
    "ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(combined_interpretation_stats_df, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "model_stats = {\n",
    "    \"benefit_answer\": {\"mean_diff\": average_model_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "    \"rigor_answer\": {\"mean_diff\": average_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "    \"importance_answer\": {\"mean_diff\": average_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "    \"full_text_answer\": {\"mean_diff\": average_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "    \"another_trial_answer\": {\"mean_diff\": average_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "}\n",
    "\n",
    "combined_interpretation_stats_df = pd.DataFrame(model_stats).T\n",
    "combined_interpretation_stats_df[\"metric\"] = combined_interpretation_stats_df.index\n",
    "# remove index\n",
    "combined_interpretation_stats_df.reset_index(drop=True, inplace=True)\n",
    "combined_interpretation_stats_df[\"method\"] = \"detect + interpret\"\n",
    "\n",
    "combined_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>1.350000</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-1.130000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.380000</td>\n",
       "      <td>-0.950000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>human experts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.381165</td>\n",
       "      <td>2.874680</td>\n",
       "      <td>3.887650</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.277165</td>\n",
       "      <td>0.088599</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.264057</td>\n",
       "      <td>0.922720</td>\n",
       "      <td>1.605395</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.205034</td>\n",
       "      <td>1.605838</td>\n",
       "      <td>2.804230</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.962500</td>\n",
       "      <td>2.496102</td>\n",
       "      <td>3.428898</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.939576</td>\n",
       "      <td>1.467239</td>\n",
       "      <td>2.411913</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.432680</td>\n",
       "      <td>-1.804166</td>\n",
       "      <td>-1.061195</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.446717</td>\n",
       "      <td>-0.918034</td>\n",
       "      <td>0.024599</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.287751</td>\n",
       "      <td>-0.257165</td>\n",
       "      <td>0.832668</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.094828</td>\n",
       "      <td>0.541371</td>\n",
       "      <td>1.648284</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ ref labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.588531</td>\n",
       "      <td>2.070864</td>\n",
       "      <td>3.106198</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.251387</td>\n",
       "      <td>-0.426146</td>\n",
       "      <td>-0.076627</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.771471</td>\n",
       "      <td>0.488157</td>\n",
       "      <td>1.054785</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.357926</td>\n",
       "      <td>0.830169</td>\n",
       "      <td>1.885683</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.147018</td>\n",
       "      <td>1.642268</td>\n",
       "      <td>2.651768</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>+ model labels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.052381</td>\n",
       "      <td>0.497852</td>\n",
       "      <td>1.606910</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-1.928571</td>\n",
       "      <td>-2.586930</td>\n",
       "      <td>-1.270213</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.233333</td>\n",
       "      <td>-1.164081</td>\n",
       "      <td>0.697414</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.842857</td>\n",
       "      <td>-2.216687</td>\n",
       "      <td>0.530972</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.163872</td>\n",
       "      <td>1.474223</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>detect + interpret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_diff  ci_lower  ci_upper                metric              method\n",
       "0    0.710000  0.070000  1.350000        benefit_answer       human experts\n",
       "1   -0.590000 -1.130000 -0.050000          rigor_answer       human experts\n",
       "2   -0.380000 -0.950000  0.190000     importance_answer       human experts\n",
       "3    0.770000  0.080000  1.470000      full_text_answer       human experts\n",
       "4    0.640000 -0.030000  1.310000  another_trial_answer       human experts\n",
       "5    3.381165  2.874680  3.887650        benefit_answer            baseline\n",
       "6    0.277165  0.088599  0.465730          rigor_answer            baseline\n",
       "7    1.264057  0.922720  1.605395     importance_answer            baseline\n",
       "8    2.205034  1.605838  2.804230      full_text_answer            baseline\n",
       "9    2.962500  2.496102  3.428898  another_trial_answer            baseline\n",
       "10   1.939576  1.467239  2.411913        benefit_answer        + ref labels\n",
       "11  -1.432680 -1.804166 -1.061195          rigor_answer        + ref labels\n",
       "12  -0.446717 -0.918034  0.024599     importance_answer        + ref labels\n",
       "13   0.287751 -0.257165  0.832668      full_text_answer        + ref labels\n",
       "14   1.094828  0.541371  1.648284  another_trial_answer        + ref labels\n",
       "15   2.588531  2.070864  3.106198        benefit_answer      + model labels\n",
       "16  -0.251387 -0.426146 -0.076627          rigor_answer      + model labels\n",
       "17   0.771471  0.488157  1.054785     importance_answer      + model labels\n",
       "18   1.357926  0.830169  1.885683      full_text_answer      + model labels\n",
       "19   2.147018  1.642268  2.651768  another_trial_answer      + model labels\n",
       "20   1.052381  0.497852  1.606910        benefit_answer  detect + interpret\n",
       "21  -1.928571 -2.586930 -1.270213          rigor_answer  detect + interpret\n",
       "22  -0.233333 -1.164081  0.697414     importance_answer  detect + interpret\n",
       "23  -0.842857 -2.216687  0.530972      full_text_answer  detect + interpret\n",
       "24   0.819048  0.163872  1.474223  another_trial_answer  detect + interpret"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = pd.concat([human_expert_stats_df, model_stats_df, gold_labelled_model_stats_df, model_output_labelled_model_stats_df, combined_interpretation_stats_df], ignore_index=True)\n",
    "\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-65988e871b88439db4898e79bed8b7a2.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-65988e871b88439db4898e79bed8b7a2.vega-embed details,\n",
       "  #altair-viz-65988e871b88439db4898e79bed8b7a2.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-65988e871b88439db4898e79bed8b7a2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-65988e871b88439db4898e79bed8b7a2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-65988e871b88439db4898e79bed8b7a2\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"data\": {\"name\": \"data-267ab603bf702c099c632cf9bc57409e\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"Treatment Benefit\", \"Study Rigor\", \"Study Importance\", \"Interest to Read Full-Text\", \"Interest to Run Another Trial\"], \"title\": null, \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"method\", \"legend\": null, \"scale\": {\"domain\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"range\": [\"#0868ac\", \"#43a2ca\", \"#7bccc4\", \"#bae4bc\", \"#E3F4D4\"]}, \"title\": \"Method\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"value\": \"gray\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"method\", \"sort\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_lower\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_upper\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": {\"expr\": \"if((datum.mean_diff >= 0),-1,20)\"}, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"mean_diff\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"method\", \"sort\": [\"human experts\", \"baseline\", \"+ ref labels\", \"+ model labels\", \"detect + interpret\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 300}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-267ab603bf702c099c632cf9bc57409e\": [{\"mean_diff\": 0.71, \"ci_lower\": 0.07, \"ci_upper\": 1.35, \"metric\": \"Treatment Benefit\", \"method\": \"human experts\"}, {\"mean_diff\": -0.59, \"ci_lower\": -1.13, \"ci_upper\": -0.05, \"metric\": \"Study Rigor\", \"method\": \"human experts\"}, {\"mean_diff\": -0.38, \"ci_lower\": -0.95, \"ci_upper\": 0.19, \"metric\": \"Study Importance\", \"method\": \"human experts\"}, {\"mean_diff\": 0.77, \"ci_lower\": 0.08, \"ci_upper\": 1.47, \"metric\": \"Interest to Read Full-Text\", \"method\": \"human experts\"}, {\"mean_diff\": 0.64, \"ci_lower\": -0.03, \"ci_upper\": 1.31, \"metric\": \"Interest to Run Another Trial\", \"method\": \"human experts\"}, {\"mean_diff\": 3.3811649465006997, \"ci_lower\": 2.874679552619501, \"ci_upper\": 3.8876503403818985, \"metric\": \"Treatment Benefit\", \"method\": \"baseline\"}, {\"mean_diff\": 0.27716450216450217, \"ci_lower\": 0.08859924356867477, \"ci_upper\": 0.46572976076032957, \"metric\": \"Study Rigor\", \"method\": \"baseline\"}, {\"mean_diff\": 1.2640572390572389, \"ci_lower\": 0.9227199205664216, \"ci_upper\": 1.6053945575480562, \"metric\": \"Study Importance\", \"method\": \"baseline\"}, {\"mean_diff\": 2.20503441003441, \"ci_lower\": 1.6058384463942166, \"ci_upper\": 2.8042303736746033, \"metric\": \"Interest to Read Full-Text\", \"method\": \"baseline\"}, {\"mean_diff\": 2.9625000000000004, \"ci_lower\": 2.4961024839163084, \"ci_upper\": 3.4288975160836923, \"metric\": \"Interest to Run Another Trial\", \"method\": \"baseline\"}, {\"mean_diff\": 1.9395762132604235, \"ci_lower\": 1.4672391057272112, \"ci_upper\": 2.411913320793636, \"metric\": \"Treatment Benefit\", \"method\": \"+ ref labels\"}, {\"mean_diff\": -1.4326802507836989, \"ci_lower\": -1.8041655059964088, \"ci_upper\": -1.061194995570989, \"metric\": \"Study Rigor\", \"method\": \"+ ref labels\"}, {\"mean_diff\": -0.44671717171717157, \"ci_lower\": -0.9180335174395834, \"ci_upper\": 0.024599174005240254, \"metric\": \"Study Importance\", \"method\": \"+ ref labels\"}, {\"mean_diff\": 0.2877514642220523, \"ci_lower\": -0.2571646960797938, \"ci_upper\": 0.8326676245238984, \"metric\": \"Interest to Read Full-Text\", \"method\": \"+ ref labels\"}, {\"mean_diff\": 1.0948275862068964, \"ci_lower\": 0.5413707188866383, \"ci_upper\": 1.6482844535271544, \"metric\": \"Interest to Run Another Trial\", \"method\": \"+ ref labels\"}, {\"mean_diff\": 2.5885309617918306, \"ci_lower\": 2.0708643916172917, \"ci_upper\": 3.1061975319663695, \"metric\": \"Treatment Benefit\", \"method\": \"+ model labels\"}, {\"mean_diff\": -0.2513865444899926, \"ci_lower\": -0.42614574654999465, \"ci_upper\": -0.07662734242999053, \"metric\": \"Study Rigor\", \"method\": \"+ model labels\"}, {\"mean_diff\": 0.7714711214711211, \"ci_lower\": 0.4881574526435565, \"ci_upper\": 1.0547847902986858, \"metric\": \"Study Importance\", \"method\": \"+ model labels\"}, {\"mean_diff\": 1.357926332926333, \"ci_lower\": 0.8301692853415118, \"ci_upper\": 1.885683380511154, \"metric\": \"Interest to Read Full-Text\", \"method\": \"+ model labels\"}, {\"mean_diff\": 2.147018140589569, \"ci_lower\": 1.6422684395758878, \"ci_upper\": 2.65176784160325, \"metric\": \"Interest to Run Another Trial\", \"method\": \"+ model labels\"}, {\"mean_diff\": 1.0523809523809518, \"ci_lower\": 0.497852123353802, \"ci_upper\": 1.6069097814081015, \"metric\": \"Treatment Benefit\", \"method\": \"detect + interpret\"}, {\"mean_diff\": -1.9285714285714284, \"ci_lower\": -2.5869298809754753, \"ci_upper\": -1.2702129761673813, \"metric\": \"Study Rigor\", \"method\": \"detect + interpret\"}, {\"mean_diff\": -0.23333333333333325, \"ci_lower\": -1.164080862453321, \"ci_upper\": 0.6974141957866544, \"metric\": \"Study Importance\", \"method\": \"detect + interpret\"}, {\"mean_diff\": -0.8428571428571426, \"ci_lower\": -2.2166866109525856, \"ci_upper\": 0.5309723252383002, \"metric\": \"Interest to Read Full-Text\", \"method\": \"detect + interpret\"}, {\"mean_diff\": 0.8190476190476187, \"ci_lower\": 0.1638724374980436, \"ci_upper\": 1.4742228005971938, \"metric\": \"Interest to Run Another Trial\", \"method\": \"detect + interpret\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a mapping for custom facet titles\n",
    "facet_title_mapping = {\n",
    "    'benefit_answer': 'Treatment Benefit',\n",
    "    'rigor_answer': 'Study Rigor',\n",
    "    'importance_answer': 'Study Importance',\n",
    "    'full_text_answer': 'Interest to Read Full-Text',\n",
    "    'another_trial_answer': 'Interest to Run Another Trial'\n",
    "}\n",
    "\n",
    "# Define the desired order for the facets\n",
    "facet_order = ['Treatment Benefit', 'Study Rigor', 'Study Importance', 'Interest to Read Full-Text', 'Interest to Run Another Trial']\n",
    "\n",
    "color_mapping = {\n",
    "    'human experts': '#0868ac',  \n",
    "    'baseline': '#43a2ca',  \n",
    "    '+ ref labels': '#7bccc4',  \n",
    "    '+ model labels': '#bae4bc', \n",
    "    'detect + interpret': '#E3F4D4'  \n",
    "}\n",
    "\n",
    "method_order = ['human experts', 'baseline', '+ ref labels', '+ model labels', 'detect + interpret']\n",
    "\n",
    "# Apply the mapping as a calculated field\n",
    "chart_data = all_results.copy()\n",
    "chart_data['metric'] = chart_data['metric'].map(facet_title_mapping)\n",
    "\n",
    "# Configure global font sizes\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Facet headers\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "bars = alt.Chart(chart_data).mark_bar().encode(\n",
    "    x=alt.X('method:N', title=None, axis=alt.Axis(labelAngle=-45), sort = method_order),\n",
    "    y=alt.Y('mean_diff:Q', title='Mean Difference'),\n",
    "    color=alt.Color('method:N', title='Method', legend=None, scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())))\n",
    ").properties(\n",
    "    width=300,  # Set the width to 300 pixels\n",
    "    height=300  # Set the height to 300 pixels\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "error_bars = alt.Chart(chart_data).mark_errorbar().encode(\n",
    "    alt.X(\"method:N\", sort = method_order),\n",
    "    alt.Y(\"ci_lower:Q\").title(\"Mean Difference\"),\n",
    "    alt.Y2(\"ci_upper:Q\"),\n",
    "    strokeWidth=alt.value(2),\n",
    "    color=alt.value('gray')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontWeight='bold',\n",
    "    dy=alt.expr(expr=alt.expr.if_(alt.datum.mean_diff >= 0, -1, 20))  # Adjust the position of the text    \n",
    ").encode(\n",
    "    text=alt.Text('mean_diff:Q', format='.2f'),\n",
    "    color=alt.value('black')  # Set text color to black\n",
    ")\n",
    "\n",
    "# Combine layers and facet\n",
    "chart = alt.layer(bars, error_bars, text, data=chart_data).facet(\n",
    "    column=alt.Column('metric:N', title=None, sort=facet_order),\n",
    ").configure(**chart_config)  # Apply the global configuration\n",
    "\n",
    "# save to html\n",
    "chart.save(\"./plots/interpretation_by_measures_all_methods.html\")\n",
    "\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benefit_answer_mean_diff</th>\n",
       "      <th>rigor_answer_mean_diff</th>\n",
       "      <th>importance_answer_mean_diff</th>\n",
       "      <th>full_text_answer_mean_diff</th>\n",
       "      <th>another_trial_answer_mean_diff</th>\n",
       "      <th>overall_mean_diff_avg</th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size_in_b</th>\n",
       "      <th>method_category</th>\n",
       "      <th>overall_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.133333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.233333</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>2.133333</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.566667</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.933333</td>\n",
       "      <td>3.866667</td>\n",
       "      <td>3.113333</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.900000</td>\n",
       "      <td>1.433333</td>\n",
       "      <td>2.066667</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>3.766667</td>\n",
       "      <td>2.753333</td>\n",
       "      <td>gpt35</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>175.0</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>2.253333</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.066667</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>2.733333</td>\n",
       "      <td>3.433333</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "      <td>generalist closed</td>\n",
       "      <td>8.0</td>\n",
       "      <td>baseline</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>4.633333</td>\n",
       "      <td>-0.233333</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.766667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>13.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>2.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3.304348</td>\n",
       "      <td>-0.068966</td>\n",
       "      <td>1.518519</td>\n",
       "      <td>2.518519</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>8.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>1.814484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3.833333</td>\n",
       "      <td>-0.183333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>70.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>1.999744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2.866667</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "      <td>generalist open</td>\n",
       "      <td>7.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>1.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "      <td>biomedical open</td>\n",
       "      <td>7.0</td>\n",
       "      <td>model_output_labelled</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    benefit_answer_mean_diff  rigor_answer_mean_diff  \\\n",
       "0                   3.133333                0.100000   \n",
       "1                   3.566667                1.466667   \n",
       "2                   3.900000                1.433333   \n",
       "3                   2.500000               -0.100000   \n",
       "4                   3.066667               -0.100000   \n",
       "..                       ...                     ...   \n",
       "61                  4.633333               -0.233333   \n",
       "62                  3.304348               -0.068966   \n",
       "63                  3.833333               -0.183333   \n",
       "64                  2.866667               -0.133333   \n",
       "65                  0.000000               -1.000000   \n",
       "\n",
       "    importance_answer_mean_diff  full_text_answer_mean_diff  \\\n",
       "0                      1.233333                    2.866667   \n",
       "1                      2.733333                    3.933333   \n",
       "2                      2.066667                    2.600000   \n",
       "3                      2.166667                    3.000000   \n",
       "4                      0.966667                    2.733333   \n",
       "..                          ...                         ...   \n",
       "61                     1.366667                    1.900000   \n",
       "62                     1.518519                    2.518519   \n",
       "63                     1.000000                    0.615385   \n",
       "64                     1.533333                    2.600000   \n",
       "65                     0.000000                   -2.333333   \n",
       "\n",
       "    another_trial_answer_mean_diff  overall_mean_diff_avg  \\\n",
       "0                         3.333333               2.133333   \n",
       "1                         3.866667               3.113333   \n",
       "2                         3.766667               2.753333   \n",
       "3                         3.700000               2.253333   \n",
       "4                         3.433333               2.020000   \n",
       "..                             ...                    ...   \n",
       "61                        2.766667                    NaN   \n",
       "62                        1.800000                    NaN   \n",
       "63                        4.733333                    NaN   \n",
       "64                        2.333333                    NaN   \n",
       "65                             NaN                    NaN   \n",
       "\n",
       "             model_name         model_type  model_size_in_b  \\\n",
       "0                 gpt4o  generalist closed              NaN   \n",
       "1            gpt4o-mini  generalist closed              NaN   \n",
       "2                 gpt35  generalist closed            175.0   \n",
       "3      gemini_1.5_flash  generalist closed              NaN   \n",
       "4   gemini_1.5_flash-8B  generalist closed              8.0   \n",
       "..                  ...                ...              ...   \n",
       "61   olmo2_instruct-13B    generalist open             13.0   \n",
       "62        openbiollm-8B    biomedical open              8.0   \n",
       "63       openbiollm-70B    biomedical open             70.0   \n",
       "64   mistral_instruct7B    generalist open              7.0   \n",
       "65          biomedgpt7B    biomedical open              7.0   \n",
       "\n",
       "          method_category  overall_avg  \n",
       "0                baseline          NaN  \n",
       "1                baseline          NaN  \n",
       "2                baseline          NaN  \n",
       "3                baseline          NaN  \n",
       "4                baseline          NaN  \n",
       "..                    ...          ...  \n",
       "61  model_output_labelled     2.086667  \n",
       "62  model_output_labelled     1.814484  \n",
       "63  model_output_labelled     1.999744  \n",
       "64  model_output_labelled     1.840000  \n",
       "65  model_output_labelled          NaN  \n",
       "\n",
       "[66 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpretation_stats_df[\"method_category\"] = \"baseline\"\n",
    "gold_labelled_interpretation_stats_df[\"method_category\"] = \"gold_labelled\"\n",
    "model_output_labelled_interpretation_stats_df[\"method_category\"] = \"model_output_labelled\"\n",
    "\n",
    "all_interpretation_stats_df = pd.concat([interpretation_stats_df, gold_labelled_interpretation_stats_df, model_output_labelled_interpretation_stats_df], ignore_index=True)\n",
    "\n",
    "all_interpretation_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               OLS Regression Results                               \n",
      "====================================================================================\n",
      "Dep. Variable:     benefit_answer_mean_diff   R-squared:                       0.203\n",
      "Model:                                  OLS   Adj. R-squared:                  0.178\n",
      "Method:                       Least Squares   F-statistic:                     8.036\n",
      "Date:                      Mon, 03 Feb 2025   Prob (F-statistic):           0.000779\n",
      "Time:                              17:25:07   Log-Likelihood:                -103.85\n",
      "No. Observations:                        66   AIC:                             213.7\n",
      "Df Residuals:                            63   BIC:                             220.3\n",
      "Df Model:                                 2                                         \n",
      "Covariance Type:                  nonrobust                                         \n",
      "============================================================================================================\n",
      "                                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                    3.3812      0.255     13.275      0.000       2.872       3.890\n",
      "method_category[T.gold_labelled]            -1.4416      0.360     -4.002      0.000      -2.161      -0.722\n",
      "method_category[T.model_output_labelled]    -0.7926      0.360     -2.201      0.031      -1.512      -0.073\n",
      "==============================================================================\n",
      "Omnibus:                        1.583   Durbin-Watson:                   1.877\n",
      "Prob(Omnibus):                  0.453   Jarque-Bera (JB):                1.560\n",
      "Skew:                           0.291   Prob(JB):                        0.458\n",
      "Kurtosis:                       2.523   Cond. No.                         3.73\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multiple Comparison of Means - Tukey HSD, FWER=0.05</caption>\n",
       "<tr>\n",
       "     <th>group1</th>            <th>group2</th>         <th>meandiff</th>  <th>p-adj</th>  <th>lower</th>   <th>upper</th> <th>reject</th>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>baseline</td>        <td>gold_labelled</td>      <td>-1.4416</td> <td>0.0005</td> <td>-2.3062</td> <td>-0.577</td>  <td>True</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>baseline</td>    <td>model_output_labelled</td>  <td>-0.7926</td> <td>0.0789</td> <td>-1.6572</td> <td>0.0719</td>  <td>False</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>gold_labelled</td> <td>model_output_labelled</td>   <td>0.649</td>  <td>0.1773</td> <td>-0.2156</td> <td>1.5135</td>  <td>False</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{ccccccc}\n",
       "\\toprule\n",
       "\\textbf{group1} &     \\textbf{group2}     & \\textbf{meandiff} & \\textbf{p-adj} & \\textbf{lower} & \\textbf{upper} & \\textbf{reject}  \\\\\n",
       "\\midrule\n",
       "    baseline    &      gold\\_labelled     &      -1.4416      &     0.0005     &    -2.3062     &     -0.577     &       True       \\\\\n",
       "    baseline    & model\\_output\\_labelled &      -0.7926      &     0.0789     &    -1.6572     &     0.0719     &      False       \\\\\n",
       " gold\\_labelled & model\\_output\\_labelled &       0.649       &     0.1773     &    -0.2156     &     1.5135     &      False       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Multiple Comparison of Means - Tukey HSD, FWER=0.05}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model = smf.ols(formula=\"benefit_answer_mean_diff ~ method_category\", \n",
    "                            data=all_interpretation_stats_df)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "\n",
    "tukey_oneway = pairwise_tukeyhsd(endog = all_interpretation_stats_df[\"benefit_answer_mean_diff\"], groups = all_interpretation_stats_df[\"method_category\"])\n",
    "\n",
    "# Display the results\n",
    "tukey_oneway.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relationship between spin detection and spin interpretation\n",
    "\n",
    "Linear Regression with statsmodels Python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all model names\n",
    "model_names = model_metadata.keys()\n",
    "# remove alpacare-13B\n",
    "model_names = [x for x in model_names if x != \"alpacare-13B\"]\n",
    "\n",
    "len(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\"]\n",
    "gpt_models = [\"gpt4o\", \"gpt4o-mini\", \"gpt35\"]\n",
    "huggingface_models = [\"alpacare-7B\", \"biomedgpt7B\", \"biomistral7B\", \n",
    "                      \"llama2_chat-7B\", \"llama2_chat-13B\", \"llama2_chat-70B\",\n",
    "                      \"llama3_instruct-8B\", \"llama3_instruct-70B\",\n",
    "                      \"med42-8B\", \"med42-70B\", \"mistral_instruct7B\", \n",
    "                      \"olmo2_instruct-7B\", \"olmo2_instruct-13B\",\n",
    "                      \"openbiollm-8B\", \"openbiollm-70B\"]\n",
    "no_probability_models = [\"claude_3.5-haiku\", \"claude_3.5-sonnet\", \"gemini_1.5_flash\", \"gemini_1.5_flash-8B\"]\n",
    "\n",
    "def get_is_detection_correct(row):\n",
    "    if row['abstract_type'] == \"spin\":\n",
    "        return row['model_answer'] == \"yes\"\n",
    "    else:\n",
    "        return row['model_answer'] == \"no\"\n",
    "    \n",
    "def get_is_abstract_type_spin(row):\n",
    "    return row['abstract_type'] == \"spin\"\n",
    "    \n",
    "def detection_probability_gpt(row):\n",
    "    # find the first instance of \"yes\" or \"no\"\n",
    "    token_probabilties = row['model_log_probabilities']\n",
    "    for token_prob in token_probabilties:\n",
    "        if token_prob['token'].lower() == \"yes\":\n",
    "            return np.exp(token_prob['logprob'])\n",
    "        elif token_prob['token'].lower() == \"no\":\n",
    "            return np.exp(token_prob['logprob'])\n",
    "    return None # this should not happen but just in case\n",
    "\n",
    "def detection_probability_huggingface(row):\n",
    "    # find the first instance of \"yes\" or \"no\"\n",
    "    token_probabilties = row['model_log_probabilities']\n",
    "    for token_prob in token_probabilties:\n",
    "        if token_prob['token_string'].lower() == \"yes\":\n",
    "            return token_prob['probability']\n",
    "        elif token_prob['token_string'].lower() == \"no\":\n",
    "            return token_prob['probability']\n",
    "    return None # this should not happen but just in case\n",
    "\n",
    "\n",
    "def prepare_data_for_regression(model_names):\n",
    "    for model_name in tqdm(model_names):\n",
    "        # print(f\"Processing {model_name}...\")\n",
    "        final_data = []\n",
    "        detection_output_file_path = f\"./eval_outputs/{model_name}/{model_name}_detection_outputs.json\"\n",
    "        interpretation_output_file_path = f\"./eval_outputs/{model_name}/{model_name}_interpretation_outputs.json\"\n",
    "        model_detection_data = pd.read_json(detection_output_file_path, orient=\"records\")\n",
    "        model_interpretation_data = pd.read_json(interpretation_output_file_path, orient=\"records\")\n",
    "\n",
    "        # merge model_detection_data and model_interpretation_data by PMID and abstract_type\n",
    "        model_data = pd.merge(model_detection_data, model_interpretation_data, on=['PMID', 'abstract_type'])\n",
    "\n",
    "        # loop through each row in model_data\n",
    "        for _, row in model_data.iterrows():\n",
    "            detection_model_prediction = 1 if row['model_answer'] == \"yes\" else 0\n",
    "            is_detection_correct = 1 if get_is_detection_correct(row) else 0\n",
    "            is_spin_in_abstract = 1 if get_is_abstract_type_spin(row) else 0\n",
    "\n",
    "            if model_name in gpt_models:\n",
    "                detection_probability = detection_probability_gpt(row)\n",
    "            elif model_name in huggingface_models:\n",
    "                detection_probability = detection_probability_huggingface(row)\n",
    "            else:\n",
    "                detection_probability = None\n",
    "            \n",
    "            for measure in measures:\n",
    "                final_data.append({\n",
    "                    \"pmid\": row['PMID'],\n",
    "                    \"measure\": measure,\n",
    "                    \"is_spin_in_abstract\": is_spin_in_abstract,\n",
    "                    \"is_detection_correct\": is_detection_correct,\n",
    "                    \"detection_model_prediction\": detection_model_prediction,\n",
    "                    \"detection_probability\": detection_probability,\n",
    "                    \"interpretation_answer\": float(row[measure]) if row[measure] != \"\" else None\n",
    "                })\n",
    "            # calculate the average of the differences\n",
    "            answers = []\n",
    "            for measure in measures:\n",
    "                if row[measure] != \"\":\n",
    "                    answers.append(float(row[measure]))\n",
    "            if len(answers) > 0:\n",
    "                avg_answer= round(np.mean(answers), 6)\n",
    "            else:\n",
    "                avg_answer = None\n",
    "            # add the average difference to the data\n",
    "            final_data.append({\n",
    "                \"pmid\": row['PMID'],\n",
    "                \"measure\": \"overall\",\n",
    "                \"is_spin_in_abstract\": is_spin_in_abstract,\n",
    "                \"is_detection_correct\": is_detection_correct,\n",
    "                \"detection_model_prediction\": detection_model_prediction,\n",
    "                \"detection_probability\": detection_probability,\n",
    "                \"interpretation_answer\": avg_answer\n",
    "            })\n",
    "\n",
    "        # save the final data to a json file\n",
    "        json_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "        save_dataset_to_csv(final_data, json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 14.44it/s]\n"
     ]
    }
   ],
   "source": [
    "prepare_data_for_regression(model_names=model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simplest Regression\n",
    "\n",
    "Is spin in abstract and the measures answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1872: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return self.mse_model/self.mse_resid\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:958: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/stats/stattools.py:50: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dw = np.sum(diff_resids**2, axis=axis) / np.sum(resids**2, axis=axis)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 2 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1967: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/scipy/stats/_stats_py.py:1971: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
      "  k, _ = kurtosistest(a, axis)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/scipy/stats/_stats_py.py:1971: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n",
      "  k, _ = kurtosistest(a, axis)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 5 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/statsmodels/regression/linear_model.py:1783: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    }
   ],
   "source": [
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer'])\n",
    "\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "        \n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract\", \n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_simple_regression_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forest Plot for \"Benefit\" Linear Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-338065f70377409baff3eba285f5bd96.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-338065f70377409baff3eba285f5bd96.vega-embed details,\n",
       "  #altair-viz-338065f70377409baff3eba285f5bd96.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-338065f70377409baff3eba285f5bd96\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-338065f70377409baff3eba285f5bd96\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-338065f70377409baff3eba285f5bd96\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 18}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"data\": {\"name\": \"data-a762c000186ae17b96df0ffc2c591269\"}, \"mark\": {\"type\": \"rule\", \"strokeWidth\": 2}, \"encoding\": {\"size\": {\"value\": 2}, \"x\": {\"field\": \"ci_lower\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"ci_upper\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-a762c000186ae17b96df0ffc2c591269\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"field\": \"coef\", \"title\": \"Coefficient\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-9086b5e891c6c4446ad27d61d4c923dc\"}, \"mark\": {\"type\": \"rule\", \"color\": \"blue\", \"strokeDash\": [4, 4], \"strokeWidth\": 2}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-52199a530ed2c15d41318ee1174bade9\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"dx\": 5, \"dy\": -10, \"fontSize\": 14, \"fontWeight\": \"bold\", \"text\": \"Human Experts\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"value\": 0}}}, {\"data\": {\"name\": \"data-949e324d51a30a65027cdc3f88ce63f9\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 24, \"dy\": 195, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-83c6355aa736c88d3e2010b970158443\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 10, \"dy\": 195, \"fontSize\": 24, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-d2787f2bd346c2865d5883806d3aca5e\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 0, \"dy\": 195, \"fontSize\": 24, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-a762c000186ae17b96df0ffc2c591269\": [{\"model_name\": \"gpt4o\", \"coef\": 3.1333, \"ci_lower\": 2.442, \"ci_upper\": 3.824, \"p_value\": 0, \"model_name_custom\": \"GPT4o\"}, {\"model_name\": \"gpt4o-mini\", \"coef\": 3.5667, \"ci_lower\": 2.9130000000000003, \"ci_upper\": 4.221, \"p_value\": 0, \"model_name_custom\": \"GPT4o Mini\"}, {\"model_name\": \"gpt35\", \"coef\": 3.9, \"ci_lower\": 3.205, \"ci_upper\": 4.595, \"p_value\": 0, \"model_name_custom\": \"GPT3.5\"}, {\"model_name\": \"gemini_1.5_flash\", \"coef\": 2.5, \"ci_lower\": 1.82, \"ci_upper\": 3.18, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"model_name\": \"gemini_1.5_flash-8B\", \"coef\": 3.0667, \"ci_lower\": 2.517, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"model_name\": \"claude_3.5-sonnet\", \"coef\": 2.5, \"ci_lower\": 1.896, \"ci_upper\": 3.104, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"model_name\": \"claude_3.5-haiku\", \"coef\": 2.9667, \"ci_lower\": 2.317, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"model_name\": \"biomistral7B\", \"coef\": 1.6667, \"ci_lower\": 1.165, \"ci_upper\": 2.169, \"p_value\": 0, \"model_name_custom\": \"BioMistral 7B\"}, {\"model_name\": \"llama2_chat-13B\", \"coef\": 2.9333, \"ci_lower\": 2.351, \"ci_upper\": 3.515, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"model_name\": \"llama2_chat-70B\", \"coef\": 2.6414, \"ci_lower\": 2.17, \"ci_upper\": 3.112, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"model_name\": \"llama3_instruct-8B\", \"coef\": 2.2, \"ci_lower\": 1.716, \"ci_upper\": 2.684, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"model_name\": \"llama3_instruct-70B\", \"coef\": 4.4, \"ci_lower\": 3.473, \"ci_upper\": 5.327, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"model_name\": \"med42-8B\", \"coef\": 2.9667, \"ci_lower\": 2.396, \"ci_upper\": 3.5380000000000003, \"p_value\": 0, \"model_name_custom\": \"Med42 8B\"}, {\"model_name\": \"med42-70B\", \"coef\": 4.8333, \"ci_lower\": 4.021, \"ci_upper\": 5.646, \"p_value\": 0, \"model_name_custom\": \"Med42 70B\"}, {\"model_name\": \"olmo2_instruct-7B\", \"coef\": 3.2333, \"ci_lower\": 2.535, \"ci_upper\": 3.932, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"model_name\": \"olmo2_instruct-13B\", \"coef\": 6.0, \"ci_lower\": 5.118, \"ci_upper\": 6.882, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"model_name\": \"mistral_instruct7B\", \"coef\": 3.9, \"ci_lower\": 3.321, \"ci_upper\": 4.479, \"p_value\": 0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"model_name\": \"openbiollm-8B\", \"coef\": 2.8036000000000003, \"ci_lower\": 2.076, \"ci_upper\": 3.532, \"p_value\": 0, \"model_name_custom\": \"OpenBioLM 8B\"}, {\"model_name\": \"openbiollm-70B\", \"coef\": 4.4, \"ci_lower\": 3.748, \"ci_upper\": 5.052, \"p_value\": 0, \"model_name_custom\": \"OpenBioLM 70B\"}, {\"model_name\": \"alpacare-7B\", \"coef\": 6.0937, \"ci_lower\": 5.069, \"ci_upper\": 7.118, \"p_value\": 0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"model_name\": \"llama2_chat-7B\", \"coef\": 3.5, \"ci_lower\": 2.907, \"ci_upper\": 4.093, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"model_name\": \"biomedgpt7B\", \"coef\": 1.2824, \"ci_lower\": 0.908, \"ci_upper\": 1.6560000000000001, \"p_value\": 0, \"model_name_custom\": \"BioMedGPT 7B\"}], \"data-9086b5e891c6c4446ad27d61d4c923dc\": [{\"x\": 0.71}], \"data-52199a530ed2c15d41318ee1174bade9\": [{\"x\": 0.71, \"y\": \"GPT4o\"}], \"data-949e324d51a30a65027cdc3f88ce63f9\": [{\"x\": 1.2824, \"text\": \"Less susceptible to spin\"}, {\"x\": 6.0937, \"text\": \"More susceptible to spin\"}], \"data-83c6355aa736c88d3e2010b970158443\": [{\"x\": 0.2, \"text\": \"\\u2190\"}], \"data-d2787f2bd346c2865d5883806d3aca5e\": [{\"x\": 7.7, \"text\": \"\\u2192\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON data into a DataFrame\n",
    "regression_results_df = pd.read_json(\"./eval_outputs/simple_linear_regression_benefit_data.json\", orient=\"index\")\n",
    "\n",
    "# Ensure index is reset and available as a column\n",
    "regression_results_df.reset_index(inplace=True)\n",
    "regression_results_df = regression_results_df.rename(columns={'index': 'model_name'})\n",
    "\n",
    "regression_results_df[\"model_name_custom\"] = regression_results_df[\"model_name\"].map(custom_labels)\n",
    "\n",
    "# Create the Altair chart\n",
    "points = alt.Chart(regression_results_df).mark_point(\n",
    "    filled=True,\n",
    "    color='red',\n",
    "    size=50  # Increase point size\n",
    ").encode(\n",
    "    x=alt.X('coef:Q').title('Coefficient'),\n",
    "    y=alt.Y('model_name_custom:N').title('LLM Name').sort(\n",
    "        field='coef',  # Sort by coefficient values\n",
    "        order='descending'\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Add error bars\n",
    "error_bars = points.mark_rule(\n",
    "    strokeWidth=2  # Increase width of error bars\n",
    ").encode(\n",
    "    x='ci_lower:Q',\n",
    "    x2='ci_upper:Q',\n",
    "    size=alt.value(2)  # Set the width of error bars\n",
    ")\n",
    "\n",
    "# Add vertical line at x = 0.71\n",
    "vertical_line = alt.Chart(pd.DataFrame({'x': [0.71]})).mark_rule(\n",
    "    color='blue',\n",
    "    strokeDash=[4, 4],  # Make it dashed\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Add label for vertical line\n",
    "label = alt.Chart(pd.DataFrame({'x': [0.71], 'y': [regression_results_df['model_name_custom'].iloc[0]]})).mark_text(\n",
    "    text='Human Experts',\n",
    "    align='center',\n",
    "    dx=5,  # Adjust text position\n",
    "    dy=-10,\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y=alt.value(0),  # Adjust position if necessary\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Define custom x-axis labels\n",
    "custom_labels_df = pd.DataFrame({\n",
    "    'x': [regression_results_df['coef'].min(), regression_results_df['coef'].max()],\n",
    "    'text': ['Less susceptible to spin', 'More susceptible to spin']\n",
    "})\n",
    "\n",
    "# Define custom x-axis labels\n",
    "left_arrow_df = pd.DataFrame({\n",
    "    'x': [0.2],\n",
    "    'text': ['←']\n",
    "})\n",
    "\n",
    "# Define custom x-axis labels\n",
    "right_arrow_df = pd.DataFrame({\n",
    "    'x': [7.7],\n",
    "    'text': ['→']\n",
    "})\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_labels = alt.Chart(custom_labels_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=24, # adjust horizontal positioning\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_left_arrow = alt.Chart(left_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=10, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_right_arrow = alt.Chart(right_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=0, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Combine all layers, including the new x-axis labels\n",
    "chart = alt.layer(error_bars, points, vertical_line, label, custom_x_labels, custom_x_left_arrow, custom_x_right_arrow).configure_axis(\n",
    "    labelFontSize=16,\n",
    "    titleFontSize=18\n",
    ").configure_title(\n",
    "    fontSize=20\n",
    ")\n",
    "\n",
    "# # Save to HTML\n",
    "chart.save(\"./plots/simple_regression_benefit_data.html\")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-edc3bd13464240679654dc1a1052274b.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-edc3bd13464240679654dc1a1052274b.vega-embed details,\n",
       "  #altair-viz-edc3bd13464240679654dc1a1052274b.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-edc3bd13464240679654dc1a1052274b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-edc3bd13464240679654dc1a1052274b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-edc3bd13464240679654dc1a1052274b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 18}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"data\": {\"name\": \"data-6abbd05e590eb886ab3b944a16091a2a\"}, \"mark\": {\"type\": \"rule\", \"strokeWidth\": 2}, \"encoding\": {\"size\": {\"value\": 2}, \"x\": {\"field\": \"ci_lower\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"ci_upper\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-6abbd05e590eb886ab3b944a16091a2a\"}, \"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"field\": \"coef\", \"title\": \"Coefficient\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"data\": {\"name\": \"data-9086b5e891c6c4446ad27d61d4c923dc\"}, \"mark\": {\"type\": \"rule\", \"color\": \"blue\", \"strokeDash\": [4, 4], \"strokeWidth\": 2}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-52199a530ed2c15d41318ee1174bade9\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"dx\": 5, \"dy\": -10, \"fontSize\": 14, \"fontWeight\": \"bold\", \"text\": \"Human Experts\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"value\": 0}}}, {\"data\": {\"name\": \"data-949e324d51a30a65027cdc3f88ce63f9\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 24, \"dy\": 195, \"fontSize\": 14, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-83c6355aa736c88d3e2010b970158443\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 10, \"dy\": 195, \"fontSize\": 30, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-d2787f2bd346c2865d5883806d3aca5e\"}, \"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dx\": 0, \"dy\": 195, \"fontSize\": 30, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"#0868ac\"}, \"text\": {\"field\": \"text\", \"type\": \"nominal\"}, \"x\": {\"field\": \"x\", \"type\": \"quantitative\"}}}], \"height\": 300, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-6abbd05e590eb886ab3b944a16091a2a\": [{\"model_name\": \"gpt4o\", \"coef\": 3.1333, \"ci_lower\": 2.442, \"ci_upper\": 3.824, \"p_value\": 0, \"model_name_custom\": \"GPT4o\"}, {\"model_name\": \"gpt4o-mini\", \"coef\": 3.5667, \"ci_lower\": 2.9130000000000003, \"ci_upper\": 4.221, \"p_value\": 0, \"model_name_custom\": \"GPT4o Mini\"}, {\"model_name\": \"gpt35\", \"coef\": 1.4333, \"ci_lower\": 0.982, \"ci_upper\": 1.884, \"p_value\": 0, \"model_name_custom\": \"GPT3.5\"}, {\"model_name\": \"gemini_1.5_flash\", \"coef\": 2.5, \"ci_lower\": 1.82, \"ci_upper\": 3.18, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"model_name\": \"gemini_1.5_flash-8B\", \"coef\": 3.0667, \"ci_lower\": 2.517, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"model_name\": \"claude_3.5-sonnet\", \"coef\": 2.5, \"ci_lower\": 1.896, \"ci_upper\": 3.104, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"model_name\": \"claude_3.5-haiku\", \"coef\": 2.9667, \"ci_lower\": 2.317, \"ci_upper\": 3.616, \"p_value\": 0, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"model_name\": \"biomistral7B\", \"coef\": 1.6667, \"ci_lower\": 1.165, \"ci_upper\": 2.169, \"p_value\": 0, \"model_name_custom\": \"BioMistral 7B\"}, {\"model_name\": \"llama2_chat-13B\", \"coef\": 2.9333, \"ci_lower\": 2.351, \"ci_upper\": 3.515, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"model_name\": \"llama2_chat-70B\", \"coef\": 2.6414, \"ci_lower\": 2.17, \"ci_upper\": 3.112, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"model_name\": \"llama3_instruct-8B\", \"coef\": 2.2, \"ci_lower\": 1.716, \"ci_upper\": 2.684, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"model_name\": \"llama3_instruct-70B\", \"coef\": 4.4, \"ci_lower\": 3.473, \"ci_upper\": 5.327, \"p_value\": 0, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"model_name\": \"med42-8B\", \"coef\": 2.9667, \"ci_lower\": 2.396, \"ci_upper\": 3.5380000000000003, \"p_value\": 0, \"model_name_custom\": \"Med42 8B\"}, {\"model_name\": \"med42-70B\", \"coef\": 4.8333, \"ci_lower\": 4.021, \"ci_upper\": 5.646, \"p_value\": 0, \"model_name_custom\": \"Med42 70B\"}, {\"model_name\": \"olmo2_instruct-7B\", \"coef\": 3.2333, \"ci_lower\": 2.535, \"ci_upper\": 3.932, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"model_name\": \"olmo2_instruct-13B\", \"coef\": 6.0, \"ci_lower\": 5.118, \"ci_upper\": 6.882, \"p_value\": 0, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"model_name\": \"mistral_instruct7B\", \"coef\": 3.9, \"ci_lower\": 3.321, \"ci_upper\": 4.479, \"p_value\": 0, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"model_name\": \"openbiollm-8B\", \"coef\": 2.8036000000000003, \"ci_lower\": 2.076, \"ci_upper\": 3.532, \"p_value\": 0, \"model_name_custom\": \"OpenBioLM 8B\"}, {\"model_name\": \"openbiollm-70B\", \"coef\": 4.4, \"ci_lower\": 3.748, \"ci_upper\": 5.052, \"p_value\": 0, \"model_name_custom\": \"OpenBioLM 70B\"}, {\"model_name\": \"alpacare-7B\", \"coef\": 6.0937, \"ci_lower\": 5.069, \"ci_upper\": 7.118, \"p_value\": 0, \"model_name_custom\": \"AlpaCare 7B\"}, {\"model_name\": \"llama2_chat-7B\", \"coef\": 3.5, \"ci_lower\": 2.907, \"ci_upper\": 4.093, \"p_value\": 0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"model_name\": \"biomedgpt7B\", \"coef\": 1.2824, \"ci_lower\": 0.908, \"ci_upper\": 1.6560000000000001, \"p_value\": 0, \"model_name_custom\": \"BioMedGPT 7B\"}], \"data-9086b5e891c6c4446ad27d61d4c923dc\": [{\"x\": 0.71}], \"data-52199a530ed2c15d41318ee1174bade9\": [{\"x\": 0.71, \"y\": \"GPT4o\"}], \"data-949e324d51a30a65027cdc3f88ce63f9\": [{\"x\": 1.2824, \"text\": \"Less susceptible to spin\"}, {\"x\": 6.0937, \"text\": \"More susceptible to spin\"}], \"data-83c6355aa736c88d3e2010b970158443\": [{\"x\": 0.2, \"text\": \"\\u2190\"}], \"data-d2787f2bd346c2865d5883806d3aca5e\": [{\"x\": 7.7, \"text\": \"\\u2192\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# FOR KAREN\n",
    "\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: CHANGE FILE NAME HERE\n",
    "# Load the JSON data into a DataFrame\n",
    "regression_results_df = pd.read_json(\"./eval_outputs/simple_linear_regression_benefit_data.json\", orient=\"index\")\n",
    "\n",
    "# Ensure index is reset and available as a column\n",
    "regression_results_df.reset_index(inplace=True)\n",
    "regression_results_df = regression_results_df.rename(columns={'index': 'model_name'})\n",
    "\n",
    "regression_results_df[\"model_name_custom\"] = regression_results_df[\"model_name\"].map(custom_labels)\n",
    "\n",
    "# Create the Altair chart\n",
    "points = alt.Chart(regression_results_df).mark_point(\n",
    "    filled=True,\n",
    "    color='red',\n",
    "    size=50  # Increase point size\n",
    ").encode(\n",
    "    x=alt.X('coef:Q').title('Coefficient'),\n",
    "    y=alt.Y('model_name_custom:N').title('LLM Name').sort(\n",
    "        field='coef',  # Sort by coefficient values\n",
    "        order='descending'\n",
    "    )\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=300\n",
    ")\n",
    "\n",
    "# Add error bars\n",
    "error_bars = points.mark_rule(\n",
    "    strokeWidth=2  # Increase width of error bars\n",
    ").encode(\n",
    "    x='ci_lower:Q',\n",
    "    x2='ci_upper:Q',\n",
    "    size=alt.value(2)  # Set the width of error bars\n",
    ")\n",
    "\n",
    "# Add vertical line at x = 0.71\n",
    "# TODO: change the x value to what the human expert values are\n",
    "# 1\t-0.590000\trigor_answer\thuman experts\n",
    "# 2\t-0.380000\timportance_answer\thuman experts\n",
    "# 3\t0.770000\tfull_text_answer\thuman experts\n",
    "# 4\t0.640000\tanother_trial_answer\thuman experts\n",
    "vertical_line = alt.Chart(pd.DataFrame({'x': [0.71]})).mark_rule(\n",
    "    color='blue',\n",
    "    strokeDash=[4, 4],  # Make it dashed\n",
    "    strokeWidth=2\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Add label for vertical line\n",
    "label = alt.Chart(pd.DataFrame({'x': [0.71], 'y': [regression_results_df['model_name_custom'].iloc[0]]})).mark_text(\n",
    "    text='Human Experts',\n",
    "    align='center',\n",
    "    dx=5,  # Adjust text position\n",
    "    dy=-10,\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    y=alt.value(0),  # Adjust position if necessary\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Define custom x-axis labels\n",
    "custom_labels_df = pd.DataFrame({\n",
    "    'x': [regression_results_df['coef'].min(), regression_results_df['coef'].max()],\n",
    "    'text': ['Less susceptible to spin', 'More susceptible to spin']\n",
    "})\n",
    "\n",
    "# TODO: hard coded x-axis for the arrows\n",
    "# MIGHT NEED TO ADJUST AS NEEDED\n",
    "# Define custom x-axis labels\n",
    "left_arrow_df = pd.DataFrame({\n",
    "    'x': [0.2],\n",
    "    'text': ['←']\n",
    "})\n",
    "\n",
    "# TODO: hard coded x-axis for the arrows\n",
    "# MIGHT NEED TO ADJUST AS NEEDED\n",
    "# Define custom x-axis labels\n",
    "right_arrow_df = pd.DataFrame({\n",
    "    'x': [7.7],\n",
    "    'text': ['→']\n",
    "})\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_labels = alt.Chart(custom_labels_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=24, # adjust horizontal positioning\n",
    "    fontSize=14,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_left_arrow = alt.Chart(left_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=10, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Create a text layer for custom x-axis labels\n",
    "custom_x_right_arrow = alt.Chart(right_arrow_df).mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    dy=195,  # Adjust vertical positioning\n",
    "    dx=0, # adjust horizontal positioning\n",
    "    fontSize=24,\n",
    "    fontWeight='bold',\n",
    ").encode(\n",
    "    x='x:Q',\n",
    "    text='text:N',\n",
    "    color=alt.value('#0868ac')  # Specify the color directly\n",
    ")\n",
    "\n",
    "# Combine all layers, including the new x-axis labels\n",
    "chart = alt.layer(error_bars, points, vertical_line, label, custom_x_labels, custom_x_left_arrow, custom_x_right_arrow).configure_axis(\n",
    "    labelFontSize=16,\n",
    "    titleFontSize=18\n",
    ").configure_title(\n",
    "    fontSize=20\n",
    ")\n",
    "\n",
    "# Save to HTML\n",
    "# TODO: \n",
    "# CHANGE FILE NAME HERE\n",
    "chart.save(\"./plots/simple_regression_benefit_data.html\")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary Spin Detection Results Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer'])\n",
    "\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "        \n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * is_detection_correct\", \n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_binary_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what the model predicts rather than whether it was correct or not\n",
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer'])\n",
    "\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "        \n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * detection_model_prediction\", \n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_binary_direct_model_prediction_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forest Plot for \"Benefit\" Linear Regression Results (Binary Model Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-0a178c5870c645bd85a3f13a8ceb8064.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-0a178c5870c645bd85a3f13a8ceb8064.vega-embed details,\n",
       "  #altair-viz-0a178c5870c645bd85a3f13a8ceb8064.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-0a178c5870c645bd85a3f13a8ceb8064\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0a178c5870c645bd85a3f13a8ceb8064\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0a178c5870c645bd85a3f13a8ceb8064\");\n",
       "    }\n",
       "\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      let deps = [\"vega-embed\"];\n",
       "      require(deps, displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 16, \"titleFontSize\": 18}, \"title\": {\"fontSize\": 20}}, \"layer\": [{\"mark\": {\"type\": \"rule\", \"strokeWidth\": 2}, \"encoding\": {\"size\": {\"value\": 2}, \"x\": {\"field\": \"ci_lower\", \"type\": \"quantitative\"}, \"x2\": {\"field\": \"ci_upper\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}, {\"mark\": {\"type\": \"point\", \"color\": \"red\", \"filled\": true, \"size\": 50}, \"encoding\": {\"x\": {\"field\": \"coef\", \"title\": \"Coefficient\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"model_name_custom\", \"sort\": {\"field\": \"coef\", \"order\": \"descending\"}, \"title\": \"LLM Name\", \"type\": \"nominal\"}}}], \"data\": {\"name\": \"data-870de94bbb29e50e3694c296e291a63e\"}, \"height\": 300, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-870de94bbb29e50e3694c296e291a63e\": [{\"model_name\": \"gpt4o\", \"coef\": 0.8889, \"ci_lower\": -0.094, \"ci_upper\": 1.8719999999999999, \"p_value\": 0.076, \"model_name_custom\": \"GPT4o\"}, {\"model_name\": \"gpt4o-mini\", \"coef\": 0.7614000000000001, \"ci_lower\": -0.268, \"ci_upper\": 1.79, \"p_value\": 0.14400000000000002, \"model_name_custom\": \"GPT4o Mini\"}, {\"model_name\": \"gpt35\", \"coef\": 1.3276, \"ci_lower\": -0.008, \"ci_upper\": 2.6630000000000003, \"p_value\": 0.051000000000000004, \"model_name_custom\": \"GPT3.5\"}, {\"model_name\": \"gemini_1.5_flash\", \"coef\": 0.7411, \"ci_lower\": -0.212, \"ci_upper\": 1.694, \"p_value\": 0.125, \"model_name_custom\": \"Gemini1.5 Flash\"}, {\"model_name\": \"gemini_1.5_flash-8B\", \"coef\": 0.11800000000000001, \"ci_lower\": -0.8160000000000001, \"ci_upper\": 1.052, \"p_value\": 0.801, \"model_name_custom\": \"Gemini1.5 Flash 8B\"}, {\"model_name\": \"claude_3.5-sonnet\", \"coef\": -0.2321, \"ci_lower\": -1.094, \"ci_upper\": 0.63, \"p_value\": 0.592, \"model_name_custom\": \"Claude3.5 Sonnet\"}, {\"model_name\": \"claude_3.5-haiku\", \"coef\": 0.7115, \"ci_lower\": -0.639, \"ci_upper\": 2.062, \"p_value\": 0.296, \"model_name_custom\": \"Claude3.5 Haiku\"}, {\"model_name\": \"biomistral7B\", \"coef\": 1.0948, \"ci_lower\": 0.14100000000000001, \"ci_upper\": 2.049, \"p_value\": 0.025, \"model_name_custom\": \"BioMistral 7B\"}, {\"model_name\": \"llama2_chat-13B\", \"coef\": 0.28, \"ci_lower\": -0.804, \"ci_upper\": 1.3639999999999999, \"p_value\": 0.607, \"model_name_custom\": \"Llama2 Chat 13B\"}, {\"model_name\": \"llama2_chat-70B\", \"coef\": 0.875, \"ci_lower\": 0.165, \"ci_upper\": 1.585, \"p_value\": 0.017, \"model_name_custom\": \"Llama2 Chat 70B\"}, {\"model_name\": \"llama3_instruct-8B\", \"coef\": 0.3, \"ci_lower\": -0.057, \"ci_upper\": 0.657, \"p_value\": 0.098, \"model_name_custom\": \"Llama3 Instruct 8B\"}, {\"model_name\": \"llama3_instruct-70B\", \"coef\": 0.17500000000000002, \"ci_lower\": -0.525, \"ci_upper\": 0.875, \"p_value\": 0.619, \"model_name_custom\": \"Llama3 Instruct 70B\"}, {\"model_name\": \"med42-8B\", \"coef\": 0.34, \"ci_lower\": -0.199, \"ci_upper\": 0.879, \"p_value\": 0.212, \"model_name_custom\": \"Med42 8B\"}, {\"model_name\": \"med42-70B\", \"coef\": 0.2857, \"ci_lower\": -2.044, \"ci_upper\": 2.616, \"p_value\": 0.807, \"model_name_custom\": \"Med42 70B\"}, {\"model_name\": \"olmo2_instruct-7B\", \"coef\": 0.2222, \"ci_lower\": -0.28300000000000003, \"ci_upper\": 0.728, \"p_value\": 0.382, \"model_name_custom\": \"Olmo2 Instruct 7B\"}, {\"model_name\": \"olmo2_instruct-13B\", \"coef\": 1.7931, \"ci_lower\": 0.106, \"ci_upper\": 3.481, \"p_value\": 0.038, \"model_name_custom\": \"Olmo2 Instruct 13B\"}, {\"model_name\": \"mistral_instruct7B\", \"coef\": 0.0, \"ci_lower\": 0.0, \"ci_upper\": 0.0, \"p_value\": null, \"model_name_custom\": \"Mistral Instruct 7B\"}, {\"model_name\": \"openbiollm-8B\", \"coef\": 2.1458, \"ci_lower\": 1.897, \"ci_upper\": 2.395, \"p_value\": 0.0, \"model_name_custom\": \"OpenBioLM 8B\"}, {\"model_name\": \"openbiollm-70B\", \"coef\": 1.5962, \"ci_lower\": 0.304, \"ci_upper\": 2.8890000000000002, \"p_value\": 0.016, \"model_name_custom\": \"OpenBioLM 70B\"}, {\"model_name\": \"alpacare-7B\", \"coef\": -0.19640000000000002, \"ci_lower\": -4.263, \"ci_upper\": 3.87, \"p_value\": 0.923, \"model_name_custom\": \"AlpaCare 7B\"}, {\"model_name\": \"llama2_chat-7B\", \"coef\": 1.5167000000000002, \"ci_lower\": 1.307, \"ci_upper\": 1.726, \"p_value\": 0.0, \"model_name_custom\": \"Llama2 Chat 7B\"}, {\"model_name\": \"biomedgpt7B\", \"coef\": 2.6923, \"ci_lower\": 1.492, \"ci_upper\": 3.893, \"p_value\": 0.0, \"model_name_custom\": \"BioMedGPT 7B\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load the JSON data into a DataFrame\n",
    "# regression_results_df = pd.read_json(\"./eval_outputs/model_detection_prediction_linear_regression_benefit_data.json\", orient=\"index\")\n",
    "\n",
    "# # Ensure index is reset and available as a column\n",
    "# regression_results_df.reset_index(inplace=True)\n",
    "# regression_results_df = regression_results_df.rename(columns={'index': 'model_name'})\n",
    "\n",
    "# regression_results_df[\"model_name_custom\"] = regression_results_df[\"model_name\"].map(custom_labels)\n",
    "\n",
    "# # Create the Altair chart\n",
    "# points = alt.Chart(regression_results_df).mark_point(\n",
    "#     filled=True,\n",
    "#     color='red',\n",
    "#     size=50  # Increase point size\n",
    "# ).encode(\n",
    "#     x=alt.X('coef:Q').title('Coefficient'),\n",
    "#     y=alt.Y('model_name_custom:N', title='LLM Name').sort(\n",
    "#         field='coef',  # Sort by coefficient values\n",
    "#         order='descending'\n",
    "#     )\n",
    "# ).properties(\n",
    "#     width=600,\n",
    "#     height=300  # Increase height for more space between error bars\n",
    "# )\n",
    "\n",
    "# # Add error bars\n",
    "# error_bars = points.mark_rule(\n",
    "#     strokeWidth=2  # Increase width of error bars\n",
    "# ).encode(\n",
    "#     x='ci_lower:Q',\n",
    "#     x2='ci_upper:Q',\n",
    "#     # y='model_name:N',  # Align the error bars with the points\n",
    "#     size=alt.value(2)  # Set the width of error bars\n",
    "# )\n",
    "\n",
    "# # Combine the points and error bars\n",
    "# chart = error_bars + points\n",
    "\n",
    "# # Apply the configuration directly to the chart\n",
    "# chart = chart.configure_axis(\n",
    "#     labelFontSize=16,  # Increase font size for axis labels\n",
    "#     titleFontSize=18   # Increase font size for axis title\n",
    "# ).configure_title(\n",
    "#     fontSize=20  # Increase font size for chart title (if any)\n",
    "# )\n",
    "\n",
    "# # Save to HTML\n",
    "# chart.save(\"./plots/model_detection_prediction_regression_benefit_data.html\")\n",
    "\n",
    "# # Display the chart\n",
    "# chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability Spin Detection Results Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = gpt_models + huggingface_models # remove no token probability models\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer', 'detection_probability'])\n",
    "        \n",
    "#         # if is_detection_no_spin_correct == 1, then detection_probability. Otherwise, 1 - detection_probability\n",
    "#         measure_data['regression_detection_variable'] = measure_data.apply(lambda x: x['detection_probability'] if x['is_detection_correct'] == 1 else 1 - x['detection_probability'], axis=1)\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "\n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * regression_detection_variable\",\n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_probability_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what the model predicts rather than whether it was correct or not\n",
    "\n",
    "# model_names = gpt_models + huggingface_models # remove no token probability models\n",
    "\n",
    "# for model_name in model_names:\n",
    "#     output_string = \"\"\n",
    "#     csv_file_path = f\"./eval_outputs/{model_name}/{model_name}_combined_data.csv\"\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "\n",
    "#     measures = [\"benefit_answer\", \"rigor_answer\", \"importance_answer\", \"full_text_answer\", \"another_trial_answer\", \"overall\"]\n",
    "#     for measure in measures:\n",
    "#         # get the data for the current measure\n",
    "#         measure_data = data[data['measure'] == measure]\n",
    "#         nan_rows_number = measure_data['interpretation_answer'].isnull().sum()\n",
    "#         # remove rows with NaN values in interpretation_answer\n",
    "#         measure_data = measure_data.dropna(subset=['interpretation_answer', 'detection_probability'])\n",
    "        \n",
    "#         # if is_detection_no_spin_correct == 1, then detection_probability. Otherwise, 1 - detection_probability\n",
    "#         measure_data['regression_detection_variable'] = measure_data.apply(lambda x: x['detection_probability'] if x['detection_model_prediction'] == 1 else 1 - x['detection_probability'], axis=1)\n",
    "#         # check if there are less than 2 rows\n",
    "#         if len(measure_data) < 2:\n",
    "#             continue\n",
    "\n",
    "#         # fit the model\n",
    "#         model = smf.ols(formula=\"interpretation_answer ~ is_spin_in_abstract * regression_detection_variable\",\n",
    "#                                     data=measure_data)\n",
    "#         results = model.fit()\n",
    "\n",
    "#         output_string += f\"Model: {model_name} - {measure}\\n\"\n",
    "#         # print number of rows with NaN value(s)\n",
    "#         output_string += f\"Number of rows with NaN value(s) in {model_name}: {nan_rows_number}\\n\"\n",
    "#         output_string += results.summary().as_text()\n",
    "#         output_string += \"\\n\"\n",
    "\n",
    "#     # save the model summary\n",
    "#     with open(f\"./eval_outputs/{model_name}/{model_name}_regression_probability_direct_model_prediction_summary.txt\", \"w\") as f:\n",
    "#         f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS LLM Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_number_of_tokens</th>\n",
       "      <th>sd_number_of_tokens</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpacare-7B</th>\n",
       "      <td>120.416667</td>\n",
       "      <td>56.264936</td>\n",
       "      <td>alpacare-7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomedgpt7B</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>59.498459</td>\n",
       "      <td>biomedgpt7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biomistral7B</th>\n",
       "      <td>140.766667</td>\n",
       "      <td>73.807941</td>\n",
       "      <td>biomistral7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_3.5-haiku</th>\n",
       "      <td>225.033333</td>\n",
       "      <td>15.084171</td>\n",
       "      <td>claude_3.5-haiku</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>claude_3.5-sonnet</th>\n",
       "      <td>230.516667</td>\n",
       "      <td>19.185491</td>\n",
       "      <td>claude_3.5-sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_1.5_flash</th>\n",
       "      <td>214.216667</td>\n",
       "      <td>30.953778</td>\n",
       "      <td>gemini_1.5_flash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gemini_1.5_flash-8B</th>\n",
       "      <td>207.700000</td>\n",
       "      <td>37.768285</td>\n",
       "      <td>gemini_1.5_flash-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o</th>\n",
       "      <td>207.850000</td>\n",
       "      <td>44.255254</td>\n",
       "      <td>gpt4o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4o-mini</th>\n",
       "      <td>253.783333</td>\n",
       "      <td>38.084595</td>\n",
       "      <td>gpt4o-mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt35</th>\n",
       "      <td>94.483333</td>\n",
       "      <td>18.754992</td>\n",
       "      <td>gpt35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2_chat-7B</th>\n",
       "      <td>230.450000</td>\n",
       "      <td>32.119270</td>\n",
       "      <td>llama2_chat-7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2_chat-13B</th>\n",
       "      <td>225.733333</td>\n",
       "      <td>31.079397</td>\n",
       "      <td>llama2_chat-13B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama2_chat-70B</th>\n",
       "      <td>227.900000</td>\n",
       "      <td>35.466745</td>\n",
       "      <td>llama2_chat-70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3_instruct-8B</th>\n",
       "      <td>266.533333</td>\n",
       "      <td>27.110556</td>\n",
       "      <td>llama3_instruct-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3_instruct-70B</th>\n",
       "      <td>248.816667</td>\n",
       "      <td>40.183534</td>\n",
       "      <td>llama3_instruct-70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med42-8B</th>\n",
       "      <td>172.616667</td>\n",
       "      <td>50.387860</td>\n",
       "      <td>med42-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med42-70B</th>\n",
       "      <td>290.533333</td>\n",
       "      <td>12.620706</td>\n",
       "      <td>med42-70B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mistral_instruct7B</th>\n",
       "      <td>150.833333</td>\n",
       "      <td>55.947942</td>\n",
       "      <td>mistral_instruct7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olmo2_instruct-7B</th>\n",
       "      <td>282.100000</td>\n",
       "      <td>3.176476</td>\n",
       "      <td>olmo2_instruct-7B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>olmo2_instruct-13B</th>\n",
       "      <td>272.033333</td>\n",
       "      <td>20.209706</td>\n",
       "      <td>olmo2_instruct-13B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openbiollm-8B</th>\n",
       "      <td>165.566667</td>\n",
       "      <td>71.853408</td>\n",
       "      <td>openbiollm-8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openbiollm-70B</th>\n",
       "      <td>155.400000</td>\n",
       "      <td>54.012097</td>\n",
       "      <td>openbiollm-70B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     average_number_of_tokens  sd_number_of_tokens  \\\n",
       "alpacare-7B                        120.416667            56.264936   \n",
       "biomedgpt7B                        195.000000            59.498459   \n",
       "biomistral7B                       140.766667            73.807941   \n",
       "claude_3.5-haiku                   225.033333            15.084171   \n",
       "claude_3.5-sonnet                  230.516667            19.185491   \n",
       "gemini_1.5_flash                   214.216667            30.953778   \n",
       "gemini_1.5_flash-8B                207.700000            37.768285   \n",
       "gpt4o                              207.850000            44.255254   \n",
       "gpt4o-mini                         253.783333            38.084595   \n",
       "gpt35                               94.483333            18.754992   \n",
       "llama2_chat-7B                     230.450000            32.119270   \n",
       "llama2_chat-13B                    225.733333            31.079397   \n",
       "llama2_chat-70B                    227.900000            35.466745   \n",
       "llama3_instruct-8B                 266.533333            27.110556   \n",
       "llama3_instruct-70B                248.816667            40.183534   \n",
       "med42-8B                           172.616667            50.387860   \n",
       "med42-70B                          290.533333            12.620706   \n",
       "mistral_instruct7B                 150.833333            55.947942   \n",
       "olmo2_instruct-7B                  282.100000             3.176476   \n",
       "olmo2_instruct-13B                 272.033333            20.209706   \n",
       "openbiollm-8B                      165.566667            71.853408   \n",
       "openbiollm-70B                     155.400000            54.012097   \n",
       "\n",
       "                              model_name  \n",
       "alpacare-7B                  alpacare-7B  \n",
       "biomedgpt7B                  biomedgpt7B  \n",
       "biomistral7B                biomistral7B  \n",
       "claude_3.5-haiku        claude_3.5-haiku  \n",
       "claude_3.5-sonnet      claude_3.5-sonnet  \n",
       "gemini_1.5_flash        gemini_1.5_flash  \n",
       "gemini_1.5_flash-8B  gemini_1.5_flash-8B  \n",
       "gpt4o                              gpt4o  \n",
       "gpt4o-mini                    gpt4o-mini  \n",
       "gpt35                              gpt35  \n",
       "llama2_chat-7B            llama2_chat-7B  \n",
       "llama2_chat-13B          llama2_chat-13B  \n",
       "llama2_chat-70B          llama2_chat-70B  \n",
       "llama3_instruct-8B    llama3_instruct-8B  \n",
       "llama3_instruct-70B  llama3_instruct-70B  \n",
       "med42-8B                        med42-8B  \n",
       "med42-70B                      med42-70B  \n",
       "mistral_instruct7B    mistral_instruct7B  \n",
       "olmo2_instruct-7B      olmo2_instruct-7B  \n",
       "olmo2_instruct-13B    olmo2_instruct-13B  \n",
       "openbiollm-8B              openbiollm-8B  \n",
       "openbiollm-70B            openbiollm-70B  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all PLS outputs from all LLMs\n",
    "enc = tiktoken.get_encoding(\"o200k_base\") # for gpt-4o and gpt-4o mini\n",
    "\n",
    "model_token_stats = {}\n",
    "number_of_tokens_total = [] # for all models\n",
    "for model_name in model_names:\n",
    "    csv_file_path = f\"./pls_outputs/{model_name}/{model_name}_outputs.csv\"\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    # calculate the number of tokens for each row in plain_language_summary\n",
    "    plain_language_summaries = data['plain_language_summary'].tolist()\n",
    "\n",
    "    number_of_tokens = []\n",
    "    for summary in plain_language_summaries:\n",
    "        token_integers = enc.encode(summary)\n",
    "        number_of_tokens.append(len(token_integers))\n",
    "        number_of_tokens_total.append(len(token_integers))\n",
    "\n",
    "    # average number of tokens\n",
    "    average_number_of_tokens = np.mean(number_of_tokens)\n",
    "    # SD of tokens\n",
    "    sd_number_of_tokens = np.std(number_of_tokens)\n",
    "    model_token_stats[model_name] = {\"average_number_of_tokens\": average_number_of_tokens, \"sd_number_of_tokens\": sd_number_of_tokens}\n",
    "\n",
    "model_token_stats_df = pd.DataFrame(model_token_stats).T\n",
    "model_token_stats_df[\"model_name\"] = model_token_stats_df.index\n",
    "\n",
    "model_token_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208.10378787878787, 67.01472464306116)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the average across all\n",
    "average_number_of_tokens = np.mean(number_of_tokens_total)\n",
    "sd_number_of_tokens = np.std(number_of_tokens_total)\n",
    "\n",
    "average_number_of_tokens, sd_number_of_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208.10378787878787, 37.62843632260712)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average across all models\n",
    "average_number_of_tokens = model_token_stats_df[\"average_number_of_tokens\"].mean()\n",
    "sd_number_of_tokens = model_token_stats_df[\"sd_number_of_tokens\"].mean()\n",
    "\n",
    "average_number_of_tokens, sd_number_of_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_evaluator_results = pd.read_json(\"./pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-sonnet_interpretation_overall_metrics.json\", orient=\"index\")\n",
    "gpt4o_mini_evaluator_results = pd.read_json(\"./pls_outputs/_interpretation_eval_results/gpt4o-mini/gpt4o-mini_interpretation_overall_metrics.json\", orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confidence_interval(df, df_column_name):\n",
    "    mean_diff = df[df_column_name].mean()  # Calculate the mean\n",
    "    std_dev = df[df_column_name].std()  # Calculate the standard deviation\n",
    "    n = len(df[df_column_name])  # Sample size\n",
    "\n",
    "    # Calculate the margin of error for 95% CI (z = 1.96)\n",
    "    z = 1.96\n",
    "    margin_of_error = z * (std_dev / sqrt(n))\n",
    "\n",
    "    # Calculate the 95% Confidence Interval\n",
    "    ci_lower = mean_diff - margin_of_error\n",
    "    ci_upper = mean_diff + margin_of_error\n",
    "\n",
    "    return ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.592424</td>\n",
       "      <td>3.573721</td>\n",
       "      <td>3.611128</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.353030</td>\n",
       "      <td>1.332122</td>\n",
       "      <td>1.373939</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.730303</td>\n",
       "      <td>2.707594</td>\n",
       "      <td>2.753012</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.686364</td>\n",
       "      <td>3.655170</td>\n",
       "      <td>3.717557</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.868182</td>\n",
       "      <td>3.840497</td>\n",
       "      <td>3.895866</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric   evaluator\n",
       "0   3.592424  3.573721  3.611128        benefit_answer  GPT4o Mini\n",
       "1   1.353030  1.332122  1.373939          rigor_answer  GPT4o Mini\n",
       "2   2.730303  2.707594  2.753012     importance_answer  GPT4o Mini\n",
       "3   3.686364  3.655170  3.717557      full_text_answer  GPT4o Mini\n",
       "4   3.868182  3.840497  3.895866  another_trial_answer  GPT4o Mini"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "average_model_pls_benefit = gpt4o_mini_evaluator_results[\"benefit_answer_mean_diff\"].mean()\n",
    "ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"benefit_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_rigor = gpt4o_mini_evaluator_results[\"rigor_answer_mean_diff\"].mean()\n",
    "ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"rigor_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_importance = gpt4o_mini_evaluator_results[\"importance_answer_mean_diff\"].mean()\n",
    "ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"importance_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_full_text = gpt4o_mini_evaluator_results[\"full_text_answer_mean_diff\"].mean()\n",
    "ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"full_text_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_another_trial = gpt4o_mini_evaluator_results[\"another_trial_answer_mean_diff\"].mean()\n",
    "ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(gpt4o_mini_evaluator_results, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "gpt4o_mini_pls_model_stats = {\n",
    "    \"benefit_answer\": {\"mean_diff\": average_model_pls_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "    \"rigor_answer\": {\"mean_diff\": average_pls_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "    \"importance_answer\": {\"mean_diff\": average_pls_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "    \"full_text_answer\": {\"mean_diff\": average_pls_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "    \"another_trial_answer\": {\"mean_diff\": average_pls_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "}\n",
    "\n",
    "pls_gpt4o_mini_model_stats_df = pd.DataFrame(gpt4o_mini_pls_model_stats).T\n",
    "pls_gpt4o_mini_model_stats_df[\"metric\"] = pls_gpt4o_mini_model_stats_df.index\n",
    "# remove index\n",
    "pls_gpt4o_mini_model_stats_df.reset_index(drop=True, inplace=True)\n",
    "pls_gpt4o_mini_model_stats_df[\"evaluator\"] = \"GPT4o Mini\"\n",
    "\n",
    "pls_gpt4o_mini_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.471212</td>\n",
       "      <td>2.466320</td>\n",
       "      <td>2.476105</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.175758</td>\n",
       "      <td>-0.182107</td>\n",
       "      <td>-0.169408</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.337879</td>\n",
       "      <td>-0.345682</td>\n",
       "      <td>-0.330075</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.818182</td>\n",
       "      <td>2.804775</td>\n",
       "      <td>2.831589</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.706061</td>\n",
       "      <td>2.687012</td>\n",
       "      <td>2.725109</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric          evaluator\n",
       "0   2.471212  2.466320  2.476105        benefit_answer  Claude 3.5 Sonnet\n",
       "1  -0.175758 -0.182107 -0.169408          rigor_answer  Claude 3.5 Sonnet\n",
       "2  -0.337879 -0.345682 -0.330075     importance_answer  Claude 3.5 Sonnet\n",
       "3   2.818182  2.804775  2.831589      full_text_answer  Claude 3.5 Sonnet\n",
       "4   2.706061  2.687012  2.725109  another_trial_answer  Claude 3.5 Sonnet"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average of all model metrics and calculate 95% CI\n",
    "average_model_pls_benefit = claude_evaluator_results[\"benefit_answer_mean_diff\"].mean()\n",
    "ci_lower_model_benefit, ci_upper_model_benefit = calculate_confidence_interval(claude_evaluator_results, \"benefit_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_rigor = claude_evaluator_results[\"rigor_answer_mean_diff\"].mean()\n",
    "ci_lower_model_rigor, ci_upper_model_rigor = calculate_confidence_interval(claude_evaluator_results, \"rigor_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_importance = claude_evaluator_results[\"importance_answer_mean_diff\"].mean()\n",
    "ci_lower_model_importance, ci_upper_model_importance = calculate_confidence_interval(claude_evaluator_results, \"importance_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_full_text = claude_evaluator_results[\"full_text_answer_mean_diff\"].mean()\n",
    "ci_lower_model_full_text, ci_upper_model_full_text = calculate_confidence_interval(claude_evaluator_results, \"full_text_answer_mean_diff\")\n",
    "\n",
    "average_pls_model_another_trial = claude_evaluator_results[\"another_trial_answer_mean_diff\"].mean()\n",
    "ci_lower_model_another_trial, ci_upper_model_another_trial = calculate_confidence_interval(claude_evaluator_results, \"another_trial_answer_mean_diff\")\n",
    "\n",
    "claude_pls_model_stats = {\n",
    "    \"benefit_answer\": {\"mean_diff\": average_model_pls_benefit, \"ci_lower\": ci_lower_model_benefit, \"ci_upper\": ci_upper_model_benefit},\n",
    "    \"rigor_answer\": {\"mean_diff\": average_pls_model_rigor, \"ci_lower\": ci_lower_model_rigor, \"ci_upper\": ci_upper_model_rigor},\n",
    "    \"importance_answer\": {\"mean_diff\": average_pls_model_importance, \"ci_lower\": ci_lower_model_importance, \"ci_upper\": ci_upper_model_importance},\n",
    "    \"full_text_answer\": {\"mean_diff\": average_pls_model_full_text, \"ci_lower\": ci_lower_model_full_text, \"ci_upper\": ci_upper_model_full_text},\n",
    "    \"another_trial_answer\": {\"mean_diff\": average_pls_model_another_trial, \"ci_lower\": ci_lower_model_another_trial, \"ci_upper\": ci_upper_model_another_trial}\n",
    "}\n",
    "\n",
    "pls_claude_model_stats_df = pd.DataFrame(claude_pls_model_stats).T\n",
    "pls_claude_model_stats_df[\"metric\"] = pls_claude_model_stats_df.index\n",
    "# remove index\n",
    "pls_claude_model_stats_df.reset_index(drop=True, inplace=True)\n",
    "pls_claude_model_stats_df[\"evaluator\"] = \"Claude 3.5 Sonnet\"\n",
    "\n",
    "pls_claude_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>ci_lower</th>\n",
       "      <th>ci_upper</th>\n",
       "      <th>metric</th>\n",
       "      <th>evaluator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.592424</td>\n",
       "      <td>3.573721</td>\n",
       "      <td>3.611128</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.353030</td>\n",
       "      <td>1.332122</td>\n",
       "      <td>1.373939</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.730303</td>\n",
       "      <td>2.707594</td>\n",
       "      <td>2.753012</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.686364</td>\n",
       "      <td>3.655170</td>\n",
       "      <td>3.717557</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.868182</td>\n",
       "      <td>3.840497</td>\n",
       "      <td>3.895866</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>GPT4o Mini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.471212</td>\n",
       "      <td>2.466320</td>\n",
       "      <td>2.476105</td>\n",
       "      <td>benefit_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.175758</td>\n",
       "      <td>-0.182107</td>\n",
       "      <td>-0.169408</td>\n",
       "      <td>rigor_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.337879</td>\n",
       "      <td>-0.345682</td>\n",
       "      <td>-0.330075</td>\n",
       "      <td>importance_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.818182</td>\n",
       "      <td>2.804775</td>\n",
       "      <td>2.831589</td>\n",
       "      <td>full_text_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.706061</td>\n",
       "      <td>2.687012</td>\n",
       "      <td>2.725109</td>\n",
       "      <td>another_trial_answer</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_diff  ci_lower  ci_upper                metric          evaluator\n",
       "0   3.592424  3.573721  3.611128        benefit_answer         GPT4o Mini\n",
       "1   1.353030  1.332122  1.373939          rigor_answer         GPT4o Mini\n",
       "2   2.730303  2.707594  2.753012     importance_answer         GPT4o Mini\n",
       "3   3.686364  3.655170  3.717557      full_text_answer         GPT4o Mini\n",
       "4   3.868182  3.840497  3.895866  another_trial_answer         GPT4o Mini\n",
       "5   2.471212  2.466320  2.476105        benefit_answer  Claude 3.5 Sonnet\n",
       "6  -0.175758 -0.182107 -0.169408          rigor_answer  Claude 3.5 Sonnet\n",
       "7  -0.337879 -0.345682 -0.330075     importance_answer  Claude 3.5 Sonnet\n",
       "8   2.818182  2.804775  2.831589      full_text_answer  Claude 3.5 Sonnet\n",
       "9   2.706061  2.687012  2.725109  another_trial_answer  Claude 3.5 Sonnet"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine two dataframes\n",
    "all_pls_model_stats_df = pd.concat([pls_gpt4o_mini_model_stats_df, pls_claude_model_stats_df], ignore_index=True)\n",
    "\n",
    "all_pls_model_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n",
      "/Users/hyesunyun/opt/anaconda3/envs/MedLitSpin/lib/python3.11/site-packages/altair/utils/core.py:395: FutureWarning: the convert_dtype parameter is deprecated and will be removed in a future version.  Do ``ser.astype(object).apply()`` instead if you want ``convert_dtype=False``.\n",
      "  col = df[col_name].apply(to_list_if_array, convert_dtype=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-71dcb9b0cb564c219c005a477b6dc483.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-71dcb9b0cb564c219c005a477b6dc483.vega-embed details,\n",
       "  #altair-viz-71dcb9b0cb564c219c005a477b6dc483.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-71dcb9b0cb564c219c005a477b6dc483\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-71dcb9b0cb564c219c005a477b6dc483\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-71dcb9b0cb564c219c005a477b6dc483\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.8.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.8.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}, \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22}, \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20}, \"text\": {\"fontSize\": 20}}, \"data\": {\"name\": \"data-3c9086933036790af59bff10c59cd985\"}, \"facet\": {\"column\": {\"field\": \"metric\", \"sort\": [\"Benefit\", \"Rigor\", \"Importance\", \"Full-Text\", \"Another Trial\"], \"title\": null, \"type\": \"nominal\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"bar\"}, \"encoding\": {\"color\": {\"field\": \"evaluator\", \"legend\": null, \"scale\": {\"domain\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"range\": [\"#0868ac\", \"#43a2ca\"]}, \"title\": \"Evaluator\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"evaluator\", \"sort\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"text\", \"align\": \"center\", \"baseline\": \"bottom\", \"dy\": {\"expr\": \"if((datum.mean_diff >= 0),-1,20)\"}, \"fontWeight\": \"bold\"}, \"encoding\": {\"color\": {\"value\": \"black\"}, \"text\": {\"field\": \"mean_diff\", \"format\": \".2f\", \"type\": \"quantitative\"}, \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"evaluator\", \"sort\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"title\": null, \"type\": \"nominal\"}, \"y\": {\"field\": \"mean_diff\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}}}, {\"mark\": {\"type\": \"errorbar\"}, \"encoding\": {\"color\": {\"value\": \"gray\"}, \"strokeWidth\": {\"value\": 2}, \"x\": {\"field\": \"evaluator\", \"sort\": [\"Claude 3.5 Sonnet\", \"GPT4o Mini\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"ci_lower\", \"title\": \"Mean Difference\", \"type\": \"quantitative\"}, \"y2\": {\"field\": \"ci_upper\"}}}], \"height\": 250, \"width\": 120}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.8.0.json\", \"datasets\": {\"data-3c9086933036790af59bff10c59cd985\": [{\"mean_diff\": 3.592424242424241, \"ci_lower\": 3.573720651762486, \"ci_upper\": 3.611127833085996, \"metric\": \"Benefit\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 1.3530303030303024, \"ci_lower\": 1.332121563463645, \"ci_upper\": 1.3739390425969598, \"metric\": \"Rigor\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 2.7303030303030305, \"ci_lower\": 2.70759383884234, \"ci_upper\": 2.7530122217637207, \"metric\": \"Importance\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 3.686363636363637, \"ci_lower\": 3.655170035896047, \"ci_upper\": 3.717557236831227, \"metric\": \"Full-Text\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 3.8681818181818186, \"ci_lower\": 3.8404974942114825, \"ci_upper\": 3.8958661421521548, \"metric\": \"Another Trial\", \"evaluator\": \"GPT4o Mini\"}, {\"mean_diff\": 2.471212121212122, \"ci_lower\": 2.4663195188992315, \"ci_upper\": 2.4761047235250127, \"metric\": \"Benefit\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": -0.1757575757575753, \"ci_lower\": -0.18210705495937363, \"ci_upper\": -0.169408096555777, \"metric\": \"Rigor\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": -0.33787878787878745, \"ci_lower\": -0.34568223495993894, \"ci_upper\": -0.33007534079763595, \"metric\": \"Importance\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": 2.818181818181818, \"ci_lower\": 2.8047750415739086, \"ci_upper\": 2.8315885947897272, \"metric\": \"Full-Text\", \"evaluator\": \"Claude 3.5 Sonnet\"}, {\"mean_diff\": 2.706060606060605, \"ci_lower\": 2.6870121684552104, \"ci_upper\": 2.725109043666, \"metric\": \"Another Trial\", \"evaluator\": \"Claude 3.5 Sonnet\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.FacetChart(...)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create altair grouped barchart\n",
    "# grouped by metric and evaluator\n",
    "\n",
    "# Create a mapping for custom facet titles\n",
    "facet_title_mapping = {\n",
    "    'benefit_answer': 'Benefit',\n",
    "    'rigor_answer': 'Rigor',\n",
    "    'importance_answer': 'Importance',\n",
    "    'full_text_answer': 'Full-Text',\n",
    "    'another_trial_answer': 'Another Trial'\n",
    "}\n",
    "\n",
    "# Define the desired order for the facets\n",
    "facet_order = ['Benefit', 'Rigor', 'Importance', 'Full-Text', 'Another Trial']\n",
    "\n",
    "color_mapping = {\n",
    "    'Claude 3.5 Sonnet': '#0868ac',  \n",
    "    'GPT4o Mini': '#43a2ca',  \n",
    "}\n",
    "\n",
    "method_order = ['Claude 3.5 Sonnet', 'GPT4o Mini']\n",
    "\n",
    "# Apply the mapping as a calculated field\n",
    "chart_data = all_pls_model_stats_df.copy()\n",
    "chart_data['metric'] = chart_data['metric'].map(facet_title_mapping)\n",
    "\n",
    "# Configure global font sizes\n",
    "chart_config = {\n",
    "    \"axis\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Axis labels and titles\n",
    "    \"header\": {\"labelFontSize\": 20, \"titleFontSize\": 22},  # Facet headers\n",
    "    \"legend\": {\"labelFontSize\": 18, \"titleFontSize\": 20},  # Legend labels and titles\n",
    "    \"text\": {\"fontSize\": 20},  # Text mark size\n",
    "}\n",
    "\n",
    "# Bar chart\n",
    "bars = alt.Chart(chart_data).mark_bar().encode(\n",
    "    x=alt.X('evaluator:N', title=None, axis=alt.Axis(labelAngle=-45), sort = method_order),\n",
    "    y=alt.Y('mean_diff:Q', title='Mean Difference'),\n",
    "    color=alt.Color('evaluator:N', title='Evaluator', legend=None, scale=alt.Scale(domain=list(color_mapping.keys()), range=list(color_mapping.values())))\n",
    ").properties(\n",
    "    width=120,  # Set the width to 300 pixels\n",
    "    height=250  # Set the height to 300 pixels\n",
    ")\n",
    "\n",
    "# Error bars\n",
    "error_bars = alt.Chart(chart_data).mark_errorbar().encode(\n",
    "    alt.X(\"evaluator:N\", sort = method_order),\n",
    "    alt.Y(\"ci_lower:Q\").title(\"Mean Difference\"),\n",
    "    alt.Y2(\"ci_upper:Q\"),\n",
    "    strokeWidth=alt.value(2),\n",
    "    color=alt.value('gray')\n",
    ")\n",
    "\n",
    "# Add value labels\n",
    "text = bars.mark_text(\n",
    "    align='center',\n",
    "    baseline='bottom',\n",
    "    fontWeight='bold',\n",
    "    dy=alt.expr(expr=alt.expr.if_(alt.datum.mean_diff >= 0, -1, 20))  # Adjust the position of the text    \n",
    ").encode(\n",
    "    text=alt.Text('mean_diff:Q', format='.2f'),\n",
    "    color=alt.value('black')  # Set text color to black\n",
    ")\n",
    "\n",
    "# Combine layers and facet\n",
    "chart = alt.layer(bars, text, error_bars, data=chart_data).facet(\n",
    "    column=alt.Column('metric:N', title=None, sort=facet_order),\n",
    ").configure(**chart_config)  # Apply\n",
    "\n",
    "# save to html\n",
    "chart.save(\"./plots/pls_evaluator_comparison_by_measures.html\")\n",
    "\n",
    "chart\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MedLitSpin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
