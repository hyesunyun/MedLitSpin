{
    "gpt4o": {
        "accuracy": 0.7833333333333333,
        "precision": 0.7073170731707317,
        "recall": 0.9666666666666667,
        "f1": 0.8169014084507042
    },
    "gpt4o-mini": {
        "accuracy": 0.85,
        "precision": 0.7837837837837838,
        "recall": 0.9666666666666667,
        "f1": 0.8656716417910447
    },
    "gpt35": {
        "accuracy": 0.5166666666666667,
        "precision": 1.0,
        "recall": 0.03333333333333333,
        "f1": 0.06451612903225806
    },
    "gemini_1.5_flash": {
        "accuracy": 0.7333333333333333,
        "precision": 0.6521739130434783,
        "recall": 1.0,
        "f1": 0.7894736842105263
    },
    "gemini_1.5_flash-8B": {
        "accuracy": 0.8333333333333334,
        "precision": 0.7941176470588235,
        "recall": 0.9,
        "f1": 0.84375
    },
    "claude_3.5-sonnet": {
        "accuracy": 0.9666666666666667,
        "precision": 1.0,
        "recall": 0.9333333333333333,
        "f1": 0.9655172413793104
    },
    "claude_3.5-haiku": {
        "accuracy": 0.5666666666666667,
        "precision": 0.5357142857142857,
        "recall": 1.0,
        "f1": 0.6976744186046512
    },
    "biomistral7B": {
        "accuracy": 0.5166666666666667,
        "precision": 1.0,
        "recall": 0.03333333333333333,
        "f1": 0.06451612903225806
    },
    "llama2_chat-13B": {
        "accuracy": 0.5666666666666667,
        "precision": 0.5370370370370371,
        "recall": 0.9666666666666667,
        "f1": 0.6904761904761905
    },
    "llama2_chat-70B": {
        "accuracy": 0.6333333333333333,
        "precision": 0.58,
        "recall": 0.9666666666666667,
        "f1": 0.725
    },
    "llama3_instruct-8B": {
        "accuracy": 0.8333333333333334,
        "precision": 1.0,
        "recall": 0.6666666666666666,
        "f1": 0.8
    },
    "llama3_instruct-70B": {
        "accuracy": 0.8333333333333334,
        "precision": 1.0,
        "recall": 0.6666666666666666,
        "f1": 0.8
    },
    "med42-8B": {
        "accuracy": 0.5833333333333334,
        "precision": 1.0,
        "recall": 0.16666666666666666,
        "f1": 0.2857142857142857
    },
    "med42-70B": {
        "accuracy": 0.8,
        "precision": 0.9090909090909091,
        "recall": 0.6666666666666666,
        "f1": 0.7692307692307693
    },
    "olmo2_instruct-7B": {
        "accuracy": 0.7,
        "precision": 1.0,
        "recall": 0.4,
        "f1": 0.5714285714285714
    },
    "olmo2_instruct-13B": {
        "accuracy": 0.5166666666666667,
        "precision": 1.0,
        "recall": 0.03333333333333333,
        "f1": 0.06451612903225806
    },
    "mistral_instruct7B": {
        "accuracy": 0.5,
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0
    },
    "openbiollm-8B": {
        "accuracy": 0.5084745762711864,
        "precision": 0.5,
        "recall": 1.0,
        "f1": 0.6666666666666666
    },
    "openbiollm-70B": {
        "accuracy": 0.8333333333333334,
        "precision": 0.8571428571428571,
        "recall": 0.8,
        "f1": 0.8275862068965517
    },
}