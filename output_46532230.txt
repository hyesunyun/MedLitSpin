
     active environment : MedLitSpin
    active env location : /home/yun.hy/.conda/envs/MedLitSpin
            shell level : 2
       user config file : /home/yun.hy/.condarc
 populated config files : 
          conda version : 4.5.4
    conda-build version : 3.10.5
         python version : 3.6.5.final.0
       base environment : /shared/centos7/anaconda3/3.6  (read only)
           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/free/linux-64
                          https://repo.anaconda.com/pkgs/free/noarch
                          https://repo.anaconda.com/pkgs/r/linux-64
                          https://repo.anaconda.com/pkgs/r/noarch
                          https://repo.anaconda.com/pkgs/pro/linux-64
                          https://repo.anaconda.com/pkgs/pro/noarch
          package cache : /shared/centos7/anaconda3/3.6/pkgs
                          /home/yun.hy/.conda/pkgs
       envs directories : /home/yun.hy/.conda/envs
                          /shared/centos7/anaconda3/3.6/envs
               platform : linux-64
             user-agent : conda/4.5.4 requests/2.18.4 CPython/3.6.5 Linux/3.10.0-1160.25.1.el7.x86_64 centos/7 glibc/2.17
                UID:GID : 1825635949:100
             netrc file : /home/yun.hy/.netrc
           offline mode : False

Running evaluation for interpreting trial results from vanilla PLS using the evaluator models...
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/gpt35/gpt35_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt35
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt35/gpt35_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt35/gpt35_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.20000000000000018
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.833333333333334
Mean difference for 'another_trial_answer': 2.6999999999999997

Overall mean difference across all answers: 1.4933333333333334
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/gpt4o/gpt4o_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt4o
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt4o/gpt4o_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt4o/gpt4o_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.20000000000000018
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.6999999999999997

Overall mean difference across all answers: 1.4866666666666666
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/gpt4o-mini/gpt4o-mini_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt4o-mini
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt4o-mini/gpt4o-mini_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gpt4o-mini/gpt4o-mini_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.8

Overall mean difference across all answers: 1.5133333333333334
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/gemini_1.5_flash/gemini_1.5_flash_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gemini_1.5_flash
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gemini_1.5_flash/gemini_1_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gemini_1.5_flash/gemini_1_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.733333333333333

Overall mean difference across all answers: 1.5
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/gemini_1.5_flash-8B/gemini_1.5_flash-8B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gemini_1.5_flash-8B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gemini_1.5_flash-8B/gemini_1_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/gemini_1.5_flash-8B/gemini_1_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.9000000000000004
Mean difference for 'another_trial_answer': 2.6666666666666665

Overall mean difference across all answers: 1.5066666666666668
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/claude_3.5-sonnet/claude_3.5-sonnet_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-sonnet
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-sonnet/claude_3_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-sonnet/claude_3_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.833333333333333
Mean difference for 'another_trial_answer': 2.6999999999999997

Overall mean difference across all answers: 1.5
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/claude_3.5-haiku/claude_3.5-haiku_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-haiku
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-haiku/claude_3_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/claude_3.5-haiku/claude_3_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.5
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.7666666666666666
Mean difference for 'another_trial_answer': 2.6333333333333333

Overall mean difference across all answers: 1.4800000000000002
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/olmo2_instruct-7B/olmo2_instruct-7B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/olmo2_instruct-7B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/olmo2_instruct-7B/olmo2_instruct-7B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/olmo2_instruct-7B/olmo2_instruct-7B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.833333333333333
Mean difference for 'another_trial_answer': 2.6999999999999997

Overall mean difference across all answers: 1.5
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/olmo2_instruct-13B/olmo2_instruct-13B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/olmo2_instruct-13B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/olmo2_instruct-13B/olmo2_instruct-13B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/olmo2_instruct-13B/olmo2_instruct-13B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.20000000000000018
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8000000000000007
Mean difference for 'another_trial_answer': 2.8

Overall mean difference across all answers: 1.5066666666666668
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/mistral_instruct7B/mistral_instruct7B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/mistral_instruct7B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/mistral_instruct7B/mistral_instruct7B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/mistral_instruct7B/mistral_instruct7B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.6999999999999997

Overall mean difference across all answers: 1.4933333333333334
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/med42-8B/med42-8B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/med42-8B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/med42-8B/med42-8B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/med42-8B/med42-8B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.5
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.2999999999999998
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.6666666666666665

Overall mean difference across all answers: 1.5
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/biomistral7B/biomistral7B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/biomistral7B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/biomistral7B/biomistral7B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/biomistral7B/biomistral7B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.5
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.9000000000000004
Mean difference for 'another_trial_answer': 2.6666666666666665

Overall mean difference across all answers: 1.5133333333333336
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/openbiollm-8B/openbiollm-8B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/openbiollm-8B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/openbiollm-8B/openbiollm-8B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/openbiollm-8B/openbiollm-8B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.20000000000000018
Mean difference for 'importance_answer': -0.36666666666666625
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.6666666666666665

Overall mean difference across all answers: 1.4733333333333334
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/llama2_chat-7B/llama2_chat-7B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-7B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-7B/llama2_chat-7B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-7B/llama2_chat-7B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.20000000000000018
Mean difference for 'importance_answer': -0.36666666666666625
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.6666666666666665

Overall mean difference across all answers: 1.4733333333333334
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/llama2_chat-13B/llama2_chat-13B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-13B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-13B/llama2_chat-13B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-13B/llama2_chat-13B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.36666666666666625
Mean difference for 'full_text_answer': 2.833333333333333
Mean difference for 'another_trial_answer': 2.6999999999999997

Overall mean difference across all answers: 1.4933333333333334
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/llama3_instruct-8B/llama3_instruct-8B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama3_instruct-8B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama3_instruct-8B/llama3_instruct-8B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama3_instruct-8B/llama3_instruct-8B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.20000000000000018
Mean difference for 'importance_answer': -0.36666666666666625
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.6999999999999997

Overall mean difference across all answers: 1.48
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/llama2_chat-70B/llama2_chat-70B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-70B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-70B/llama2_chat-70B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama2_chat-70B/llama2_chat-70B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.36666666666666625
Mean difference for 'full_text_answer': 2.833333333333333
Mean difference for 'another_trial_answer': 2.733333333333333

Overall mean difference across all answers: 1.5
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/llama3_instruct-70B/llama3_instruct-70B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama3_instruct-70B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama3_instruct-70B/llama3_instruct-70B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/llama3_instruct-70B/llama3_instruct-70B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.7666666666666666

Overall mean difference across all answers: 1.5066666666666668
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/med42-70B/med42-70B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/med42-70B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/med42-70B/med42-70B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/med42-70B/med42-70B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.833333333333333
Mean difference for 'another_trial_answer': 2.733333333333333

Overall mean difference across all answers: 1.5066666666666668
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/openbiollm-70B/openbiollm-70B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/openbiollm-70B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/openbiollm-70B/openbiollm-70B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/openbiollm-70B/openbiollm-70B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.7666666666666666

Overall mean difference across all answers: 1.5066666666666668
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/biomedgpt7B/biomedgpt7B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/biomedgpt7B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/biomedgpt7B/biomedgpt7B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/biomedgpt7B/biomedgpt7B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.2999999999999998
Mean difference for 'full_text_answer': 2.833333333333333
Mean difference for 'another_trial_answer': 2.6666666666666665

Overall mean difference across all answers: 1.5
Arguments Provided for the Evaluator:
Model:        claude_3.5-sonnet
Input Path:   code/pls_outputs/alpacare-7B/alpacare-7B_outputs.csv
Output Path:  code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/alpacare-7B
Is Debug:     None

Output path did not exist. Directory was created.
Loading the dataset...
Loading the model...
Saving outputs from model - claude_3.5-sonnet to csv and json
Model outputs saved to code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/alpacare-7B/alpacare-7B_outputs_pls_interpretation_outputs.json and code/pls_outputs/_interpretation_eval_results/claude_3.5-sonnet/alpacare-7B/alpacare-7B_outputs_pls_interpretation_outputs.csv
Calculating means differences in scores between the PLS from spun and unspun abstracts...
Mean difference for 'benefit_answer': 2.466666666666667
Mean difference for 'rigor_answer': -0.16666666666666607
Mean difference for 'importance_answer': -0.33333333333333304
Mean difference for 'full_text_answer': 2.8
Mean difference for 'another_trial_answer': 2.6666666666666665

Overall mean difference across all answers: 1.4866666666666668
