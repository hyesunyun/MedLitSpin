
     active environment : MedLitSpin
    active env location : /home/yun.hy/.conda/envs/MedLitSpin
            shell level : 4
       user config file : /home/yun.hy/.condarc
 populated config files : 
          conda version : 24.5.0
    conda-build version : 24.5.1
         python version : 3.12.4.final.0
                 solver : libmamba (default)
       virtual packages : __archspec=1=sapphirerapids
                          __conda=24.5.0=0
                          __cuda=12.3=0
                          __glibc=2.34=0
                          __linux=5.14.0=0
                          __unix=0=0
       base environment : /shared/EL9/explorer/anaconda3/2024.06  (read only)
      conda av data dir : /shared/EL9/explorer/anaconda3/2024.06/etc/conda
  conda av metadata url : None
           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/r/linux-64
                          https://repo.anaconda.com/pkgs/r/noarch
          package cache : /shared/EL9/explorer/anaconda3/2024.06/pkgs
                          /home/yun.hy/.conda/pkgs
       envs directories : /home/yun.hy/.conda/envs
                          /shared/EL9/explorer/anaconda3/2024.06/envs
               platform : linux-64
             user-agent : conda/24.5.0 requests/2.32.2 CPython/3.12.4 Linux/5.14.0-362.13.1.el9_3.x86_64 rocky/9.3 glibc/2.34 solver/libmamba conda-libmamba-solver/24.1.0 libmambapy/1.5.8 aau/0.4.4 c/. s/. e/.
                UID:GID : 1825635949:100
             netrc file : /home/yun.hy/.netrc
           offline mode : False


Running evaluation for detecting spin in abstracts of medical literature...
Arguments Provided for the Evaluator:
Model:        biomedgpt7B
Output Path:  code/eval_outputs/biomedgpt7B
Is Debug:     None

Loading the dataset...
Loading the model...
Model's dtype: torch.float16
Model's device: cuda:0
Model's device map: {'': 0}

Saving outputs from model - biomedgpt7B to csv and json
Model outputs saved to code/eval_outputs/biomedgpt7B/biomedgpt7B_detection_outputs.json and code/eval_outputs/biomedgpt7B/biomedgpt7B_detection_outputs.csv
Calculating metrics...
Model's output has some 'Error' or empty string values. Removing these rows from the metrics...
Number of rows after removing 'Error' or empty string values: 58
Accuracy: 0.5
Precision: 0.5
Recall: 1.0
F1: 0.6666666666666666
####################################
Running evaluation for interpreting trial results...
Arguments Provided for the Evaluator:
Model:        biomedgpt7B
Output Path:  code/eval_outputs/biomedgpt7B
Is Debug:     None

Loading the dataset...
Loading the model...
Model's dtype: torch.float16
Model's device: cuda:0
Model's device map: {'': 0}

Saving outputs from model - biomedgpt7B to csv and json
Model outputs saved to code/eval_outputs/biomedgpt7B/biomedgpt7B_interpretation_outputs.json and code/eval_outputs/biomedgpt7B/biomedgpt7B_interpretation_outputs.csv
Calculating means differences in scores between spin and no spin abstracts...
Column 'benefit_answer' has some 'Error' or empty string values. Removing these rows from the metrics...
PMIDs with 'Error' or empty string values in column 'benefit_answer': ['20153039', '20800381', '19273714']
Number of rows after removing 'Error' or empty string values: 54
Mean difference for 'benefit_answer': 1.2407407407407405
Column 'rigor_answer' has some 'Error' or empty string values. Removing these rows from the metrics...
PMIDs with 'Error' or empty string values in column 'rigor_answer': ['20564068', '20530276', '21041710', '16314619', '20973267', '22112969', '17264336', '16148021', '17134892', '17173959', '20153039', '20673585', '12177098', '17179098', '11261827', '21471562', '16504757', '15947110', '18955454', '20087643', '10637238', '21399726', '9093724', '21060024', '17530429', '20448107', '18794551', '19273714', '20800381']
Number of rows after removing 'Error' or empty string values: 2
Mean difference for 'rigor_answer': 0.0
Column 'importance_answer' has some 'Error' or empty string values. Removing these rows from the metrics...
PMIDs with 'Error' or empty string values in column 'importance_answer': ['20564068', '20530276', '21041710', '16314619', '20973267', '22112969', '17264336', '16148021', '17134892', '10547391', '17173959', '20153039', '20673585', '12177098', '17179098', '11261827', '21471562', '16504757', '15947110', '18955454', '20087643', '10637238', '21399726', '9093724', '21060024', '17530429', '20448107', '18794551', '19273714']
Number of rows after removing 'Error' or empty string values: 2
Mean difference for 'importance_answer': 0.0
Column 'full_text_answer' has some 'Error' or empty string values. Removing these rows from the metrics...
PMIDs with 'Error' or empty string values in column 'full_text_answer': ['20564068', '21471562', '21060024', '9093724', '17134892', '20800381', '21041710', '10547391', '17173959', '18794551', '19273714', '20153039', '20673585', '18955454', '20973267', '20087643', '21399726']
Number of rows after removing 'Error' or empty string values: 26
Mean difference for 'full_text_answer': -0.1538461538461533
Column 'another_trial_answer' has some 'Error' or empty string values. Removing these rows from the metrics...
PMIDs with 'Error' or empty string values in column 'another_trial_answer': ['20564068', '20530276', '21041710', '16314619', '20973267', '22112969', '17264336', '16148021', '17134892', '10547391', '17173959', '20153039', '20673585', '12177098', '17179098', '11261827', '21471562', '16504757', '15947110', '18955454', '20087643', '10637238', '21399726', '9093724', '21060024', '17530429', '20448107', '18794551', '19273714', '20800381']
Number of rows after removing 'Error' or empty string values: 0
Mean difference for 'another_trial_answer': nan

Overall mean difference across all answers: nan
